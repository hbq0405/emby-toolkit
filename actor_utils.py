# actor_utils.py
import threading
import concurrent.futures
import time
import psycopg2
import constants
from datetime import datetime
from typing import Optional, Dict, Any, List, Callable
# å¯¼å…¥åº•å±‚å·¥å…·ç®±å’Œæ—¥å¿—
import logging
from database import connection
from database.actor_db import ActorDBManager
import utils
import handler.tmdb as tmdb
import handler.emby as emby
from handler.douban import DoubanApi
from ai_translator import AITranslator
from utils import contains_chinese

logger = logging.getLogger(__name__)

# --- æ¼”å‘˜é€‰æ‹© ---
def select_best_role(current_role: str, candidate_role: str) -> str:
    """
    æ ¹æ®ä¼˜å…ˆçº§é€‰æ‹©æœ€ä½³è§’è‰²åã€‚
    ã€æœ€ç»ˆä¿®æ­£ç‰ˆã€‘ç¡®ä¿æœ‰ä»·å€¼çš„ä¸­æ–‡åä¸ä¼šè¢«è‹±æ–‡åè¦†ç›–ã€‚

    ä¼˜å…ˆçº§é¡ºåº:
    1. æœ‰å†…å®¹çš„è±†ç“£ä¸­æ–‡è§’è‰²å
    2. æœ‰å†…å®¹çš„æœ¬åœ°ä¸­æ–‡è§’è‰²å
    3. æœ‰å†…å®¹çš„è‹±æ–‡è§’è‰²å (è±†ç“£æ¥æºä¼˜å…ˆ)
    4. 'æ¼”å‘˜' (æˆ–å…¶ä»–å ä½ç¬¦)
    5. ç©ºå­—ç¬¦ä¸²
    """
    # --- æ­¥éª¤ 1: æ¸…ç†å’Œè§„èŒƒåŒ–è¾“å…¥ ---
    original_current = current_role # ä¿å­˜åŸå§‹å€¼ç”¨äºæ—¥å¿—
    original_candidate = candidate_role # ä¿å­˜åŸå§‹å€¼ç”¨äºæ—¥å¿—
    
    current_role = str(current_role or '').strip()
    candidate_role = str(candidate_role or '').strip()

    # --- æ­¥éª¤ 2: å‡†å¤‡æ—¥å¿—å’Œåˆ¤æ–­æ ‡å¿— ---
    logger.info(f"  âœ å¤‡é€‰è§’è‰²å: å½“å‰='{current_role}', è±†ç“£='{candidate_role}'")

    current_is_chinese = utils.contains_chinese(current_role)
    candidate_is_chinese = utils.contains_chinese(candidate_role)
    
    # å®šä¹‰ä¸€ä¸ªæ›´å¹¿æ³›çš„å ä½ç¬¦åˆ—è¡¨
    placeholders = {"actor", "actress", "æ¼”å‘˜", "é…éŸ³"}
    current_is_placeholder = current_role.lower() in placeholders
    candidate_is_placeholder = candidate_role.lower() in placeholders

    # --- æ­¥éª¤ 3: åº”ç”¨ä¼˜å…ˆçº§è§„åˆ™å¹¶è®°å½•å†³ç­– ---

    # ä¼˜å…ˆçº§ 1: è±†ç“£è§’è‰²æ˜¯æœ‰æ•ˆçš„ä¸­æ–‡å
    if candidate_is_chinese and not candidate_is_placeholder:
        logger.trace(f"  âœ å†³ç­–: [ä¼˜å…ˆçº§1] è±†ç“£è§’è‰²æ˜¯æœ‰æ•ˆä¸­æ–‡åã€‚é€‰æ‹©è±†ç“£è§’è‰²ã€‚")
        logger.info(f"    â””â”€ é€‰æ‹©: '{candidate_role}'")
        return candidate_role

    # ä¼˜å…ˆçº§ 2: å½“å‰è§’è‰²æ˜¯æœ‰æ•ˆçš„ä¸­æ–‡åï¼Œè€Œè±†ç“£è§’è‰²ä¸æ˜¯ã€‚å¿…é¡»ä¿ç•™å½“å‰è§’è‰²ï¼
    if current_is_chinese and not current_is_placeholder and not candidate_is_chinese:
        logger.trace(f"  âœ å†³ç­–: [ä¼˜å…ˆçº§2] å½“å‰è§’è‰²æ˜¯æœ‰æ•ˆä¸­æ–‡åï¼Œè€Œè±†ç“£ä¸æ˜¯ã€‚ä¿ç•™å½“å‰è§’è‰²ã€‚")
        logger.info(f"      â””â”€ é€‰æ‹©: '{current_role}'")
        return current_role

    # ä¼˜å…ˆçº§ 3: ä¸¤è€…éƒ½ä¸æ˜¯æœ‰æ•ˆçš„ä¸­æ–‡åï¼ˆæˆ–éƒ½æ˜¯ï¼‰ã€‚é€‰æ‹©ä¸€ä¸ªéå ä½ç¬¦çš„ï¼Œè±†ç“£è€…ä¼˜å…ˆã€‚
    if candidate_role and not candidate_is_placeholder:
        logger.trace(f"  âœ å†³ç­–: [ä¼˜å…ˆçº§3] è±†ç“£è§’è‰²æ˜¯æœ‰æ•ˆçš„éä¸­æ–‡å/å ä½ç¬¦ã€‚é€‰æ‹©è±†ç“£è§’è‰²ã€‚")
        logger.info(f"      â””â”€ é€‰æ‹©: '{candidate_role}'")
        return candidate_role
    
    if current_role and not current_is_placeholder:
        logger.trace(f"  âœ å†³ç­–: [ä¼˜å…ˆçº§4] å½“å‰è§’è‰²æ˜¯æœ‰æ•ˆçš„éä¸­æ–‡å/å ä½ç¬¦ï¼Œè€Œè±†ç“£è§’è‰²æ˜¯æ— æ•ˆçš„ã€‚ä¿ç•™å½“å‰è§’è‰²ã€‚")
        logger.info(f"      â””â”€ é€‰æ‹©: '{current_role}'")
        return current_role

    # ä¼˜å…ˆçº§ 4: å¤„ç†å ä½ç¬¦ã€‚å¦‚æœä¸¤è€…ä¹‹ä¸€æ˜¯å ä½ç¬¦ï¼Œåˆ™è¿”å›ä¸€ä¸ªï¼ˆè±†ç“£ä¼˜å…ˆï¼‰ã€‚
    if candidate_role: # å¦‚æœè±†ç“£æœ‰å†…å®¹ï¼ˆæ­¤æ—¶åªèƒ½æ˜¯å ä½ç¬¦ï¼‰
        logger.trace(f"  âœ å†³ç­–: [ä¼˜å…ˆçº§5] è±†ç“£è§’è‰²æ˜¯å ä½ç¬¦ã€‚é€‰æ‹©è±†ç“£è§’è‰²ã€‚")
        logger.info(f"      â””â”€ é€‰æ‹©: '{candidate_role}'")
        return candidate_role
        
    if current_role: # å¦‚æœå½“å‰æœ‰å†…å®¹ï¼ˆæ­¤æ—¶åªèƒ½æ˜¯å ä½ç¬¦ï¼‰
        logger.trace(f"  âœ å†³ç­–: [ä¼˜å…ˆçº§6] å½“å‰è§’è‰²æ˜¯å ä½ç¬¦ï¼Œè±†ç“£ä¸ºç©ºã€‚ä¿ç•™å½“å‰è§’è‰²ã€‚")
        logger.info(f"      â””â”€ é€‰æ‹©: '{current_role}'")
        return current_role

    # ä¼˜å…ˆçº§ 5: æ‰€æœ‰æƒ…å†µéƒ½å¤„ç†å®Œï¼Œåªå‰©ä¸‹ä¸¤è€…éƒ½ä¸ºç©ºã€‚
    logger.trace(f"  âœ å†³ç­–: [ä¼˜å…ˆçº§7] æ‰€æœ‰è¾“å…¥å‡ä¸ºç©ºæˆ–æ— æ•ˆã€‚è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚")
    logger.info(f"      â””â”€ é€‰æ‹©: ''")
    return ""

# --- è´¨é‡è¯„ä¼° ---
def evaluate_cast_processing_quality(
    final_cast: List[Dict[str, Any]], 
    original_cast_count: int, 
    expected_final_count: Optional[int] = None,
    is_animation: bool = False  # âœ¨âœ¨âœ¨ æ–°å¢å‚æ•°ï¼Œé»˜è®¤ä¸º False âœ¨âœ¨âœ¨
) -> float:
    """
    ã€V-Final æç®€ç‰ˆ - åŠ¨ç”»ç‰‡ä¼˜åŒ–ã€‘
    åªå…³å¿ƒæœ€ç»ˆäº§å‡ºçš„ä¸­æ–‡åŒ–è´¨é‡å’Œæ¼”å‘˜æ•°é‡ã€‚
    å¦‚æœæ£€æµ‹åˆ°æ˜¯åŠ¨ç”»ç‰‡ï¼Œåˆ™è·³è¿‡æ‰€æœ‰å…³äºæ•°é‡çš„æƒ©ç½šã€‚
    """
    if not final_cast:
        # âœ¨ å¦‚æœæ˜¯åŠ¨ç”»ç‰‡ä¸”æ¼”å‘˜åˆ—è¡¨ä¸ºç©ºï¼Œå¯ä»¥ç»™ä¸€ä¸ªåŸºç¡€é€šè¿‡åˆ†ï¼Œé¿å…è¿›æ‰‹åŠ¨åˆ—è¡¨
        if is_animation:
            logger.info("  âœ è´¨é‡è¯„ä¼°ï¼šåŠ¨ç”»ç‰‡/çºªå½•ç‰‡æ¼”å‘˜åˆ—è¡¨ä¸ºç©ºï¼Œå±äºæ­£å¸¸æƒ…å†µï¼Œç»™äºˆåŸºç¡€é€šè¿‡åˆ† 7.0ã€‚")
            return 7.0
        else:
            logger.warning("  âœ å¤„ç†åæ¼”å‘˜åˆ—è¡¨ä¸ºç©ºï¼è¯„ä¸º 0.0 åˆ†ã€‚")
            return 0.0
        
    total_actors = len(final_cast)
    accumulated_score = 0.0
    
    logger.debug(f"--- è´¨é‡è¯„ä¼°å¼€å§‹ ---")
    logger.debug(f"  - åŸå§‹æ¼”å‘˜æ•°: {original_cast_count}")
    logger.debug(f"  - å¤„ç†åæ¼”å‘˜æ•°: {total_actors}")
    logger.debug(f"------------------")

    for i, actor_data in enumerate(final_cast):
        # æ¯ä¸ªæ¼”å‘˜çš„åŸºç¡€åˆ†æ˜¯ 0.0ï¼Œé€šè¿‡åŠ åˆ†é¡¹ç´¯åŠ 
        score = 0.0
        
        # --- æ™ºèƒ½è·å–æ•°æ® ---
        actor_name = actor_data.get("name") or actor_data.get("Name")
        actor_role = actor_data.get("character") or actor_data.get("Role")
        
        # --- æ¼”å‘˜åè¯„åˆ† (æ»¡åˆ† 5.0) ---
        if actor_name and utils.contains_chinese(actor_name):
            score += 5.0
        elif actor_name:
            score += 1.0 # ä¿ç•™ä¸€ä¸ªè¾ƒä½çš„åŸºç¡€åˆ†ç»™è‹±æ–‡å

        # --- è§’è‰²åè¯„åˆ† (æ»¡åˆ† 5.0) ---
        placeholders = {"æ¼”å‘˜", "é…éŸ³"}
        is_placeholder = (str(actor_role).endswith("(é…éŸ³)")) or (str(actor_role) in placeholders)

        if actor_role and utils.contains_chinese(actor_role) and not is_placeholder:
            score += 5.0 # æœ‰æ„ä¹‰çš„ä¸­æ–‡è§’è‰²å
        elif actor_role and utils.contains_chinese(actor_role) and is_placeholder:
            score += 2.5 # ä¸­æ–‡å ä½ç¬¦
        elif actor_role:
            score += 0.5 # è‹±æ–‡è§’è‰²å

        final_actor_score = min(10.0, score)
        accumulated_score += final_actor_score
        
        logger.debug(f"    â”œâ”€ [{i+1}/{total_actors}] æ¼”å‘˜: '{actor_name}' (è§’è‰²: '{actor_role}') | å•é¡¹è¯„åˆ†: {final_actor_score:.1f}")

    avg_score = accumulated_score / total_actors if total_actors > 0 else 0.0
    
    # --- âœ¨âœ¨âœ¨ æ ¸å¿ƒä¿®æ”¹ï¼šæ¡ä»¶åŒ–çš„æ•°é‡æƒ©ç½šé€»è¾‘ âœ¨âœ¨âœ¨ ---
    logger.debug(f"------------------------------------")
    logger.debug(f"  âœ åŸºç¡€å¹³å‡åˆ† (æƒ©ç½šå‰): {avg_score:.2f}")

    if is_animation:
        logger.debug("  âœ æƒ©ç½š: æ£€æµ‹åˆ°ä¸ºåŠ¨ç”»ç‰‡/çºªå½•ç‰‡ï¼Œè·³è¿‡æ‰€æœ‰æ•°é‡ç›¸å…³çš„æƒ©ç½šã€‚")
    else:
        # åªæœ‰åœ¨ä¸æ˜¯åŠ¨ç”»ç‰‡æ—¶ï¼Œæ‰æ‰§è¡ŒåŸæ¥çš„æ•°é‡æƒ©ç½šé€»è¾‘
        if total_actors < 10:
            penalty_factor = total_actors / 10.0
            logger.warning(f"  âœ æƒ©ç½š: æœ€ç»ˆæ¼”å‘˜æ•°({total_actors})å°‘äº10ä¸ªï¼Œä¹˜ä»¥æƒ©ç½šå› å­ {penalty_factor:.2f}")
            avg_score *= penalty_factor
            
        elif expected_final_count is not None:
            if total_actors < expected_final_count * 0.8:
                penalty_factor = total_actors / expected_final_count
                logger.warning(f"  âœ æƒ©ç½š: æ•°é‡({total_actors})è¿œå°‘äºé¢„æœŸ({expected_final_count})ï¼Œä¹˜ä»¥æƒ©ç½šå› å­ {penalty_factor:.2f}")
                avg_score *= penalty_factor
        elif total_actors < original_cast_count * 0.8:
            penalty_factor = total_actors / original_cast_count
            logger.warning(f"  âœ æƒ©ç½š: æ•°é‡ä»{original_cast_count}å¤§å¹…å‡å°‘åˆ°{total_actors}ï¼Œä¹˜ä»¥æƒ©ç½šå› å­ {penalty_factor:.2f}")
            avg_score *= penalty_factor
        else:
            logger.debug(f"  âœ æƒ©ç½š: æ•°é‡æ­£å¸¸ï¼Œä¸è¿›è¡Œæƒ©ç½šã€‚")
    
    final_score_rounded = round(avg_score, 1)
    logger.info(f"  âœ æœ€ç»ˆè¯„åˆ†: {final_score_rounded:.1f} ---")
    return final_score_rounded

# --- ç¿»è¯‘æ¼”å‘˜çš„ç‰¹å®šå­—æ®µ ---
def translate_actor_field(text: Optional[str], db_manager: ActorDBManager, db_cursor: psycopg2.extensions.cursor, ai_translator: Optional[AITranslator], translator_engines: List[str], ai_enabled: bool) -> Optional[str]:
    """ç¿»è¯‘æ¼”å‘˜çš„ç‰¹å®šå­—æ®µï¼Œæ™ºèƒ½é€‰æ‹©AIæˆ–ä¼ ç»Ÿç¿»è¯‘å¼•æ“ã€‚"""
    # 1. å‰ç½®æ£€æŸ¥ï¼šå¦‚æœæ–‡æœ¬ä¸ºç©ºã€æ˜¯çº¯ç©ºæ ¼ï¼Œæˆ–å·²åŒ…å«ä¸­æ–‡ï¼Œåˆ™ç›´æ¥è¿”å›åŸæ–‡
    if not text or not text.strip() or utils.contains_chinese(text):
        return text
    
    text_stripped = text.strip()

    # 2. å‰ç½®æ£€æŸ¥ï¼šè·³è¿‡çŸ­çš„å¤§å†™å­—æ¯ç¼©å†™
    if len(text_stripped) <= 2 and text_stripped.isupper():
        return text

    # 3. æ ¸å¿ƒä¿®å¤ï¼šä¼˜å…ˆä»æ•°æ®åº“è¯»å–ç¼“å­˜ï¼Œå¹¶å¤„ç†æ‰€æœ‰æƒ…å†µ
    cached_entry = db_manager.get_translation_from_db(db_cursor, text_stripped)
    if cached_entry:
        # æƒ…å†µ A: ç¼“å­˜ä¸­æœ‰æˆåŠŸçš„ç¿»è¯‘ç»“æœ
        if cached_entry.get("translated_text"):
            cached_translation = cached_entry.get("translated_text")
            logger.info(f"æ•°æ®åº“ç¿»è¯‘ç¼“å­˜å‘½ä¸­ for '{text_stripped}' -> '{cached_translation}'")
            return cached_translation
        # æƒ…å†µ B: ç¼“å­˜ä¸­æ˜ç¡®è®°å½•äº†è¿™æ˜¯ä¸€ä¸ªå¤±è´¥çš„ç¿»è¯‘
        else:
            logger.debug(f"æ•°æ®åº“ç¿»è¯‘ç¼“å­˜å‘½ä¸­ (å¤±è´¥è®°å½•) for '{text_stripped}'ï¼Œä¸å†å°è¯•åœ¨çº¿ç¿»è¯‘ã€‚")
            return text # ç›´æ¥è¿”å›åŸæ–‡ï¼Œé¿å…é‡å¤è¯·æ±‚

    # 4. å¦‚æœç¼“å­˜ä¸­å®Œå…¨æ²¡æœ‰è®°å½•ï¼Œæ‰è¿›è¡Œåœ¨çº¿ç¿»è¯‘
    logger.debug(f"'{text_stripped}' åœ¨ç¿»è¯‘ç¼“å­˜ä¸­æœªæ‰¾åˆ°ï¼Œå°†è¿›è¡Œåœ¨çº¿ç¿»è¯‘...")
    final_translation = None
    final_engine = "unknown"

    # æ ¹æ®é…ç½®é€‰æ‹©ç¿»è¯‘æ–¹å¼
    ai_translation_attempted = False

    # æ­¥éª¤ 1: å¦‚æœAIç¿»è¯‘å¯ç”¨ï¼Œä¼˜å…ˆå°è¯•AI
    if ai_translator and ai_enabled:
        ai_translation_attempted = True
        logger.debug(f"AIç¿»è¯‘å·²å¯ç”¨ï¼Œä¼˜å…ˆå°è¯•ä½¿ç”¨ '{ai_translator.provider}' è¿›è¡Œç¿»è¯‘...")
        try:
            # ai_translator.translate åº”è¯¥åœ¨å¤±è´¥æ—¶è¿”å› None æˆ–æŠ›å‡ºå¼‚å¸¸
            ai_result = ai_translator.translate(text_stripped)
            if ai_result: # ç¡®ä¿AIè¿”å›äº†æœ‰æ•ˆç»“æœ
                final_translation = ai_result
                final_engine = ai_translator.provider
        except Exception as e_ai:
            # å¦‚æœAIç¿»è¯‘å™¨å†…éƒ¨æŠ›å‡ºå¼‚å¸¸ï¼Œåœ¨è¿™é‡Œæ•è·
            logger.error(f"AIç¿»è¯‘å™¨åœ¨ç¿»è¯‘ '{text_stripped}' æ—¶å‘ç”Ÿå¼‚å¸¸: {e_ai}")
            # ä¸åšä»»ä½•äº‹ï¼Œè®©æµç¨‹ç»§ç»­å¾€ä¸‹èµ°ï¼Œå°è¯•ä¼ ç»Ÿå¼•æ“

    # 5. å¤„ç†åœ¨çº¿ç¿»è¯‘çš„ç»“æœï¼Œå¹¶æ›´æ–°ç¼“å­˜
    if final_translation and final_translation.strip() and final_translation.strip().lower() != text_stripped.lower():
        # ç¿»è¯‘æˆåŠŸï¼Œå­˜å…¥ç¼“å­˜å¹¶è¿”å›ç»“æœ
        logger.info(f"åœ¨çº¿ç¿»è¯‘æˆåŠŸ: '{text_stripped}' -> '{final_translation}' (ä½¿ç”¨å¼•æ“: {final_engine})")
        db_manager.save_translation_to_db(db_cursor, text_stripped, final_translation, final_engine)
        return final_translation
    else:
        # ç¿»è¯‘å¤±è´¥æˆ–è¿”å›åŸæ–‡ï¼Œå°†å¤±è´¥çŠ¶æ€å­˜å…¥ç¼“å­˜ï¼Œå¹¶è¿”å›åŸæ–‡
        logger.warning(f"åœ¨çº¿ç¿»è¯‘æœªèƒ½ç¿»è¯‘ '{text_stripped}' æˆ–è¿”å›äº†åŸæ–‡ (ä½¿ç”¨å¼•æ“: {final_engine})ã€‚")
        db_manager.save_translation_to_db(db_cursor, text_stripped, None, f"failed_or_same_via_{final_engine}")
        return text

# âœ¨âœ¨âœ¨ä»è±†ç“£APIè·å–æŒ‡å®šåª’ä½“çš„æ¼”å‘˜åŸå§‹æ•°æ®åˆ—è¡¨âœ¨âœ¨âœ¨
def find_douban_cast(douban_api: DoubanApi, media_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»è±†ç“£APIè·å–æ¼”å‘˜åŸå§‹æ•°æ®ã€‚"""
        # å‡è®¾ constants å’Œ self.douban_api å·²ç»å­˜åœ¨
        # if not (getattr(constants, 'DOUBAN_API_AVAILABLE', False) and self.douban_api and \
        #         self.data_source_mode in [constants.DOMESTIC_SOURCE_MODE_LOCAL_THEN_ONLINE, constants.DOMESTIC_SOURCE_MODE_ONLINE_ONLY]):
        #     return []
        if not douban_api:
            logger.warning("æœªæä¾› DoubanApi å®ä¾‹ï¼Œæ— æ³•è·å–è±†ç“£æ¼”å‘˜ã€‚")
            return []
        douban_data = douban_api.get_acting(
            name=media_info.get("Name"),
            imdbid=media_info.get("ProviderIds", {}).get("Imdb"),
            mtype="movie" if media_info.get("Type") == "Movie" else ("tv" if media_info.get("Type") == "Series" else None),
            year=str(media_info.get("ProductionYear", "")),
            douban_id_override=media_info.get("ProviderIds", {}).get("Douban")
        )
        if douban_data and not douban_data.get("error") and isinstance(douban_data.get("cast"), list):
            return douban_data["cast"]
        return []

# âœ¨âœ¨âœ¨æ ¼å¼åŒ–ä»è±†ç“£è·å–çš„åŸå§‹æ¼”å‘˜æ•°æ®ï¼Œè¿›è¡Œåˆæ­¥æ¸…ç†å’Œå»é‡ï¼Œä½¿å…¶ç¬¦åˆå†…éƒ¨å¤„ç†æ ¼å¼âœ¨âœ¨âœ¨
def format_douban_cast(douban_api_actors_raw: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    ã€ä¿®å¤ç‰ˆã€‘
    æ ¼å¼åŒ–è±†ç“£åŸå§‹æ¼”å‘˜æ•°æ®å¹¶è¿›è¡Œåˆæ­¥å»é‡ã€‚
    - æ–°å¢ï¼šæå–å¹¶ä¿ç•™è±†ç“£æä¾›çš„ç°æˆå¤´åƒé“¾æ¥ã€‚
    """
    formatted_candidates = []
    seen_douban_ids = set()
    seen_names = set()

    if not douban_api_actors_raw:
        return formatted_candidates

    for item in douban_api_actors_raw:
        name_zh = str(item.get("name", "")).strip()
        if not name_zh: 
            continue
            
        douban_id = str(item.get("id", "")).strip() or None

        # ã€ä¸¥æ ¼çš„å»é‡é€»è¾‘ã€‘
        if douban_id and douban_id in seen_douban_ids:
            continue
        if name_zh in seen_names:
            continue

        if douban_id:
            seen_douban_ids.add(douban_id)
        seen_names.add(name_zh)
        
        # â–¼â–¼â–¼ æ ¸å¿ƒæ–°å¢ï¼šä»ç¼“å­˜ä¸­å®‰å…¨åœ°æå–å¤´åƒé“¾æ¥ â–¼â–¼â–¼
        avatar_url = (item.get("avatar", {}) or {}).get("large")
        # â–²â–²â–² æ–°å¢ç»“æŸ â–²â–²â–²

        formatted_candidates.append({
            "Name": name_zh,
            # ä¿®æ­£ï¼šæ ¹æ®ä½ æä¾›çš„JSONï¼Œå­—æ®µåº”ä¸º latin_name
            "OriginalName": str(item.get("latin_name", "")).strip(), 
            "Role": str(item.get("character", "")).strip(),
            "DoubanCelebrityId": douban_id,
            "ProviderIds": {"Douban": douban_id} if douban_id else {},
            # æ–°å¢å­—æ®µï¼Œå°†å¤´åƒé“¾æ¥ä¼ é€’ä¸‹å»
            "DoubanAvatarUrl": avatar_url 
        })
        
    return formatted_candidates

# âœ¨âœ¨âœ¨æ ¼å¼åŒ–æ¼”å‘˜è¡¨âœ¨âœ¨âœ¨
def format_and_complete_cast_list(
    cast_list: List[Dict[str, Any]], 
    is_animation: bool, 
    config: Dict[str, Any],
    mode: str = 'auto'  # â˜…â˜…â˜… æ ¸å¿ƒå‚æ•°: 'auto' æˆ– 'manual' â˜…â˜…â˜…
) -> List[Dict[str, Any]]:
    """
    ã€V9 - æœ€ç»ˆç­–ç•¥ç‰ˆã€‘æ ¹æ®è°ƒç”¨æ¨¡å¼æ ¼å¼åŒ–å¹¶æ’åºæ¼”å‘˜åˆ—è¡¨ã€‚
    - 'auto': è‡ªåŠ¨å¤„ç†æµç¨‹ã€‚ä¸¥æ ¼æŒ‰åŸå§‹TMDbçš„ 'order' å­—æ®µæ’åºã€‚
    - 'manual': æ‰‹åŠ¨ç¼–è¾‘æµç¨‹ã€‚ä»¥ä¼ å…¥åˆ—è¡¨çš„é¡ºåºä¸ºåŸºå‡†ï¼Œå¹¶å°†é€šç”¨è§’è‰²æ’åˆ°æœ«å°¾ã€‚
    """
    processed_cast = []
    add_role_prefix = config.get(constants.CONFIG_OPTION_ACTOR_ROLE_ADD_PREFIX, False)
    generic_roles = {"æ¼”å‘˜", "é…éŸ³"}

    logger.debug(f"  âœ æ ¼å¼åŒ–æ¼”å‘˜åˆ—è¡¨ï¼Œè°ƒç”¨æ¨¡å¼: '{mode}' (å‰ç¼€å¼€å…³: {'å¼€' if add_role_prefix else 'å…³'})")
    # --- é˜¶æ®µ1: ç»Ÿä¸€çš„è§’è‰²åæ ¼å¼åŒ– (æ‰€æœ‰æ¨¡å¼é€šç”¨) ---
    for idx, actor in enumerate(cast_list):
        new_actor = actor.copy()
        
        # (è§’è‰²åå¤„ç†é€»è¾‘ä¿æŒä¸å˜)
        character_name = new_actor.get("character")
        final_role = character_name.strip() if character_name else ""
        if utils.contains_chinese(final_role):
            final_role = final_role.replace(" ", "").replace("ã€€", "")
        if add_role_prefix:
            if final_role and final_role not in generic_roles:
                prefix = "é… " if is_animation else "é¥° "
                final_role = f"{prefix}{final_role}"
            elif not final_role:
                final_role = "é…éŸ³" if is_animation else "æ¼”å‘˜"
        else:
            if not final_role:
                final_role = "é…éŸ³" if is_animation else "æ¼”å‘˜"
        new_actor["character"] = final_role
        
        # ä¸º 'manual' æ¨¡å¼è®°å½•åŸå§‹é¡ºåº
        new_actor['original_index'] = idx
        
        processed_cast.append(new_actor)

    # --- é˜¶æ®µ2: æ ¹æ®æ¨¡å¼æ‰§è¡Œä¸åŒçš„æ’åºç­–ç•¥ ---
    if mode == 'manual':
        # ã€æ‰‹åŠ¨æ¨¡å¼ã€‘ï¼šä»¥ç”¨æˆ·è‡ªå®šä¹‰é¡ºåºä¸ºåŸºç¡€ï¼Œå¹¶å¢å¼ºï¼ˆé€šç”¨è§’è‰²åç½®ï¼‰
        logger.debug("  âœ åº”ç”¨ 'manual' æ’åºç­–ç•¥ï¼šä¿ç•™ç”¨æˆ·è‡ªå®šä¹‰é¡ºåºï¼Œå¹¶å°†é€šç”¨è§’è‰²åç½®ã€‚")
        processed_cast.sort(key=lambda actor: (
            1 if actor.get("character") in generic_roles else 0,  # 1. é€šç”¨è§’è‰²æ’åœ¨åé¢
            actor.get("original_index")                          # 2. åœ¨æ­¤åŸºç¡€ä¸Šï¼Œä¿æŒåŸå§‹æ‰‹åŠ¨é¡ºåº
        ))
    else: # mode == 'auto' æˆ–å…¶ä»–ä»»ä½•é»˜è®¤æƒ…å†µ
        # ã€è‡ªåŠ¨æ¨¡å¼ã€‘ï¼šä¸¥æ ¼æŒ‰ç…§TMDbåŸå§‹çš„ 'order' å­—æ®µæ’åº
        logger.debug("  âœ åº”ç”¨ 'auto' æ’åºç­–ç•¥ï¼šä¸¥æ ¼æŒ‰åŸå§‹TMDb 'order' å­—æ®µæ’åºã€‚")
        processed_cast.sort(key=lambda actor: actor.get('order', 999))
        
    # --- é˜¶æ®µ3: æœ€ç»ˆé‡ç½® order ç´¢å¼• (æ‰€æœ‰æ¨¡å¼é€šç”¨) ---
    for new_idx, actor in enumerate(processed_cast):
        actor["order"] = new_idx
        if 'original_index' in actor:
            del actor['original_index'] # æ¸…ç†ä¸´æ—¶key
            
    return processed_cast

# --- ç”¨äºè·å–å•ä¸ªæ¼”å‘˜çš„TMDbè¯¦æƒ… ---
def fetch_tmdb_details_for_actor(actor_info: Dict, tmdb_api_key: str) -> Optional[Dict]:
    """ä¸€ä¸ªç‹¬ç«‹çš„ã€å¯åœ¨çº¿ç¨‹ä¸­è¿è¡Œçš„å‡½æ•°ï¼Œç”¨äºè·å–å•ä¸ªæ¼”å‘˜çš„TMDbè¯¦æƒ…ã€‚"""
    tmdb_id = actor_info.get("tmdb_person_id")
    if not tmdb_id:
        return None
    try:
        details = tmdb.get_person_details_tmdb(
            person_id=int(tmdb_id), 
            api_key=tmdb_api_key, 
            append_to_response="external_ids,translations"
        )
        if details:
            # æˆåŠŸè·å–ï¼Œè¿”å›è¯¦æƒ…
            return {"tmdb_id": tmdb_id, "status": "found", "details": details}
        else:
            # APIè°ƒç”¨æˆåŠŸä½†è¿”å›ç©ºï¼Œä¹Ÿæ ‡è®°ä¸ºæœªæ‰¾åˆ°
            return {"tmdb_id": tmdb_id, "status": "not_found"}

    except tmdb.TMDbResourceNotFound:
        # â˜…â˜…â˜… æ•è·åˆ°404å¼‚å¸¸ï¼Œè¿”å›ä¸€ä¸ªæ˜ç¡®çš„â€œæœªæ‰¾åˆ°â€çŠ¶æ€ â˜…â˜…â˜…
        return {"tmdb_id": tmdb_id, "status": "not_found"}
    
    except tmdb.TMDbAPIError as e:
        # å…¶ä»–APIé”™è¯¯ï¼ˆå¦‚ç½‘ç»œé—®é¢˜ï¼‰ï¼Œè®°å½•æ—¥å¿—å¹¶è¿”å›å¤±è´¥çŠ¶æ€
        logger.warning(f"è·å–æ¼”å‘˜ {tmdb_id} è¯¦æƒ…æ—¶é‡åˆ°APIé”™è¯¯: {e}")
        return {"tmdb_id": tmdb_id, "status": "failed"}

# --- æ¼”å‘˜æ•°æ®è¡¥å…… ---

def enrich_all_actor_aliases_task(
    tmdb_api_key: str, 
    run_duration_minutes: int,
    sync_interval_days: int,
    stop_event: Optional[threading.Event] = None,
    update_status_callback: Optional[Callable] = None,
    force_full_update: bool = False
):
    """
    - è§£å†³äº†åœ¨åˆå¹¶IMDbå†²çªè®°å½•æ—¶ï¼Œç”±äºemby_person_idç­‰å…¶ä»–IDå·²å­˜åœ¨äºç¬¬ä¸‰æ–¹è®°å½•è€Œå¯¼è‡´çš„äºŒæ¬¡å”¯ä¸€é”®å†²çªã€‚
    - åˆå¹¶é€»è¾‘ç°åœ¨ä¼šé¢„å…ˆæ£€æŸ¥æ¯ä¸ªå¾…åˆå¹¶çš„IDï¼Œå¦‚æœå‘ç°æ–°å†²çªï¼Œä¼šå°è¯•å°†å†²çªçš„IDä»å…¶æ—§è®°å½•ä¸­å‰¥ç¦»ï¼Œå†èµ‹ç»™æ–°è®°å½•ã€‚
    - å¢å¼ºäº†æ—¥å¿—è®°å½•ï¼Œæ¸…æ™°åœ°å±•ç¤ºäº†æ¯ä¸€æ­¥åˆå¹¶å†³ç­–ã€‚
    - ä¿æŒäº†åŸæœ‰çš„ä¸‰é˜¶æ®µå¤„ç†ï¼ˆTMDbå…ƒæ•°æ®ã€è±†ç“£IMDbã€è±†ç“£å¤´åƒï¼‰ã€‚
    """
    task_mode = "(å…¨é‡)" if force_full_update else "(å¢é‡)"
    logger.info(f"--- å¼€å§‹æ‰§è¡Œâ€œæ¼”å‘˜æ•°æ®è¡¥å……â€è®¡åˆ’ä»»åŠ¡ [{task_mode}] ---")

    if update_status_callback:
        update_status_callback(0, "æ¼”å‘˜æ•°æ®è¡¥å……ä»»åŠ¡å¼€å§‹")

    start_time = time.time()
    end_time = float('inf')
    if run_duration_minutes > 0:
        end_time = start_time + run_duration_minutes * 60
        end_time_str = datetime.fromtimestamp(end_time).strftime('%Y-%m-%d %H:%M:%S')
        logger.info(f"  âœ ä»»åŠ¡å°†è¿è¡Œ {run_duration_minutes} åˆ†é’Ÿï¼Œé¢„è®¡åœ¨ {end_time_str} å·¦å³è‡ªåŠ¨åœæ­¢ã€‚")

    SYNC_INTERVAL_DAYS = sync_interval_days
    logger.info(f"  âœ åŒæ­¥å†·å´æ—¶é—´ä¸º {SYNC_INTERVAL_DAYS} å¤©ã€‚")

    conn = None
    douban_api = None
    try:
        douban_api = DoubanApi()

        with connection.get_db_connection() as conn:
            # --- é˜¶æ®µä¸€ï¼šä» TMDb è¡¥å……å…ƒæ•°æ® (å¹¶å‘æ‰§è¡Œ) ---
            logger.info("  âœ é˜¶æ®µä¸€ï¼šä» TMDb è¡¥å……æ¼”å‘˜å…ƒæ•°æ® (IMDb ID, å¤´åƒç­‰) ---")
            cursor = conn.cursor()
            
            if force_full_update:
                logger.info("  âœ æ·±åº¦æ¨¡å¼å·²æ¿€æ´»ï¼šå°†æ‰«ææ‰€æœ‰æ¼”å‘˜ï¼Œæ— è§†ç°æœ‰æ•°æ®ã€‚")
                sql_find_actors = """
                    SELECT p.* FROM person_identity_map p
                    LEFT JOIN actor_metadata m ON p.tmdb_person_id = m.tmdb_id
                    WHERE p.tmdb_person_id IS NOT NULL
                    ORDER BY m.last_updated_at ASC NULLS FIRST
                """
            else:
                logger.info(f"  âœ æ ‡å‡†æ¨¡å¼ï¼šå°†ä»…æ‰«æéœ€è¦è¡¥å……æ•°æ®ä¸”å†·å´æœŸå·²è¿‡çš„æ¼”å‘˜ (å†·å´æœŸ: {sync_interval_days} å¤©)ã€‚")
                sql_find_actors = f"""
                    SELECT p.* FROM person_identity_map p
                    LEFT JOIN actor_metadata m ON p.tmdb_person_id = m.tmdb_id
                    WHERE p.tmdb_person_id IS NOT NULL AND (p.imdb_id IS NULL OR m.tmdb_id IS NULL OR m.profile_path IS NULL OR m.gender IS NULL OR m.original_name IS NULL)
                    AND (m.last_updated_at IS NULL OR m.last_updated_at < NOW() - INTERVAL '{sync_interval_days} days')
                    ORDER BY m.last_updated_at ASC
                """
            
            cursor.execute(sql_find_actors)
            actors_for_tmdb = cursor.fetchall()
            
            if actors_for_tmdb:
                total_tmdb = len(actors_for_tmdb)
                logger.info(f"  âœ æ‰¾åˆ° {total_tmdb} ä½æ¼”å‘˜éœ€è¦ä» TMDb è¡¥å……å…ƒæ•°æ®ã€‚")
                
                CHUNK_SIZE = 200
                MAX_TMDB_WORKERS = 5

                for i in range(0, total_tmdb, CHUNK_SIZE):
                    if (stop_event and stop_event.is_set()) or (time.time() >= end_time):
                        logger.info("  ğŸš« è¾¾åˆ°è¿è¡Œæ—¶é•¿æˆ–æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œåœ¨ TMDb ä¸‹æ‰¹æ¬¡å¼€å§‹å‰ç»“æŸã€‚")
                        break

                    progress = int((i / total_tmdb) * 100)
                    chunk_num = i//CHUNK_SIZE + 1
                    total_chunks = (total_tmdb + CHUNK_SIZE - 1) // CHUNK_SIZE
                    if update_status_callback:
                        update_status_callback(progress, f"å¤„ç†æ‰¹æ¬¡ {chunk_num}/{total_chunks}")

                    chunk = actors_for_tmdb[i:i + CHUNK_SIZE]
                    logger.info(f"  âœ å¼€å§‹å¤„ç† TMDb ç¬¬ {chunk_num} æ‰¹æ¬¡ï¼Œå…± {len(chunk)} ä¸ªæ¼”å‘˜ ---")

                    imdb_updates_to_commit = []
                    metadata_to_commit = []
                    invalid_tmdb_ids = []
                    
                    tmdb_success_count, imdb_found_count, metadata_added_count, not_found_count = 0, 0, 0, 0

                    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_TMDB_WORKERS) as executor:
                        future_to_actor = {executor.submit(fetch_tmdb_details_for_actor, dict(actor), tmdb_api_key): actor for actor in chunk}
                        
                        for future in concurrent.futures.as_completed(future_to_actor):
                            if stop_event and stop_event.is_set():
                                for f in future_to_actor: f.cancel()
                                raise InterruptedError("ä»»åŠ¡åœ¨TMDbå¤„ç†æ‰¹æ¬¡ä¸­è¢«ä¸­æ­¢")

                            result = future.result()
                            if not result: continue

                            status = result.get("status")
                            tmdb_id = result.get("tmdb_id")
                            details = result.get("details", {})

                            if status == "found" and details:
                                tmdb_success_count += 1
                                imdb_id = details.get("external_ids", {}).get("imdb_id")
                                if imdb_id:
                                    imdb_found_count += 1
                                    imdb_updates_to_commit.append((imdb_id, tmdb_id))
                                
                                best_original_name = None
                                if details.get("english_name_from_translations"):
                                    best_original_name = details.get("english_name_from_translations")
                                elif details.get("original_name") and not contains_chinese(details.get("original_name")):
                                    best_original_name = details.get("original_name")
                                
                                metadata_entry = {
                                    "tmdb_id": tmdb_id,
                                    "profile_path": details.get("profile_path"),
                                    "gender": details.get("gender"),
                                    "adult": details.get("adult", False),
                                    "popularity": details.get("popularity"),
                                    "original_name": best_original_name
                                }
                                metadata_to_commit.append(metadata_entry)
                                metadata_added_count += 1
                            
                            elif status == "not_found":
                                not_found_count += 1
                                invalid_tmdb_ids.append(tmdb_id)

                    logger.info(
                        f"  âœ æ‰¹æ¬¡å¤„ç†å®Œæˆã€‚æ‘˜è¦: "
                        f"æˆåŠŸè·å–({tmdb_success_count}), æ–°å¢IMDb({imdb_found_count}), "
                        f"æ–°å¢å…ƒæ•°æ®({metadata_added_count}), æœªæ‰¾åˆ°({not_found_count})."
                    )
                    
                    if imdb_updates_to_commit or metadata_to_commit or invalid_tmdb_ids:
                        try:
                            logger.info(f"  âœ æ‰¹æ¬¡å®Œæˆï¼Œå‡†å¤‡å†™å…¥æ•°æ®åº“...")

                            if metadata_to_commit:
                                cols = metadata_to_commit[0].keys()
                                cols_str = ", ".join(cols)
                                placeholders_str = ", ".join([f"%({k})s" for k in cols])
                                update_cols = [f"{col} = EXCLUDED.{col}" for col in cols if col != 'tmdb_id']
                                update_str = ", ".join(update_cols)
                                
                                sql_upsert_metadata = f"""
                                    INSERT INTO actor_metadata ({cols_str}, last_updated_at)
                                    VALUES ({placeholders_str}, NOW())
                                    ON CONFLICT (tmdb_id) DO UPDATE SET {update_str}, last_updated_at = NOW()
                                """
                                cursor.executemany(sql_upsert_metadata, metadata_to_commit)
                                logger.trace(f"  âœ æˆåŠŸæ‰¹é‡å†™å…¥ {len(metadata_to_commit)} æ¡æ¼”å‘˜å…ƒæ•°æ®ã€‚")

                            for imdb_id, tmdb_id in imdb_updates_to_commit:
                                try:
                                    cursor.execute("SAVEPOINT imdb_update_savepoint")
                                    cursor.execute("UPDATE person_identity_map SET imdb_id = %s WHERE tmdb_person_id = %s", (imdb_id, tmdb_id))
                                    cursor.execute("RELEASE SAVEPOINT imdb_update_savepoint")
                                except psycopg2.IntegrityError as ie:
                                    cursor.execute("ROLLBACK TO SAVEPOINT imdb_update_savepoint")
                                    if "violates unique constraint" in str(ie) and "imdb_id" in str(ie):
                                        logger.warning(f"  âœ [åˆå¹¶é€»è¾‘] æ£€æµ‹åˆ° IMDb ID '{imdb_id}' (æ¥è‡ªTMDb: {tmdb_id}) å†²çªã€‚")
                                        
                                        cursor.execute("SELECT * FROM person_identity_map WHERE imdb_id = %s", (imdb_id,))
                                        target_actor = cursor.fetchone()
                                        cursor.execute("SELECT * FROM person_identity_map WHERE tmdb_person_id = %s", (tmdb_id,))
                                        source_actor = cursor.fetchone()

                                        if not target_actor or not source_actor or source_actor['map_id'] == target_actor['map_id']:
                                            logger.warning(f"  ğŸš« åˆå¹¶ä¸­æ­¢ï¼šæºæˆ–ç›®æ ‡è®°å½•ä¸å­˜åœ¨ï¼Œæˆ–å®ƒä»¬æœ¬å°±æ˜¯åŒä¸€æ¡è®°å½•ã€‚")
                                            continue

                                        target_map_id = target_actor['map_id']
                                        source_map_id = source_actor['map_id']
                                        logger.info(f"  âœ å‡†å¤‡åˆå¹¶ï¼šæº(map_id:{source_map_id}, tmdb:{tmdb_id}) -> ç›®æ ‡(map_id:{target_map_id}, imdb:{imdb_id})")

                                        # --- å®šä¹‰ä¸€ä¸ªå¯é‡ç”¨çš„ã€å®‰å…¨çš„IDåˆå¹¶å‡½æ•° ---
                                        def safe_merge_id(id_field_name: str, id_value: Any, source_id: int, target_id: int):
                                            if not id_value or target_actor.get(id_field_name):
                                                return # å¦‚æœæºIDä¸ºç©ºï¼Œæˆ–ç›®æ ‡å·²æœ‰åŒç±»IDï¼Œåˆ™ä¸åˆå¹¶

                                            # é¢„æ£€æŸ¥ï¼šè¿™ä¸ªIDæ˜¯å¦å·²å­˜åœ¨äºå…¶ä»–è®°å½•ä¸­ï¼Ÿ
                                            cursor.execute(f"SELECT map_id FROM person_identity_map WHERE {id_field_name} = %s", (id_value,))
                                            conflicting_record = cursor.fetchone()
                                            
                                            if conflicting_record and conflicting_record['map_id'] != target_id:
                                                # å­˜åœ¨å†²çªï¼è¿™ä¸ªIDå±äºå¦ä¸€ä¸ªè®°å½•ã€‚æˆ‘ä»¬éœ€è¦å…ˆæŠŠå®ƒä»æ—§è®°å½•ä¸Šå‰¥ç¦»ã€‚
                                                logger.warning(f"  âœ æ£€æµ‹åˆ° {id_field_name} '{id_value}' å­˜åœ¨äºç¬¬ä¸‰æ–¹è®°å½• (map_id: {conflicting_record['map_id']})ã€‚å°†ä»æ—§è®°å½•ä¸­ç§»é™¤ã€‚")
                                                cursor.execute(f"UPDATE person_identity_map SET {id_field_name} = NULL WHERE map_id = %s", (conflicting_record['map_id'],))

                                            # ç°åœ¨å¯ä»¥å®‰å…¨åœ°æ›´æ–°åˆ°ç›®æ ‡è®°å½•äº†
                                            logger.info(f"  âœ æ­£åœ¨å°† {id_field_name} '{id_value}' åˆå¹¶åˆ°ç›®æ ‡è®°å½• (map_id: {target_id})ã€‚")
                                            cursor.execute(f"UPDATE person_identity_map SET {id_field_name} = %s WHERE map_id = %s", (id_value, target_id))

                                        # --- ä¾æ¬¡å®‰å…¨åœ°åˆå¹¶å„ä¸ªID ---
                                        # 1. åˆå¹¶ TMDb ID
                                        safe_merge_id('tmdb_person_id', source_actor.get('tmdb_person_id'), source_map_id, target_map_id)
                                        # 2. åˆå¹¶ Douban ID
                                        safe_merge_id('douban_celebrity_id', source_actor.get('douban_celebrity_id'), source_map_id, target_map_id)
                                        # 3. åˆå¹¶ Emby ID
                                        safe_merge_id('emby_person_id', source_actor.get('emby_person_id'), source_map_id, target_map_id)

                                        # 4. æœ€åï¼Œåˆ é™¤ç°åœ¨å·²ç»ä¸ºç©ºå£³çš„æºè®°å½•
                                        logger.info(f"  âœ æ‰€æœ‰IDåˆå¹¶å®Œæˆï¼Œå‡†å¤‡åˆ é™¤æºè®°å½• (map_id: {source_map_id})ã€‚")
                                        cursor.execute("DELETE FROM person_identity_map WHERE map_id = %s", (source_map_id,))
                                        logger.info(f"  âœ æˆåŠŸå°†è®°å½• (map_id:{source_map_id}) åˆå¹¶åˆ° (map_id:{target_map_id})ã€‚")
                                    else:
                                        # å¦‚æœæ˜¯å…¶ä»–ç±»å‹çš„å”¯ä¸€é”®å†²çªï¼Œåˆ™é‡æ–°æŠ›å‡ºå¼‚å¸¸
                                        raise ie

                            if invalid_tmdb_ids:
                                cursor.executemany("UPDATE person_identity_map SET tmdb_person_id = NULL WHERE tmdb_person_id = %s", [(tid,) for tid in invalid_tmdb_ids])

                            conn.commit()
                            logger.info("  âœ… æ•°æ®åº“æ›´æ”¹å·²æˆåŠŸæäº¤ã€‚")

                        except Exception as db_e:
                            logger.error(f"  âœ æ•°æ®åº“æ“ä½œå¤±è´¥: {db_e}", exc_info=True)
                            conn.rollback()
            else:
                logger.info("  âœ æ²¡æœ‰éœ€è¦ä» TMDb è¡¥å……æˆ–æ¸…ç†çš„æ¼”å‘˜ã€‚")

    except InterruptedError:
        logger.info("  ğŸš« æ¼”å‘˜æ•°æ®è¡¥å……ä»»åŠ¡è¢«ä¸­æ­¢ã€‚")
        if conn: conn.rollback()
    except Exception as e:
        logger.error(f"  âœ æ¼”å‘˜æ•°æ®è¡¥å……ä»»åŠ¡å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        if conn: conn.rollback()
    finally:
        # å°†å…³é—­æ“ä½œç§»åˆ° finally å—ï¼Œç¡®ä¿æ— è®ºå¦‚ä½•éƒ½èƒ½æ‰§è¡Œ
        if douban_api:
            douban_api.close()
        if update_status_callback:
            update_status_callback(100, "æ¼”å‘˜æ•°æ®è¡¥å……ä»»åŠ¡å®Œæˆ")
        logger.trace("--- â€œæ¼”å‘˜æ•°æ®è¡¥å……â€è®¡åˆ’ä»»åŠ¡å·²é€€å‡º ---")
