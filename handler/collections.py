# handler/collections.py

import logging
import json
from typing import Dict, List, Any, Set
from datetime import datetime
import concurrent.futures

# å¯¼å…¥æ•°æ®è®¿é—®å±‚å’Œå¤–éƒ¨ API å¤„ç†å™¨
from database import collection_db, media_db, request_db
import handler.emby as emby
import handler.tmdb as tmdb
import config_manager

logger = logging.getLogger(__name__)

def sync_and_subscribe_native_collections(progress_callback=None):
    """
    æ‰«æ Emby åˆé›†ã€‚
    """
    if progress_callback:
        progress_callback(0, "æ­£åœ¨è¿žæŽ¥ Emby èŽ·å–åˆé›†åˆ—è¡¨...")

    logger.info("--- å¼€å§‹æ‰§è¡ŒåŽŸç”Ÿåˆé›†æ‰«æä»»åŠ¡ ---")
    
    config = config_manager.APP_CONFIG
    tmdb_api_key = config.get("tmdb_api_key")
    
    # 1. èŽ·å– Emby åˆé›†
    emby_collections = emby.get_all_native_collections_from_emby(
        base_url=config.get('emby_server_url'),
        api_key=config.get('emby_api_key'),
        user_id=config.get('emby_user_id')
    )
    
    libraries_to_process = config.get("libraries_to_process", [])
    if libraries_to_process:
        emby_collections = [c for c in emby_collections if c.get('ParentId') in libraries_to_process]
    
    total_collections = len(emby_collections)
    if total_collections == 0:
        if progress_callback: progress_callback(100, "æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„åˆé›†ã€‚")
        return

    if progress_callback:
        progress_callback(5, f"å…±æ‰¾åˆ° {total_collections} ä¸ªåˆé›†ï¼Œå¼€å§‹å¹¶å‘èŽ·å– TMDb è¯¦æƒ…...")

    # 2. å¹¶å‘èŽ·å– TMDb è¯¦æƒ…
    collection_tmdb_details_map = {}
    
    def fetch_tmdb_details(collection):
        tmdb_coll_id = collection.get('tmdb_collection_id')
        if not tmdb_coll_id: return None, None, collection.get('name')
        # è¿”å›ž emby_id, details, name ä»¥ä¾¿å›žè°ƒä½¿ç”¨
        return collection.get('emby_collection_id'), tmdb.get_collection_details(tmdb_coll_id, tmdb_api_key), collection.get('name')

    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_to_coll = {executor.submit(fetch_tmdb_details, c): c for c in emby_collections}
        
        finished_count = 0
        
        for future in concurrent.futures.as_completed(future_to_coll):
            finished_count += 1
            coll_name = "æœªçŸ¥"
            try:
                emby_id, details, name = future.result()
                coll_name = name or "æœªçŸ¥"
                if emby_id and details and 'parts' in details:
                    collection_tmdb_details_map[emby_id] = details
            except Exception as e:
                logger.warning(f"èŽ·å–åˆé›†è¯¦æƒ…å¤±è´¥: {e}")
            
            if progress_callback:
                percent = 5 + int((finished_count / total_collections) * 85)
                percent = min(percent, 90)
                progress_callback(percent, f"æ­£åœ¨èŽ·å– TMDb ({finished_count}/{total_collections}): {coll_name}")

    if progress_callback:
        progress_callback(90, "TMDb æ•°æ®èŽ·å–å®Œæ¯•ï¼Œå¼€å§‹å†™å…¥æ•°æ®åº“...")

    for i, collection in enumerate(emby_collections):
        if progress_callback:
            percent = 90 + int(((i + 1) / total_collections) * 10)
            percent = min(percent, 99)
            progress_callback(percent, f"æ­£åœ¨å…¥åº“ ({i+1}/{total_collections}): {collection.get('name')}")

        emby_collection_id = collection.get('emby_collection_id')
        tmdb_details = collection_tmdb_details_map.get(emby_collection_id)
        
        if not tmdb_details: continue

        # A. æå–æ•°æ®
        all_parts = []
        all_tmdb_ids = []
        
        for part in tmdb_details.get('parts', []):
            if not part.get('poster_path') or not part.get('release_date'): continue
            
            t_id = str(part['id'])
            all_parts.append({
                'tmdb_id': t_id,
                'title': part['title'],
                'original_title': part.get('original_title'),
                'release_date': part['release_date'],
                'poster_path': part['poster_path'],
                'overview': part.get('overview')
            })
            all_tmdb_ids.append(t_id)

        if not all_tmdb_ids: continue

        # B. ç¡®ä¿ media_metadata å­˜åœ¨åŸºç¡€æ•°æ®
        media_db.batch_ensure_basic_movies(all_parts)

        # C. å†™å…¥åˆé›†å…³ç³»è¡¨
        collection_db.upsert_native_collection({
            'emby_collection_id': emby_collection_id,
            'name': collection.get('name'),
            'tmdb_collection_id': collection.get('tmdb_collection_id'),
            'poster_path': tmdb_details.get('poster_path'),
            'all_tmdb_ids': all_tmdb_ids
        })

    logger.info("--- åŽŸç”Ÿåˆé›†æ‰«æå®Œæˆ ---")
    if progress_callback:
        progress_callback(100, "åŽŸç”Ÿåˆé›†æ‰«æå®Œæˆï¼")
    
    # æ‰«æå®Œå¼€å§‹æ£€æŸ¥ç¼ºå¤±æ ‡è®°å¾…è®¢é˜…
    subscribe_all_missing_in_native_collections()

def subscribe_all_missing_in_native_collections():
    """
    æŠŠæ‰€æœ‰åŽŸç”Ÿåˆé›†ä¸­ç¼ºå¤±çš„ç”µå½±åŠ å…¥å¾…è®¢é˜…åˆ—è¡¨ã€‚
    (ä¿®å¤ç‰ˆï¼šæŒ‰åˆé›†åç§°åˆ†ç»„æäº¤ï¼Œç¡®ä¿æ¥æºæ ‡è®°æ­£ç¡®)
    """
    logger.info("--- å¼€å§‹æ‰§è¡ŒåŽŸç”Ÿåˆé›†ç¼ºå¤±ç”µå½±æ‰¹é‡å¾…è®¢é˜… ---")
    
    # 1. ä¸€æ¬¡æ€§æ‹¿åˆ°æ‰€æœ‰ç¼ºå¤±çš„ç”µå½±
    missing_movies = collection_db.get_all_missing_movies_in_collections()
    
    if not missing_movies:
        logger.info("  âžœ æ²¡æœ‰å‘çŽ°éœ€è¦è®¢é˜…çš„ç¼ºå¤±ç”µå½±ã€‚")
        return {'subscribed_count': 0, 'skipped_count': 0, 'quota_exceeded': False}

    today_str = datetime.now().strftime('%Y-%m-%d')
    
    # ä½¿ç”¨å­—å…¸æŒ‰åˆé›†åç§°åˆ†ç»„: { 'åˆé›†å': {'released': [], 'unreleased': []} }
    grouped_requests = {}
    
    # 2. éåŽ†å¹¶åˆ†ç»„
    for movie in missing_movies:
        # å¤„ç†æ—¥æœŸç±»åž‹
        r_date = movie.get('release_date')
        r_date_str = str(r_date) if r_date else None
        
        # èŽ·å–åˆé›†åç§°ä½œä¸ºåˆ†ç»„é”®
        coll_names = movie.get('collection_names', 'åŽŸç”Ÿåˆé›†')
        
        # åˆå§‹åŒ–è¯¥åˆé›†çš„åˆ—è¡¨
        if coll_names not in grouped_requests:
            grouped_requests[coll_names] = {'released': [], 'unreleased': []}

        # æž„é€ æ ‡å‡† media_info
        media_info = {
            'tmdb_id': movie['tmdb_id'],
            'title': movie['title'],
            'original_title': movie.get('original_title'),
            'release_date': r_date_str,
            'poster_path': movie.get('poster_path'),
            'overview': movie.get('overview'),
            'source': {
                'type': 'native_collection',  
                'name': coll_names                  
            }
        }

        # æ ¹æ®ä¸Šæ˜ æ—¥æœŸæ”¾å…¥å¯¹åº”åˆ—è¡¨
        if r_date_str and r_date_str > today_str:
            grouped_requests[coll_names]['unreleased'].append(media_info)
        else:
            grouped_requests[coll_names]['released'].append(media_info)

    total_count = 0
    
    # 3. æŒ‰åˆé›†åˆ†æ‰¹å†™å…¥ request_db
    for coll_name, queues in grouped_requests.items():
        # æž„é€ è¯¥æ‰¹æ¬¡çš„æ¥æºå¯¹è±¡
        batch_source = {
            'type': 'native_collection',
            'name': coll_name
        }

        # å¤„ç†å·²ä¸Šæ˜ 
        released_list = queues['released']
        if released_list:
            count = len(released_list)
            total_count += count
            logger.info(f"  âžœ [{coll_name}] æ‰¹é‡å¾…è®¢é˜…: {count} éƒ¨å·²ä¸Šæ˜ ç”µå½±è®¾ä¸º WANTED...")
            request_db.set_media_status_wanted(
                tmdb_ids=[m['tmdb_id'] for m in released_list],
                item_type='Movie',
                source=batch_source, # ä¿®å¤ï¼šä½¿ç”¨å½“å‰å¾ªçŽ¯çš„åˆé›†åä½œä¸ºæ¥æº
                media_info_list=released_list
            )

        # å¤„ç†æœªä¸Šæ˜ 
        unreleased_list = queues['unreleased']
        if unreleased_list:
            count = len(unreleased_list)
            total_count += count
            logger.info(f"  âžœ [{coll_name}] æ‰¹é‡å¾…è®¢é˜…: {count} éƒ¨æœªä¸Šæ˜ ç”µå½±è®¾ä¸º PENDING_RELEASE...")
            request_db.set_media_status_pending_release(
                tmdb_ids=[m['tmdb_id'] for m in unreleased_list],
                item_type='Movie',
                source=batch_source, # ä¿®å¤ï¼šä½¿ç”¨å½“å‰å¾ªçŽ¯çš„åˆé›†åä½œä¸ºæ¥æº
                media_info_list=unreleased_list
            )

    logger.info(f"--- æ‰¹é‡å¾…è®¢é˜…å®Œæˆï¼Œå…±å¤„ç† {total_count} éƒ¨ç”µå½± ---")
    
    return {
        'subscribed_count': total_count, 
        'skipped_count': 0, 
        'quota_exceeded': False
    }

def assemble_all_collection_details() -> List[Dict[str, Any]]:
    """
    ã€V5 - åŠ¨æ€ç»Ÿè®¡ç‰ˆã€‘
    è¯»å–æ—¶ï¼Œæ ¹æ® ID åˆ—è¡¨å®žæ—¶åŽ» media_metadata ç»Ÿè®¡ ç¼ºå¤±/å…¥åº“/è®¢é˜…/æœªä¸Šæ˜  æ•°é‡ã€‚
    """
    logger.info("--- å¼€å§‹ç»„è£…åŽŸç”Ÿåˆé›†è¯¦æƒ… (åŠ¨æ€ç»Ÿè®¡) ---")
    
    all_collections = collection_db.get_all_native_collections()
    if not all_collections: return []

    # 1. æ”¶é›†æ‰€æœ‰ ID
    global_tmdb_ids = set()
    for coll in all_collections:
        ids = coll.get('all_tmdb_ids_json')
        if ids:
            if isinstance(ids, str):
                try: ids = json.loads(ids)
                except: ids = []
            coll['parsed_ids'] = ids
            global_tmdb_ids.update(ids)
        else:
            coll['parsed_ids'] = []

    if not global_tmdb_ids: return all_collections

    # 2. æ‰¹é‡èŽ·å–å…ƒæ•°æ®
    media_details_map = media_db.get_media_details_by_tmdb_ids(list(global_tmdb_ids))
    today_str = datetime.now().strftime('%Y-%m-%d')

    # 3. åŠ¨æ€è®¡ç®—ç»Ÿè®¡æ•°æ®
    for coll in all_collections:
        # åˆå§‹åŒ–è®¡æ•°å™¨
        stats = {
            'missing': 0,
            'in_library': 0,
            'subscribed': 0,
            'unreleased': 0
        }
        
        final_movies = []
        
        for tmdb_id in coll['parsed_ids']:
            tmdb_id_str = str(tmdb_id)
            item = media_details_map.get(tmdb_id_str)
            
            if not item: continue # ç†è®ºä¸Šä¸åº”å‘ç”Ÿ

            # å¤„ç†æ—¥æœŸ
            raw_date = item.get('release_date')
            release_date_str = str(raw_date) if raw_date else None

            # æå– Emby ID
            emby_id = None
            if item.get('in_library'):
                ids_json = item.get('emby_item_ids_json')
                # å…¼å®¹å¤„ç†ï¼šå¯èƒ½æ˜¯ list å¯¹è±¡ï¼Œä¹Ÿå¯èƒ½æ˜¯ json å­—ç¬¦ä¸²
                if ids_json:
                    if isinstance(ids_json, list) and len(ids_json) > 0:
                        emby_id = ids_json[0]
                    elif isinstance(ids_json, str):
                        try:
                            parsed = json.loads(ids_json)
                            if isinstance(parsed, list) and len(parsed) > 0:
                                emby_id = parsed[0]
                        except: pass

            # åˆ¤æ–­çŠ¶æ€
            status = 'missing'
            if item.get('in_library'):
                status = 'in_library'
                stats['in_library'] += 1
            elif item.get('subscription_status') == 'SUBSCRIBED':
                status = 'subscribed'
                stats['subscribed'] += 1
            elif item.get('subscription_status') == 'PAUSED':
                status = 'paused' # æš‚åœä¹Ÿç®—è®¢é˜…çš„ä¸€ç§ï¼Œæˆ–è€…å•ç‹¬ç»Ÿè®¡
                stats['subscribed'] += 1
            else:
                if release_date_str and release_date_str > today_str:
                    status = 'unreleased'
                    stats['unreleased'] += 1
                else:
                    # æ—¢ä¸åœ¨åº“ï¼Œä¹Ÿæ²¡è®¢é˜…ï¼Œä¸”å·²ä¸Šæ˜  -> ç¼ºå¤±
                    stats['missing'] += 1

            final_movies.append({
                'tmdb_id': tmdb_id_str,
                'emby_id': emby_id,
                'title': item.get('title'),
                'poster_path': item.get('poster_path'),
                'release_date': release_date_str,
                'status': status
            })

        # å°†ç»Ÿè®¡ç»“æžœæ³¨å…¥åˆ°é›†åˆå¯¹è±¡ä¸­ï¼Œä¾›å‰ç«¯ä½¿ç”¨
        coll['statistics'] = stats
        coll['movies'] = sorted(final_movies, key=lambda x: x.get('release_date') or '9999')
        
        # æ¸…ç†
        coll.pop('all_tmdb_ids_json', None)
        coll.pop('parsed_ids', None)

    return all_collections

# â˜…â˜…â˜… æ–°å¢žï¼šå•åˆé›†å¤„ç†å‡½æ•° â˜…â˜…â˜…
def process_single_collection_by_emby_id(emby_collection_id: str, collection_name: str = "æœªçŸ¥åˆé›†"):
    """
    ã€Webhookä¸“ç”¨ã€‘å¤„ç†å•ä¸ªæ–°å…¥åº“çš„åŽŸç”Ÿåˆé›†ã€‚
    æµç¨‹ï¼šèŽ·å–è¯¦æƒ… -> å…¥åº“å…ƒæ•°æ® -> æ ‡è®°ç¼ºå¤±ç”µå½±ä¸ºå¾…è®¢é˜…ã€‚
    """
    logger.info(f"--- å¼€å§‹å¤„ç†å•ä¸ªæ–°åˆé›†: {collection_name} (ID: {emby_collection_id}) ---")
    
    config = config_manager.APP_CONFIG
    tmdb_api_key = config.get("tmdb_api_key")
    
    # 1. ä»Ž Emby èŽ·å–è¯¥åˆé›†çš„ TMDb ID
    # æˆ‘ä»¬ç›´æŽ¥å¤ç”¨ emby.get_emby_item_details
    item_details = emby.get_emby_item_details(
        item_id=emby_collection_id,
        emby_server_url=config.get('emby_server_url'),
        emby_api_key=config.get('emby_api_key'),
        user_id=config.get('emby_user_id'),
        fields="ProviderIds,Name"
    )
    
    if not item_details:
        logger.error(f"  ðŸš« æ— æ³•èŽ·å–åˆé›† {collection_name} çš„è¯¦æƒ…ï¼Œå¤„ç†ä¸­æ­¢ã€‚")
        return

    tmdb_collection_id = item_details.get("ProviderIds", {}).get("Tmdb")
    if not tmdb_collection_id:
        logger.warning(f"  âš ï¸ åˆé›† {collection_name} æ²¡æœ‰ TMDb IDï¼Œå¯èƒ½æ˜¯è‡ªå»ºåˆé›†ï¼Œè·³è¿‡å¤„ç†ã€‚")
        return

    # 2. èŽ·å– TMDb è¯¦æƒ… (åŒ…å«æ‰€æœ‰ç”µå½±åˆ—è¡¨)
    tmdb_details = tmdb.get_collection_details(tmdb_collection_id, tmdb_api_key)
    if not tmdb_details or 'parts' not in tmdb_details:
        logger.error(f"  ðŸš« æ— æ³•ä»Ž TMDb èŽ·å–åˆé›† {tmdb_collection_id} çš„è¯¦æƒ…ã€‚")
        return

    # 3. æå–æ•°æ®å¹¶å…¥åº“
    all_parts = []
    all_tmdb_ids = []
    
    for part in tmdb_details.get('parts', []):
        if not part.get('poster_path') or not part.get('release_date'): continue
        
        t_id = str(part['id'])
        all_parts.append({
            'tmdb_id': t_id,
            'title': part['title'],
            'original_title': part.get('original_title'),
            'release_date': part['release_date'],
            'poster_path': part['poster_path'],
            'overview': part.get('overview')
        })
        all_tmdb_ids.append(t_id)

    if not all_tmdb_ids: 
        logger.warning(f"  âš ï¸ åˆé›† {collection_name} ä¸­æ²¡æœ‰æœ‰æ•ˆçš„ç”µå½±æ•°æ®ã€‚")
        return

    # 3.1 ç¡®ä¿ media_metadata å­˜åœ¨åŸºç¡€æ•°æ®
    media_db.batch_ensure_basic_movies(all_parts)

    # 3.2 å†™å…¥åˆé›†å…³ç³»è¡¨
    collection_db.upsert_native_collection({
        'emby_collection_id': emby_collection_id,
        'name': collection_name,
        'tmdb_collection_id': str(tmdb_collection_id),
        'poster_path': tmdb_details.get('poster_path'),
        'all_tmdb_ids': all_tmdb_ids
    })
    
    logger.info(f"  âœ… åˆé›† {collection_name} å…ƒæ•°æ®å…¥åº“å®Œæˆï¼ŒåŒ…å« {len(all_tmdb_ids)} éƒ¨ç”µå½±ã€‚")

    # 4. é’ˆå¯¹è¯¥åˆé›†æ‰§è¡Œç¼ºå¤±è®¢é˜…
    # æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨ç­›é€‰å‡ºç¼ºå¤±çš„ï¼Œè€Œä¸æ˜¯è°ƒç”¨å…¨é‡çš„ subscribe_all_missing_in_native_collections
    _subscribe_missing_for_single_collection(collection_name, all_parts)

def _subscribe_missing_for_single_collection(collection_name: str, all_parts: List[Dict]):
    """
    ã€å†…éƒ¨è¾…åŠ©ã€‘åªé’ˆå¯¹å•ä¸ªåˆé›†çš„ç”µå½±åˆ—è¡¨æ‰§è¡Œç¼ºå¤±è®¢é˜…æ£€æŸ¥ã€‚
    """
    # 1. æŸ¥åº“ï¼šå“ªäº›å·²ç»åœ¨åº“é‡Œäº†ï¼Œå“ªäº›å·²ç»è®¢é˜…äº†
    tmdb_ids = [p['tmdb_id'] for p in all_parts]
    existing_map = media_db.get_media_details_by_tmdb_ids(tmdb_ids)
    
    today_str = datetime.now().strftime('%Y-%m-%d')
    
    released_missing = []
    unreleased_missing = []
    
    for part in all_parts:
        t_id = part['tmdb_id']
        db_item = existing_map.get(t_id)
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨æˆ–å·²è®¢é˜…
        if db_item:
            if db_item.get('in_library'): continue
            if db_item.get('subscription_status') in ['SUBSCRIBED', 'WANTED', 'PENDING_RELEASE']: continue
        
        # æž„é€  media_info
        media_info = {
            'tmdb_id': t_id,
            'title': part['title'],
            'original_title': part.get('original_title'),
            'release_date': part['release_date'],
            'poster_path': part['poster_path'],
            'overview': part.get('overview'),
            'source': {
                'type': 'native_collection',  
                'name': collection_name                  
            }
        }
        
        if part['release_date'] > today_str:
            unreleased_missing.append(media_info)
        else:
            released_missing.append(media_info)
            
    # 2. å†™å…¥ request_db
    source = {'type': 'native_collection', 'name': collection_name}
    
    if released_missing:
        logger.info(f"  âžœ [{collection_name}] è‡ªåŠ¨è¡¥å…¨: {len(released_missing)} éƒ¨å·²ä¸Šæ˜ ç”µå½±è®¾ä¸º WANTED...")
        request_db.set_media_status_wanted(
            tmdb_ids=[m['tmdb_id'] for m in released_missing],
            item_type='Movie',
            source=source,
            media_info_list=released_missing
        )
        
    if unreleased_missing:
        logger.info(f"  âžœ [{collection_name}] è‡ªåŠ¨è¡¥å…¨: {len(unreleased_missing)} éƒ¨æœªä¸Šæ˜ ç”µå½±è®¾ä¸º PENDING_RELEASE...")
        request_db.set_media_status_pending_release(
            tmdb_ids=[m['tmdb_id'] for m in unreleased_missing],
            item_type='Movie',
            source=source,
            media_info_list=unreleased_missing
        )