# tasks/subscriptions.py
# æ™ºèƒ½è®¢é˜…ä¸åª’ä½“æ´—ç‰ˆä»»åŠ¡æ¨¡å—
import re
import os
import json
import time
import logging
from datetime import datetime, date, timedelta, timezone
from typing import List, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed # <--- å°±æ˜¯åŠ ä¸Šè¿™ä¸€è¡Œï¼

# å¯¼å…¥éœ€è¦çš„åº•å±‚æ¨¡å—å’Œå…±äº«å®ä¾‹
import config_manager
import constants
import handler.emby as emby
import handler.tmdb as tmdb
import handler.moviepilot as moviepilot
import task_manager
from handler import telegram
from database import connection, settings_db, resubscribe_db, collection_db, user_db
from .helpers import _get_standardized_effect, _extract_quality_tag_from_filename

logger = logging.getLogger(__name__)

def _extract_exclusion_keywords_from_filename(filename: str) -> List[str]:
    """
    ã€V8 - èŒè´£æ˜ç¡®ç‰ˆã€‘
    - æ ¸å¿ƒèŒè´£ï¼šä»…è´Ÿè´£ä»æ–‡ä»¶åä¸­æå–æœ‰æ•ˆçš„ã€éä¸­æ–‡çš„æŠ€æœ¯æ ‡ç­¾å’Œå‘å¸ƒç»„å…³é”®å­—ã€‚
    - è¾“å‡ºï¼šè¿”å›ä¸€ä¸ªå¹²å‡€çš„å…³é”®å­—åˆ—è¡¨ (List[str])ã€‚å¦‚æœæå–ä¸åˆ°ä»»ä½•æœ‰æ•ˆå…³é”®å­—ï¼Œåˆ™è¿”å›ä¸€ä¸ªç©ºåˆ—è¡¨ã€‚
    - â˜…â˜…â˜… æœ¬å‡½æ•°ä¸å†è´Ÿè´£ç”Ÿæˆä»»ä½•æœ€ç»ˆæ ¼å¼çš„å­—ç¬¦ä¸²ã€‚
    """
    if not filename:
        return []

    name_part = os.path.splitext(filename)[0]
    keywords = set()

    KNOWN_TECH_TAGS = {
        'BLURAY', 'BDRIP', 'WEB-DL', 'WEBDL', 'WEBRIP', 'HDTV', 'REMUX', 
        'X264', 'X265', 'H264', 'H265', 'AVC', 'HEVC', '10BIT', 
        'DTS', 'AC3', 'ATMOS', 'DDP5', 'AAC', 'FLAC',
        '1080P', '2160P', '720P', '4K', 'UHD'
    }

    words = re.split(r'[.\s_Â·()\[\]-]', name_part)
    season_episode_pattern = re.compile(r'^S\d{2,4}E\d{2,4}$', re.IGNORECASE)

    for word in reversed(words):
        if not word or season_episode_pattern.match(word):
            continue
        
        if re.search(r'[\u4e00-\u9fff]', word):
            continue

        if len(word) > 2 and not word.isdigit():
            if word.upper() not in KNOWN_TECH_TAGS:
                keywords.add(word)
                break

    normalized_name_part = re.sub(r'[\s_Â·()\[\]]', '.', name_part)
    common_tags_regex = r'\.(BluRay|BDRip|WEB-DL|WEBDL|WEBRip|HDTV|REMUX|x264|x265|h264|h265|AVC|HEVC|10bit|DTS|AC3|Atmos|DDP5|AAC|FLAC)\b'
    found_tags = re.findall(common_tags_regex, normalized_name_part, re.IGNORECASE)
    
    for tag in found_tags:
        normalized_tag = tag.upper().replace('WEB-DL', 'WEBDL')
        keywords.add(normalized_tag)

    return sorted(list(keywords))

def _get_detected_languages_from_streams(
    media_streams: List[dict], 
    stream_type: str, 
    lang_keyword_map: dict
) -> set:
    """
    ã€V2 - æ™ºèƒ½è¯†åˆ«ç‰ˆã€‘
    ä»åª’ä½“æµä¸­æ£€æµ‹æŒ‡å®šç±»å‹ï¼ˆAudio/Subtitleï¼‰çš„è¯­è¨€ã€‚
    - ä¼˜å…ˆæ£€æŸ¥æ ‡å‡†çš„ 'Language' å­—æ®µã€‚
    - ç„¶åæ£€æŸ¥ 'Title' å’Œ 'DisplayTitle' å­—æ®µä¸­çš„å…³é”®è¯ã€‚
    - è¿”å›ä¸€ä¸ªåŒ…å«æ ‡å‡†åŒ–è¯­è¨€ä»£ç çš„é›†åˆ (ä¾‹å¦‚ {'chi', 'eng'})ã€‚
    """
    detected_langs = set()
    
    # 1. ä¼˜å…ˆä»æ ‡å‡†çš„ Language å­—æ®µè·å–ä¿¡æ¯
    standard_chinese_codes = {'chi', 'zho', 'chs', 'cht', 'zh-cn', 'zh-hans', 'zh-sg', 'cmn', 'yue'}
    standard_english_codes = {'eng'}
    standard_japanese_codes = {'jpn'}
    
    for stream in media_streams:
        if stream.get('Type') == stream_type and (lang_code := str(stream.get('Language', '')).lower()):
            if lang_code in standard_chinese_codes:
                detected_langs.add('chi')
            elif lang_code in standard_english_codes:
                detected_langs.add('eng')
            elif lang_code in standard_japanese_codes:
                detected_langs.add('jpn')

    # 2. æ‰«æ Title å’Œ DisplayTitle ä½œä¸ºè¡¥å……
    for stream in media_streams:
        if stream.get('Type') == stream_type:
            # å°†æ ‡é¢˜å’Œæ˜¾ç¤ºæ ‡é¢˜åˆå¹¶ï¼Œå¹¶è½¬ä¸ºå°å†™ï¼Œä»¥ä¾¿æœç´¢
            title_string = (stream.get('Title', '') + stream.get('DisplayTitle', '')).lower()
            if not title_string:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
            for lang_key, keywords in lang_keyword_map.items():
                # lang_key å¯èƒ½æ˜¯ 'chi', 'sub_chi', 'eng' ç­‰
                normalized_lang_key = lang_key.replace('sub_', '')
                
                if any(keyword.lower() in title_string for keyword in keywords):
                    detected_langs.add(normalized_lang_key)

    return detected_langs

EFFECT_KEYWORD_MAP = {
    "æœæ¯”è§†ç•Œ": ["dolby vision", "dovi"],
    "HDR": ["hdr", "hdr10", "hdr10+", "hlg"]
}

AUDIO_SUBTITLE_KEYWORD_MAP = {
    # éŸ³è½¨å…³é”®è¯
    "chi": ["Mandarin", "CHI", "ZHO", "å›½è¯­", "å›½é…", "å›½è‹±åŒè¯­", "å…¬æ˜ ", "å°é…", "äº¬è¯‘", "ä¸Šè¯‘", "å¤®è¯‘"],
    "yue": ["Cantonese", "YUE", "ç²¤è¯­"],
    "eng": ["English", "ENG", "è‹±è¯­"],
    "jpn": ["Japanese", "JPN", "æ—¥è¯­"],
    # å­—å¹•å…³é”®è¯ (å¯ä»¥å’ŒéŸ³è½¨å…±ç”¨ï¼Œä¹Ÿå¯ä»¥åˆ†å¼€å®šä¹‰)
    "sub_chi": ["CHS", "CHT", "ä¸­å­—", "ç®€ä¸­", "ç¹ä¸­", "ç®€", "ç¹"],
    "sub_eng": ["ENG", "è‹±å­—"],
}

# â˜…â˜…â˜… å®šä¹‰åˆ†è¾¨ç‡ç­‰çº§è¾…åŠ©å‡½æ•° â˜…â˜…â˜…
def _get_resolution_tier(width: int, height: int) -> tuple[int, str]:
    """æ ¹æ®è§†é¢‘çš„å®½æˆ–é«˜ï¼Œå°†å…¶å½’ç±»åˆ°å¯¹åº”çš„åˆ†è¾¨ç‡ç­‰çº§ã€‚"""
    if width >= 3800 or height >= 2100:
        return 4, "4K"
    if width >= 1900 or height >= 1000:
        return 3, "1080p"
    if width >= 1200 or height >= 700:
        return 2, "720p"
    if height > 0:
        return 1, f"{height}p"
    return 0, "æœªçŸ¥"

# --- è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥å‰§é›†æˆ–ç‰¹å®šå­£æ˜¯å¦å®Œç»“ï¼Œå¹¶è¿”å›æ´—ç‰ˆæ ‡å¿— ---
def _check_and_get_series_best_version_flag(series_tmdb_id: int, tmdb_api_key: str, season_number: Optional[int] = None, series_name: str = "æœªçŸ¥å‰§é›†") -> Optional[int]:
    """
    è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥å‰§é›†æˆ–ç‰¹å®šå­£æ˜¯å¦å®Œç»“ï¼Œå¹¶è¿”å›æ´—ç‰ˆæ ‡å¿—ã€‚
    """
    if not tmdb_api_key:
        return None
    
    today = date.today()
    try:
        if season_number is not None:
            # æ£€æŸ¥å•å­£æ˜¯å¦å®Œç»“
            season_details = tmdb.get_tv_details(series_tmdb_id, season_number, tmdb_api_key)
            if season_details and season_details.get('episodes'):
                last_episode = season_details['episodes'][-1]
                last_air_date_str = last_episode.get('air_date')
                if last_air_date_str:
                    last_air_date = datetime.strptime(last_air_date_str, '%Y-%m-%d').date()
                    if last_air_date <= today:
                        logger.info(f"  âœ ã€Š{series_name}ã€‹ç¬¬ {season_number} å­£å·²å®Œç»“ï¼Œå°†ä»¥æ´—ç‰ˆæ¨¡å¼è®¢é˜…ã€‚")
                        return 1
        else:
            series_details = tmdb.get_tv_details(series_tmdb_id, tmdb_api_key)
            if series_details and (last_episode_to_air := series_details.get('last_episode_to_air')):
                last_air_date_str = last_episode_to_air.get('air_date')
                if last_air_date_str:
                    last_air_date = datetime.strptime(last_air_date_str, '%Y-%m-%d').date()
                    if last_air_date <= today:
                        logger.info(f"  âœ å‰§é›†ã€Š{series_name}ã€‹çš„æœ€åä¸€é›†å·²æ’­å‡ºï¼Œå°†ä»¥æ´—ç‰ˆæ¨¡å¼è®¢é˜…ã€‚")
                        return 1
                        
    except Exception as e_tmdb:
        logger.warning(f"  âœ è·å–ã€Š{series_name}ã€‹è¯¦æƒ…å¤±è´¥: {e_tmdb}ï¼Œå°†ä»¥æ™®é€šæ¨¡å¼è®¢é˜…ã€‚")
    
    return None

# â˜…â˜…â˜… è‡ªåŠ¨è®¢é˜…ä»»åŠ¡ â˜…â˜…â˜…
def task_auto_subscribe(processor):
    """
    - ç°åœ¨æ­¤ä»»åŠ¡ä¼šä¾æ¬¡å¤„ç†ï¼šåŸç”Ÿåˆé›†ã€è¿½å‰§ã€è‡ªå®šä¹‰åˆé›†ã€æ¼”å‘˜è®¢é˜…ï¼Œæœ€åå¤„ç†åª’ä½“æ´—ç‰ˆã€‚
    - ä¸€ä¸ªä»»åŠ¡æå®šæ‰€æœ‰æ—¥å¸¸è‡ªåŠ¨åŒ–è®¢é˜…éœ€æ±‚ã€‚
    """
    task_name = "ç¼ºå¤±æ´—ç‰ˆè®¢é˜…"
    logger.info(f"--- å¼€å§‹æ‰§è¡Œ '{task_name}' ä»»åŠ¡ ---")
    
    task_manager.update_status_from_thread(0, "æ­£åœ¨å¯åŠ¨ç¼ºå¤±æ´—ç‰ˆè®¢é˜…ä»»åŠ¡...")
    
    if not config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_AUTOSUB_ENABLED):
        logger.info("  âœ è®¢é˜…æ€»å¼€å…³æœªå¼€å¯ï¼Œä»»åŠ¡è·³è¿‡ã€‚")
        task_manager.update_status_from_thread(100, "ä»»åŠ¡è·³è¿‡ï¼šæ€»å¼€å…³æœªå¼€å¯")
        return

    try:
        today = date.today()
        tmdb_api_key = config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_TMDB_API_KEY)

        task_manager.update_status_from_thread(10, "ç¼ºå¤±æ´—ç‰ˆè®¢é˜…å·²å¯åŠ¨...")
        subscription_details = []
        resubscribed_count = 0
        deleted_count = 0
        quota_exhausted = False

        with connection.get_db_connection() as conn:
            cursor = conn.cursor()

            # --- 1. å¤„ç†åŸç”Ÿç”µå½±åˆé›†  ---
            if not processor.is_stop_requested() and not quota_exhausted:
                task_manager.update_status_from_thread(15, "æ­£åœ¨æ£€æŸ¥åŸç”Ÿç”µå½±åˆé›†...")
                sql_query_native_movies = "SELECT * FROM collections_info WHERE status = 'has_missing' AND missing_movies_json IS NOT NULL AND missing_movies_json != '[]'"
                cursor.execute(sql_query_native_movies)
                native_collections_to_check = cursor.fetchall()
                logger.info(f"  âœ æ‰¾åˆ° {len(native_collections_to_check)} ä¸ªæœ‰ç¼ºå¤±å½±ç‰‡çš„åŸç”Ÿåˆé›†ã€‚")
                
                for collection in native_collections_to_check:
                    if processor.is_stop_requested() or quota_exhausted: break
                    
                    movies_to_keep = []
                    all_movies = collection['missing_movies_json']
                    movies_changed = False
                    
                    for movie in all_movies:
                        if processor.is_stop_requested(): break
                        
                        if movie.get('status') == 'missing':
                            release_date_str = movie.get('release_date')
                            if not release_date_str:
                                movies_to_keep.append(movie)
                                continue
                            try:
                                release_date = datetime.strptime(release_date_str.strip(), '%Y-%m-%d').date()
                            except (ValueError, TypeError):
                                movies_to_keep.append(movie)
                                continue

                            if release_date <= today:
                                current_quota = settings_db.get_subscription_quota()
                                if current_quota <= 0:
                                    quota_exhausted = True
                                    logger.warning("  âœ æ¯æ—¥è®¢é˜…é…é¢å·²ç”¨å°½ï¼ŒåŸç”Ÿåˆé›†æ£€æŸ¥æå‰ç»“æŸã€‚")
                                    movies_to_keep.append(movie)
                                    break

                                if moviepilot.subscribe_movie_to_moviepilot(movie, config_manager.APP_CONFIG):
                                    settings_db.decrement_subscription_quota()
                                    subscription_details.append({'module': 'åŸç”Ÿåˆé›†', 'source': collection.get('name', 'æœªçŸ¥åˆé›†'), 'item': f"ç”µå½±ã€Š{movie['title']}ã€‹"})
                                    movies_changed = True
                                    movie['status'] = 'subscribed'
                                movies_to_keep.append(movie)
                            else:
                                movies_to_keep.append(movie)
                        else:
                            movies_to_keep.append(movie)
                            
                    if movies_changed:
                        new_missing_json = json.dumps(movies_to_keep)
                        new_status = 'ok' if not any(m.get('status') == 'missing' for m in movies_to_keep) else 'has_missing'
                        cursor.execute("UPDATE collections_info SET missing_movies_json = %s, status = %s WHERE emby_collection_id = %s", (new_missing_json, new_status, collection['emby_collection_id']))

            # --- 2. å¤„ç†æ™ºèƒ½è¿½å‰§ ---
            if not processor.is_stop_requested() and not quota_exhausted:
                task_manager.update_status_from_thread(30, "æ­£åœ¨æ£€æŸ¥ç¼ºå¤±çš„å‰§é›†...")
                sql_query = "SELECT * FROM watchlist WHERE status IN ('Watching', 'Paused') AND missing_info_json IS NOT NULL AND missing_info_json != '[]'"
                cursor.execute(sql_query)
                series_to_check = cursor.fetchall()
                
                for series in series_to_check:
                    if processor.is_stop_requested() or quota_exhausted: break
                    series_name = series['item_name']
                    series_tmdb_id = series['tmdb_id']
                    logger.info(f"    â”œâ”€ æ­£åœ¨æ£€æŸ¥: ã€Š{series_name}ã€‹")
                    try:
                        missing_info = series['missing_info_json']
                        missing_seasons = missing_info.get('missing_seasons', [])
                        if not missing_seasons: continue
                        
                        seasons_to_keep = []
                        seasons_changed = False
                        for season in missing_seasons:
                            if processor.is_stop_requested() or quota_exhausted: break
                            
                            air_date_str = season.get('air_date')
                            if not air_date_str: seasons_to_keep.append(season); continue
                            try: season_date = datetime.strptime(air_date_str.strip(), '%Y-%m-%d').date()
                            except (ValueError, TypeError): seasons_to_keep.append(season); continue

                            if season_date <= today:
                                resubscribe_info = series.get('resubscribe_info_json') or {}
                                last_subscribed_str = resubscribe_info.get(str(season['season_number']))
                                if last_subscribed_str:
                                    try:
                                        cooldown_hours = 24 
                                        last_subscribed_time = datetime.fromisoformat(last_subscribed_str.replace('Z', '+00:00'))
                                        if datetime.now(timezone.utc) < last_subscribed_time + timedelta(hours=cooldown_hours):
                                            seasons_to_keep.append(season)
                                            continue
                                    except (ValueError, TypeError): pass
                                current_quota = settings_db.get_subscription_quota()
                                if current_quota <= 0:
                                    quota_exhausted = True; seasons_to_keep.append(season); break

                                # --- æ£€æŸ¥å‰§é›†æ˜¯å¦å®Œç»“ ---
                                best_version_flag = _check_and_get_series_best_version_flag(
                                    series_tmdb_id=series_tmdb_id,
                                    tmdb_api_key=tmdb_api_key,
                                    season_number=season['season_number'],
                                    series_name=series_name
                                )
                                
                                success = moviepilot.subscribe_series_to_moviepilot(
                                    series_info=dict(series), season_number=season['season_number'], 
                                    config=config_manager.APP_CONFIG, best_version=best_version_flag
                                )
                                
                                if success:
                                    settings_db.decrement_subscription_quota()
                                    cursor.execute("""
                                        UPDATE watchlist SET resubscribe_info_json = jsonb_set(
                                            COALESCE(resubscribe_info_json, '{}'::jsonb), %s, %s::jsonb, true)
                                        WHERE item_id = %s
                                    """, ([str(season['season_number'])], f'"{datetime.now(timezone.utc).isoformat()}"', series['item_id']))
                                    subscription_details.append({'module': 'æ™ºèƒ½è¿½å‰§', 'item': f"ã€Š{series_name}ã€‹ç¬¬ {season['season_number']} å­£"})
                                    seasons_changed = True
                                else:
                                    seasons_to_keep.append(season)
                            else:
                                seasons_to_keep.append(season)
                                
                        if seasons_changed:
                            missing_info['missing_seasons'] = seasons_to_keep
                            cursor.execute("UPDATE watchlist SET missing_info_json = %s WHERE item_id = %s", (json.dumps(missing_info), series['item_id']))
                    except Exception as e_series:
                        logger.error(f"  âœ ã€æ™ºèƒ½è®¢é˜…-å‰§é›†ã€‘å¤„ç†å‰§é›† '{series_name}' æ—¶å‡ºé”™: {e_series}")

            # --- 3. å¤„ç†ä¸­é—´ç¼ºé›†çš„å­£ ---
            if not processor.is_stop_requested() and not quota_exhausted:
                task_manager.update_status_from_thread(35, "æ­£åœ¨æ£€æŸ¥ä¸­é—´ç¼ºé›†çš„å­£...")
                # æŸ¥è¯¢é‚£äº›è¢«æ ‡è®°äº† "seasons_with_gaps" çš„å‰§é›†
                sql_query_gaps = "SELECT * FROM watchlist WHERE status IN ('Watching', 'Paused', 'Completed') AND jsonb_array_length(missing_info_json->'seasons_with_gaps') > 0"
                cursor.execute(sql_query_gaps)
                series_with_gaps_to_check = cursor.fetchall()
                
                logger.info(f"  âœ æ‰¾åˆ° {len(series_with_gaps_to_check)} éƒ¨å‰§é›†å­˜åœ¨ä¸­é—´ç¼ºé›†çš„å­£éœ€è¦è®¢é˜…ã€‚")

                for series in series_with_gaps_to_check:
                    if processor.is_stop_requested() or quota_exhausted: break
                    
                    series_name = series['item_name']
                    missing_info = series['missing_info_json']
                    seasons_to_subscribe = missing_info.get('seasons_with_gaps', [])
                    
                    if not seasons_to_subscribe: continue

                    seasons_subscribed_this_run = []
                    for season_num in seasons_to_subscribe:
                        if processor.is_stop_requested() or quota_exhausted: break

                        # é…é¢æ£€æŸ¥
                        current_quota = settings_db.get_subscription_quota()
                        if current_quota <= 0:
                            quota_exhausted = True
                            logger.warning("  âœ æ¯æ—¥è®¢é˜…é…é¢å·²ç”¨å°½ï¼Œä¸­é—´ç¼ºé›†è®¢é˜…æå‰ç»“æŸã€‚")
                            break

                        # â˜…â˜…â˜… æ ¸å¿ƒï¼šæ ¹æ®ç”¨æˆ·è®¾ç½®å†³å®šè®¢é˜…æ¨¡å¼ â˜…â˜…â˜…
                        # constants.CONFIG_OPTION_RESUBSCRIBE_USE_BEST_VERSION å¯¹åº” "æ˜¯å¦æ•´å­£æ´—ç‰ˆ" å¼€å…³
                        use_best_version = config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_RESUBSCRIBE_USE_BEST_VERSION, False)
                        best_version_param = 1 if use_best_version else None
                        log_mode = "æ´—ç‰ˆæ¨¡å¼" if use_best_version else "æ™®é€šæ¨¡å¼"
                        logger.info(f"  âœ å‡†å¤‡ä¸ºã€Š{series_name}ã€‹ç¬¬ {season_num} å­£æäº¤è®¢é˜… ({log_mode})...")

                        success = moviepilot.subscribe_series_to_moviepilot(
                            series_info=dict(series), 
                            season_number=season_num, 
                            config=config_manager.APP_CONFIG, 
                            best_version=best_version_param
                        )

                        if success:
                            settings_db.decrement_subscription_quota()
                            subscription_details.append({'module': 'ä¸­é—´ç¼ºé›†', 'item': f"ã€Š{series_name}ã€‹ç¬¬ {season_num} å­£ ({log_mode})"})
                            seasons_subscribed_this_run.append(season_num)
                    
                    # å¦‚æœæˆåŠŸè®¢é˜…äº†ä»»ä½•å­£ï¼Œå°±ä»æ ‡è®°ä¸­ç§»é™¤å®ƒä»¬ï¼Œé˜²æ­¢é‡å¤è®¢é˜…
                    if seasons_subscribed_this_run:
                        remaining_gaps = [s for s in seasons_to_subscribe if s not in seasons_subscribed_this_run]
                        missing_info['seasons_with_gaps'] = remaining_gaps
                        cursor.execute("UPDATE watchlist SET missing_info_json = %s WHERE item_id = %s", (json.dumps(missing_info), series['item_id']))

            # --- 4. å¤„ç†è‡ªå®šä¹‰åˆé›† ---
            if not processor.is_stop_requested() and not quota_exhausted:
                task_manager.update_status_from_thread(45, "æ­£åœ¨æ£€æŸ¥è‡ªå®šä¹‰æ¦œå•åˆé›†...")
                sql_query_custom_collections = "SELECT * FROM custom_collections WHERE type = 'list' AND health_status = 'has_missing' AND generated_media_info_json IS NOT NULL AND generated_media_info_json != '[]'"
                cursor.execute(sql_query_custom_collections)
                custom_collections_to_check = cursor.fetchall()
                
                for collection in custom_collections_to_check:
                    if processor.is_stop_requested() or quota_exhausted: break
                    try:
                        all_media = collection['generated_media_info_json']
                        media_to_keep = []
                        media_changed = False
                        for media_item in all_media:
                            if processor.is_stop_requested(): break
                            
                            if media_item.get('status') == 'missing':
                                release_date_str = media_item.get('release_date')
                                if not release_date_str: media_to_keep.append(media_item); continue
                                try: release_date = datetime.strptime(release_date_str.strip(), '%Y-%m-%d').date()
                                except (ValueError, TypeError): media_to_keep.append(media_item); continue

                                if release_date <= today:
                                    current_quota = settings_db.get_subscription_quota()
                                    if current_quota <= 0:
                                        quota_exhausted = True; media_to_keep.append(media_item); break
                                        
                                    success = False
                                    media_title = media_item.get('title', 'æœªçŸ¥æ ‡é¢˜')
                                    media_tmdb_id = media_item.get('tmdb_id')
                                    authoritative_type = 'Series' if media_item.get('media_type') == 'Series' else 'Movie'

                                    if authoritative_type == 'Movie':
                                        success = moviepilot.subscribe_movie_to_moviepilot(media_item, config_manager.APP_CONFIG)
                                    elif authoritative_type == 'Series':
                                        # --- æ£€æŸ¥å‰§é›†æ˜¯å¦å®Œç»“ ---
                                        best_version_flag = _check_and_get_series_best_version_flag(
                                            series_tmdb_id=media_tmdb_id,
                                            tmdb_api_key=tmdb_api_key,
                                            series_name=media_title
                                        )
                                        series_info = { "item_name": media_title, "tmdb_id": media_tmdb_id }
                                        success = moviepilot.subscribe_series_to_moviepilot(
                                            series_info, season_number=None, 
                                            config=config_manager.APP_CONFIG, best_version=best_version_flag
                                        )
                                    
                                    if success:
                                        settings_db.decrement_subscription_quota()
                                        subscription_details.append({'module': 'è‡ªå®šä¹‰åˆé›†', 'source': collection.get('name', 'æœªçŸ¥æ¦œå•'), 'item': f"{authoritative_type}ã€Š{media_title}ã€‹"})
                                        media_changed = True
                                        media_item['status'] = 'subscribed'
                                    media_to_keep.append(media_item)
                                else:
                                    media_to_keep.append(media_item)
                            else:
                                media_to_keep.append(media_item)
                                
                        if media_changed:
                            new_missing_json = json.dumps(media_to_keep, ensure_ascii=False)
                            new_missing_count = sum(1 for m in media_to_keep if m.get('status') == 'missing')
                            new_health_status = 'has_missing' if new_missing_count > 0 else 'ok'
                            cursor.execute(
                                "UPDATE custom_collections SET generated_media_info_json = %s, health_status = %s, missing_count = %s WHERE id = %s", 
                                (new_missing_json, new_health_status, new_missing_count, collection['id'])
                            )
                    except Exception as e_coll:
                        logger.error(f"  âœ å¤„ç†è‡ªå®šä¹‰åˆé›† '{collection['name']}' æ—¶å‘ç”Ÿé”™è¯¯: {e_coll}", exc_info=True)

            # --- 5. å¤„ç†æ¼”å‘˜è®¢é˜… ---
            if not processor.is_stop_requested() and not quota_exhausted:
                task_manager.update_status_from_thread(60, "æ­£åœ¨æ£€æŸ¥æ¼”å‘˜è®¢é˜…çš„ç¼ºå¤±ä½œå“...")
                sql_query_actors = """
                    SELECT
                        tam.*,
                        sub.actor_name
                    FROM
                        tracked_actor_media AS tam
                    JOIN
                        actor_subscriptions AS sub ON tam.subscription_id = sub.id
                    WHERE
                        tam.status = 'MISSING'
                """
                cursor.execute(sql_query_actors)
                actor_media_to_check = cursor.fetchall()
                
                for media_item in actor_media_to_check:
                    if processor.is_stop_requested() or quota_exhausted: break
                    
                    release_date = media_item.get('release_date')
                    if not release_date or release_date > today: continue

                    current_quota = settings_db.get_subscription_quota()
                    if current_quota <= 0:
                        quota_exhausted = True; break
                    
                    success = False
                    media_title = media_item.get('title', 'æœªçŸ¥æ ‡é¢˜')
                    media_tmdb_id = media_item.get('tmdb_media_id')
                    
                    if media_item['media_type'] == 'Movie':
                        movie_info = {'title': media_title, 'tmdb_id': media_tmdb_id}
                        success = moviepilot.subscribe_movie_to_moviepilot(movie_info, config_manager.APP_CONFIG)
                    elif media_item['media_type'] == 'Series':
                        # --- æ£€æŸ¥å‰§é›†æ˜¯å¦å®Œç»“ ---
                        best_version_flag = _check_and_get_series_best_version_flag(
                            series_tmdb_id=media_tmdb_id,
                            tmdb_api_key=tmdb_api_key,
                            series_name=media_title
                        )
                        series_info = {"item_name": media_title, "tmdb_id": media_tmdb_id}
                        success = moviepilot.subscribe_series_to_moviepilot(
                            series_info, season_number=None, 
                            config=config_manager.APP_CONFIG, best_version=best_version_flag
                        )
                    
                    if success:
                        settings_db.decrement_subscription_quota()
                        actor_name = media_item.get('actor_name', 'æœªçŸ¥æ¼”å‘˜')
                        subscription_details.append({'module': 'æ¼”å‘˜è®¢é˜…', 'source': actor_name, 'item': f"ä½œå“ã€Š{media_title}ã€‹"})
                        cursor.execute("UPDATE tracked_actor_media SET status = 'SUBSCRIBED' WHERE id = %s", (media_item['id'],))

            conn.commit()

        # --- 6. å¤„ç†åª’ä½“æ´—ç‰ˆ ---
        logger.info("--- æ™ºèƒ½è®¢é˜…ç¼ºå¤±å·²å®Œæˆï¼Œå¼€å§‹æ‰§è¡Œåª’ä½“æ´—ç‰ˆä»»åŠ¡ ---")
        task_manager.update_status_from_thread(85, "ç¼ºå¤±è®¢é˜…å®Œæˆï¼Œæ­£åœ¨å¯åŠ¨åª’ä½“æ´—ç‰ˆ...") # æ›´æ–°ä¸€ä¸ªè¿‡æ¸¡çŠ¶æ€
        
        # ç›´æ¥è°ƒç”¨æ´—ç‰ˆä»»åŠ¡å‡½æ•°
        task_resubscribe_library(processor)

        # --- æ„å»ºæœ€ç»ˆçš„åˆ†ç±»æ±‡æ€»æ—¥å¿— ---
        summary_message = ""
        if subscription_details:
            header = f"âœ… æ™ºèƒ½è®¢é˜…å®Œæˆï¼ŒæˆåŠŸæäº¤ {len(subscription_details)} é¡¹:"
            item_lines = []
            for detail in subscription_details:
                module = detail['module']
                source = detail.get('source')
                prefix = f"[{module}-{source}]" if source else f"[{module}]"
                item_lines.append(f"  â”œâ”€ {prefix} {detail['item']}")
            
            summary_message = header + "\n" + "\n".join(item_lines)
            if quota_exhausted:
                summary_message += "\n(æ¯æ—¥è®¢é˜…é…é¢å·²ç”¨å°½ï¼Œéƒ¨åˆ†é¡¹ç›®å¯èƒ½æœªå¤„ç†)"
        else:
            summary_message = "âœ… æ™ºèƒ½è®¢é˜…å®Œæˆï¼Œæœ¬æ¬¡æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„åª’ä½“ã€‚"

        # æ— è®ºæœ‰æ— è®¢é˜…ï¼Œéƒ½æ‰“å°æœ€ç»ˆæ—¥å¿—
        logger.info(summary_message)

        # --- å‘ç®¡ç†å‘˜å‘é€ Telegram é€šçŸ¥ ---
        admin_chat_ids = user_db.get_admin_telegram_chat_ids()
        if admin_chat_ids:
            # ä¸º Telegram çš„ MarkdownV2 æ ¼å¼è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
            # æ³¨æ„ï¼šæˆ‘ä»¬åªè½¬ä¹‰æ¶ˆæ¯å†…å®¹ï¼Œä¿ç•™æˆ‘ä»¬è‡ªå·±æ·»åŠ çš„æ ¼å¼
            escaped_summary = summary_message.replace('[', '\\[').replace(']', '\\]').replace('(', '\\(').replace(')', '\\)').replace('-', '\\-')
            
            logger.info(f"  âœ å‡†å¤‡å‘ {len(admin_chat_ids)} ä½ç®¡ç†å‘˜å‘é€ä»»åŠ¡æ€»ç»“...")
            for chat_id in admin_chat_ids:
                # disable_notification=True è¡¨ç¤ºå‘é€é™é»˜é€šçŸ¥ï¼Œé¿å…æ‰“æ‰°
                telegram.send_telegram_message(chat_id, escaped_summary, disable_notification=True)

    except Exception as e:
        logger.error(f"æ™ºèƒ½è®¢é˜…ä¸æ´—ç‰ˆä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        task_manager.update_status_from_thread(-1, f"é”™è¯¯: {e}")

# â˜…â˜…â˜… åª’ä½“æ´—ç‰ˆä»»åŠ¡ â˜…â˜…â˜…
def build_resubscribe_payload(item_details: dict, rule: Optional[dict]) -> Optional[dict]:
    """
    - ã€V6 - å¥å£®ä¸è°ƒè¯•ç‰ˆã€‘
    - å¢åŠ è¯¦ç»†çš„å…¥å£æ—¥å¿—ï¼Œç”¨äºæ’æŸ¥é—®é¢˜ã€‚
    - å¼ºåŒ–äº†ä» item_details ä¸­æå–æ ¸å¿ƒä¿¡æ¯çš„é€»è¾‘ã€‚
    - ç¡®ä¿ä¸ºâ€œå­£â€ç±»å‹æ­£ç¡®æ·»åŠ  season å‚æ•°ã€‚
    """
    # â˜…â˜…â˜… å…³é”®è°ƒè¯•æ­¥éª¤ 1: æ‰“å°ä¼ å…¥çš„å®Œæ•´åŸå§‹æ•°æ® â˜…â˜…â˜…
    from datetime import date, datetime # ç¡®ä¿å¯¼å…¥
    details_for_log = item_details.copy()
    for key, value in details_for_log.items():
        # å°† datetime å’Œ date å¯¹è±¡éƒ½è½¬æ¢ä¸º ISO æ ¼å¼çš„å­—ç¬¦ä¸²
        if isinstance(value, (datetime, date)):
            details_for_log[key] = value.isoformat()

    # --- 1. æ›´ç¨³å¥åœ°æå–æ ¸å¿ƒID ---
    item_name = item_details.get('item_name') # ç›´æ¥ä½¿ç”¨ item_nameï¼Œå®ƒæ›´å¯é 
    tmdb_id_str = str(item_details.get('tmdb_id', '')).strip()
    item_type = item_details.get('item_type') # 'Movie' or 'Season'

    if not all([item_name, tmdb_id_str, item_type]):
        logger.error(f"æ„å»ºPayloadå¤±è´¥ï¼šç¼ºå°‘æ ¸å¿ƒåª’ä½“ä¿¡æ¯ (name, tmdb_id, type)ã€‚æ¥æº: {item_details}")
        return None
    
    try:
        tmdb_id = int(tmdb_id_str)
    except (ValueError, TypeError):
        logger.error(f"æ„å»ºPayloadå¤±è´¥ï¼šTMDB ID '{tmdb_id_str}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ã€‚")
        return None

    # --- 2. åˆå§‹åŒ–Payloadï¼Œå¹¶æ ¹æ®ç±»å‹å†³å®šåŸºç¡€è®¢é˜…å ---
    # é»˜è®¤ä½¿ç”¨åŸå§‹å‰§é›†åï¼Œé¿å…åç§°ä¸­åŒ…å« â€œ- ç¬¬ X å­£â€
    base_series_name = item_name.split(' - ç¬¬')[0]
    media_type_for_payload = "ç”µè§†å‰§" if item_type in ["Series", "Season"] else "ç”µå½±"

    payload = {
        "name": base_series_name,
        "tmdbid": tmdb_id,
        "type": media_type_for_payload,
        "best_version": 1
    }

    # --- 3. â˜…â˜…â˜… æ ¸å¿ƒé€»è¾‘ï¼šå¦‚æœæ˜¯å­£ï¼Œåˆ™å¿…é¡»æ·»åŠ  season å­—æ®µ â˜…â˜…â˜…
    if item_type == "Season":
        season_num = item_details.get('season_number')
        if season_num is not None:
            payload['season'] = int(season_num)
            logger.info(f"  âœ å·²ä¸ºã€Š{base_series_name}ã€‹ç²¾å‡†æŒ‡å®šè®¢é˜…å­£: {payload['season']}")
        else:
            # è¿™æ˜¯ä¸€ä¸ªä¿æŠ¤æ€§åˆ†æ”¯ï¼Œæ­£å¸¸æƒ…å†µä¸‹ä¸åº”è¯¥è¿›å…¥
            logger.error(f"  âœ ä¸¥é‡é”™è¯¯ï¼šé¡¹ç›®ç±»å‹ä¸º 'Season'ï¼Œä½†åœ¨æ•°æ®åº“è®°å½•ä¸­æœªæ‰¾åˆ° 'season_number'ï¼å°†æŒ‰æ•´å­£è®¢é˜…ï¼Œå¯èƒ½å¯¼è‡´é—®é¢˜ï¼")

    # --- 4. å¤„ç†æ–‡ä»¶åæ’é™¤é€»è¾‘ ---
    original_filename = item_details.get('filename')
    if original_filename:
        exclusion_keywords_list = _extract_exclusion_keywords_from_filename(original_filename)
        
        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜… æ ¸å¿ƒé€»è¾‘é‡æ„ â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
        # åªæœ‰åœ¨æå–åˆ°æœ‰æ•ˆå…³é”®å­—æ—¶ï¼Œæ‰æ„å»ºå¹¶åº”ç”¨â€œä¸”(AND)â€é€»è¾‘çš„æ­£åˆ™è¡¨è¾¾å¼
        if exclusion_keywords_list:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼çš„æ­£å‘å…ˆè¡Œæ–­è¨€ (positive lookahead) æ¥å®ç° AND é€»è¾‘
            # ä¾‹å¦‚: (?=.*1080p)(?=.*x265)(?=.*GROUP)
            # è¿™æ„å‘³ç€æ ‡é¢˜ä¸­å¿…é¡»åŒæ—¶åŒ…å« "1080p", "x265", å’Œ "GROUP"
            and_regex_parts = [f"(?=.*{re.escape(k)})" for k in exclusion_keywords_list]
            payload['exclude'] = "".join(and_regex_parts)
            logger.info(f"  âœ ç²¾å‡†æ’é™¤æ¨¡å¼ï¼šå·²ä¸ºã€Š{item_name}ã€‹ç”Ÿæˆ AND é€»è¾‘æ­£åˆ™: {payload['exclude']}")
        else:
            # å¦‚æœåˆ—è¡¨ä¸ºç©ºï¼Œè¯´æ˜æ–‡ä»¶åå¾ˆå¹²å‡€ï¼Œæ²¡æœ‰ä»»ä½•å¯ä¾›æ’é™¤çš„ç‰¹å¾
            # æ­¤æ—¶æˆ‘ä»¬ä¸æ·»åŠ ä»»ä½• exclude å‚æ•°ï¼Œè¿™æ˜¯æœ€å®‰å…¨çš„åšæ³•
            logger.info(f"  âœ… æ–‡ä»¶ååˆ†æå®Œæˆï¼Œæœªæå–åˆ°æœ‰æ•ˆæŠ€æœ¯æˆ–å‘å¸ƒç»„å…³é”®å­—ï¼Œä¸æ·»åŠ æ’é™¤è§„åˆ™ã€‚")
        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

    else:
        logger.info("  ğŸ¤· æ–‡ä»¶åä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œæ— æ³•æå–å…³é”®å­—ã€‚")

    use_custom_subscribe = config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_USE_CUSTOM_RESUBSCRIBE, False)
    if not use_custom_subscribe or not rule:
        log_reason = "è‡ªå®šä¹‰æ´—ç‰ˆæœªå¼€å¯" if not use_custom_subscribe else "æœªåŒ¹é…åˆ°è§„åˆ™"
        logger.info(f"  âœ ã€Š{item_name}ã€‹å°†ä½¿ç”¨å…¨å±€æ´—ç‰ˆ ({log_reason})ã€‚")
        
        return payload

    rule_name = rule.get('name', 'æœªçŸ¥è§„åˆ™')
    final_include_lookaheads = []

    # --- åˆ†è¾¨ç‡ã€è´¨é‡ (é€»è¾‘ä¸å˜) ---
    if rule.get("resubscribe_resolution_enabled"):
        threshold = rule.get("resubscribe_resolution_threshold")
        target_resolution = None
        if threshold == 3840: target_resolution = "4k"
        elif threshold == 1920: target_resolution = "1080p"
        if target_resolution:
            payload['resolution'] = target_resolution
            logger.info(f"  âœ ã€Š{item_name}ã€‹æŒ‰è§„åˆ™ '{rule_name}' è¿½åŠ è¿‡æ»¤å™¨ - åˆ†è¾¨ç‡: {target_resolution}")
    if rule.get("resubscribe_quality_enabled"):
        quality_list = rule.get("resubscribe_quality_include")
        if isinstance(quality_list, list) and quality_list:
            payload['quality'] = ",".join(quality_list)
            logger.info(f"  âœ ã€Š{item_name}ã€‹æŒ‰è§„åˆ™ '{rule_name}' è¿½åŠ è¿‡æ»¤å™¨ - è´¨é‡: {payload['quality']}")
    
    # --- ç‰¹æ•ˆè®¢é˜…é€»è¾‘ (å®æˆ˜ä¼˜åŒ–) ---
    if rule.get("resubscribe_effect_enabled"):
        effect_list = rule.get("resubscribe_effect_include", [])
        if isinstance(effect_list, list) and effect_list:
            simple_effects_for_payload = set()
            
            EFFECT_HIERARCHY = ["dovi_p8", "dovi_p7", "dovi_p5", "dovi_other", "hdr10+", "hdr", "sdr"]
            # â˜…â˜…â˜… æ ¸å¿ƒä¿®æ”¹ï¼šå°† "dv" åŠ å…¥æ­£åˆ™ â˜…â˜…â˜…
            EFFECT_PARAM_MAP = {
                "dovi_p8": ("(?=.*(dovi|dolby|dv))(?=.*hdr)", "dovi"),
                "dovi_p7": ("(?=.*(dovi|dolby|dv))(?=.*(p7|profile.?7))", "dovi"),
                "dovi_p5": ("(?=.*(dovi|dolby|dv))", "dovi"),
                "dovi_other": ("(?=.*(dovi|dolby|dv))", "dovi"),
                "hdr10+": ("(?=.*(hdr10\+|hdr10plus))", "hdr10+"),
                "hdr": ("(?=.*hdr)", "hdr")
            }
            OLD_EFFECT_MAP = {"æœæ¯”è§†ç•Œ": "dovi_other", "HDR": "hdr"}

            highest_req_priority = 999
            best_effect_choice = None
            for choice in effect_list:
                normalized_choice = OLD_EFFECT_MAP.get(choice, choice)
                try:
                    priority = EFFECT_HIERARCHY.index(normalized_choice)
                    if priority < highest_req_priority:
                        highest_req_priority = priority
                        best_effect_choice = normalized_choice
                except ValueError: continue
            
            if best_effect_choice:
                regex_pattern, simple_effect = EFFECT_PARAM_MAP.get(best_effect_choice, (None, None))
                if regex_pattern:
                    final_include_lookaheads.append(regex_pattern)
                if simple_effect:
                    simple_effects_for_payload.add(simple_effect)

            if simple_effects_for_payload:
                 payload['effect'] = ",".join(simple_effects_for_payload)

    # --- éŸ³è½¨ã€å­—å¹•å¤„ç† (é€»è¾‘ä¸å˜) ---
    if rule.get("resubscribe_audio_enabled"):
        audio_langs = rule.get("resubscribe_audio_missing_languages", [])
        if isinstance(audio_langs, list) and audio_langs:
            audio_keywords = [k for lang in audio_langs for k in AUDIO_SUBTITLE_KEYWORD_MAP.get(lang, [])]
            if audio_keywords:
                final_include_lookaheads.append(f"(?=.*({'|'.join(sorted(list(set(audio_keywords)), key=len, reverse=True))}))")

    if rule.get("resubscribe_subtitle_effect_only"):
        final_include_lookaheads.append("(?=.*ç‰¹æ•ˆ)")
    elif rule.get("resubscribe_subtitle_enabled"):
        subtitle_langs = rule.get("resubscribe_subtitle_missing_languages", [])
        if isinstance(subtitle_langs, list) and subtitle_langs:
            subtitle_keywords = [k for lang in subtitle_langs for k in AUDIO_SUBTITLE_KEYWORD_MAP.get(f"sub_{lang}", [])]
            if subtitle_keywords:
                final_include_lookaheads.append(f"(?=.*({'|'.join(sorted(list(set(subtitle_keywords)), key=len, reverse=True))}))")

    if final_include_lookaheads:
        payload['include'] = "".join(final_include_lookaheads)
        logger.info(f"  âœ ã€Š{item_name}ã€‹æŒ‰è§„åˆ™ '{rule_name}' ç”Ÿæˆçš„ AND æ­£åˆ™è¿‡æ»¤å™¨(ç²¾ç­›): {payload['include']}")

    return payload

def _item_needs_resubscribe(item_details: dict, config: dict, media_metadata: Optional[dict] = None) -> tuple[bool, str]:
    """
    ã€V12 - åŠŸèƒ½å®Œæ•´Â·æœ€ç»ˆç‰ˆã€‘
    - æ¢å¤äº†æ‰€æœ‰æ£€æŸ¥é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼šåˆ†è¾¨ç‡ã€è´¨é‡ã€ç‰¹æ•ˆã€éŸ³è½¨å’Œå­—å¹•ã€‚
    - æ­¤ç‰ˆæœ¬è°ƒç”¨å…¨å±€çš„ã€æœ€æ–°çš„ _get_standardized_effect å‡½æ•°æ¥åšå†³ç­–ã€‚
    """
    item_name = item_details.get('Name', 'æœªçŸ¥é¡¹ç›®')
    logger.trace(f"  âœ å¼€å§‹ä¸ºã€Š{item_name}ã€‹æ£€æŸ¥æ´—ç‰ˆéœ€æ±‚ ---")
    
    media_streams = item_details.get('MediaStreams', [])
    file_path = item_details.get('Path', '')
    file_name_lower = os.path.basename(file_path).lower() if file_path else ""

    reasons = []
    video_stream = next((s for s in media_streams if s.get('Type') == 'Video'), None)

    CHINESE_LANG_CODES = {'chi', 'zho', 'chs', 'cht', 'zh-cn', 'zh-hans', 'zh-sg', 'cmn', 'yue'}
    CHINESE_SPEAKING_REGIONS = {'ä¸­å›½', 'ä¸­å›½å¤§é™†', 'é¦™æ¸¯', 'ä¸­å›½é¦™æ¸¯', 'å°æ¹¾', 'ä¸­å›½å°æ¹¾', 'æ–°åŠ å¡'}

    # 1. åˆ†è¾¨ç‡æ£€æŸ¥
    try:
        if config.get("resubscribe_resolution_enabled"):
            if not video_stream:
                reasons.append("æ— è§†é¢‘æµä¿¡æ¯")
            else:
                # â˜…â˜…â˜… 2. (ä¿®æ”¹) ä½¿ç”¨ç­‰çº§ç³»ç»Ÿè¿›è¡Œåˆ¤æ–­ â˜…â˜…â˜…
                
                # ä»é…ç½®ä¸­è·å–ç”¨æˆ·è®¾ç½®çš„å®½åº¦é˜ˆå€¼ (ä¾‹å¦‚ 1920)
                threshold_width = int(config.get("resubscribe_resolution_threshold") or 1920)
                
                # è·å–ç”¨æˆ·è¦æ±‚çš„ç­‰çº§
                required_tier, required_tier_name = _get_resolution_tier(threshold_width, 0)

                # è·å–å½“å‰è§†é¢‘çš„å®é™…ç­‰çº§
                current_width = int(video_stream.get('Width') or 0)
                current_height = int(video_stream.get('Height') or 0)
                current_tier, _ = _get_resolution_tier(current_width, current_height)

                # åªæœ‰å½“å‰ç­‰çº§ä¸¥æ ¼å°äºè¦æ±‚ç­‰çº§æ—¶ï¼Œæ‰æ ‡è®°
                if current_tier < required_tier:
                    reasons.append(f"åˆ†è¾¨ç‡ < {required_tier_name}")

    except (ValueError, TypeError) as e:
        logger.warning(f"  âœ [åˆ†è¾¨ç‡æ£€æŸ¥] å¤„ç†æ—¶å‘ç”Ÿç±»å‹é”™è¯¯: {e}")

    # 2. è´¨é‡æ£€æŸ¥
    try:
        if config.get("resubscribe_quality_enabled"):
            required_list = config.get("resubscribe_quality_include", [])
            if isinstance(required_list, list) and required_list:
                required_list_lower = [str(q).lower() for q in required_list]
                if not any(term in file_name_lower for term in required_list_lower):
                    reasons.append("è´¨é‡ä¸ç¬¦")
    except Exception as e:
        logger.warning(f"  âœ [è´¨é‡æ£€æŸ¥] å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    # 3. ç‰¹æ•ˆæ£€æŸ¥ (è°ƒç”¨æœ€æ–°çš„å…¨å±€å‡½æ•°)
    try:
        if config.get("resubscribe_effect_enabled"):
            user_choices = config.get("resubscribe_effect_include", [])
            if isinstance(user_choices, list) and user_choices:
                EFFECT_HIERARCHY = ["dovi_p8", "dovi_p7", "dovi_p5", "dovi_other", "hdr10+", "hdr", "sdr"]
                OLD_EFFECT_MAP = {"æœæ¯”è§†ç•Œ": "dovi_other", "HDR": "hdr"}
                highest_req_priority = 999
                for choice in user_choices:
                    normalized_choice = OLD_EFFECT_MAP.get(choice, choice)
                    try:
                        priority = EFFECT_HIERARCHY.index(normalized_choice)
                        if priority < highest_req_priority:
                            highest_req_priority = priority
                    except ValueError:
                        continue
                
                if highest_req_priority < 999:
                    current_effect = _get_standardized_effect(file_name_lower, video_stream)
                    current_priority = EFFECT_HIERARCHY.index(current_effect)
                    if current_priority > highest_req_priority:
                        reasons.append("ç‰¹æ•ˆä¸ç¬¦")
    except Exception as e:
        logger.warning(f"  âœ [ç‰¹æ•ˆæ£€æŸ¥] å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    # 4. æ–‡ä»¶å¤§å°æ£€æŸ¥ 
    try:
        if config.get("resubscribe_filesize_enabled"):
            # ä» MediaSources è·å–æ–‡ä»¶å¤§å°ï¼ˆå•ä½ï¼šå­—èŠ‚ï¼‰
            media_source = item_details.get('MediaSources', [{}])[0]
            file_size_bytes = media_source.get('Size')
            
            if file_size_bytes:
                # è·å–è§„åˆ™é…ç½®
                operator = config.get("resubscribe_filesize_operator", 'lt')
                threshold_gb = float(config.get("resubscribe_filesize_threshold_gb", 10.0))
                
                # å°†æ–‡ä»¶å¤§å°ä» Bytes è½¬æ¢ä¸º GB
                file_size_gb = file_size_bytes / (1024**3)

                # æ ¹æ®æ“ä½œç¬¦è¿›è¡Œæ¯”è¾ƒ
                needs_resubscribe = False
                reason_text = ""
                if operator == 'lt' and file_size_gb < threshold_gb:
                    needs_resubscribe = True
                    reason_text = f"æ–‡ä»¶ < {threshold_gb} GB"
                elif operator == 'gt' and file_size_gb > threshold_gb:
                    needs_resubscribe = True
                    reason_text = f"æ–‡ä»¶ > {threshold_gb} GB"
                
                if needs_resubscribe:
                    reasons.append(reason_text)

    except (ValueError, TypeError, IndexError) as e:
        logger.warning(f"  âœ [æ–‡ä»¶å¤§å°æ£€æŸ¥] å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    # 5. éŸ³è½¨å’Œå­—å¹•æ£€æŸ¥
    def _is_exempted_from_chinese_check(item_details: dict) -> bool:
        """
        ã€V5 - åŸå§‹æ ‡é¢˜ç»ˆæç‰ˆã€‘
        - é‡‡çº³ç”¨æˆ·çš„ç»ä½³å»ºè®®ï¼Œä½¿ç”¨ TMDB çš„ original_title ä½œä¸ºæ ¸å¿ƒåˆ¤æ–­ä¾æ®ã€‚
        - è¿™æ˜¯ç›®å‰æœ€ç²¾å‡†ã€æœ€èƒ½æŠµæŠ—æœ¬åœ°åŒ–å‘½åå¹²æ‰°çš„æ–¹æ¡ˆã€‚
        - è±å…æ¡ä»¶ (æŒ‰ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥):
          1. (æœ€é«˜) åª’ä½“çš„åˆ¶ç‰‡å›½å®¶/åœ°åŒºæ˜¯åè¯­åŒºã€‚
          2. (æ¬¡é«˜) åª’ä½“çš„åŸå§‹æ ‡é¢˜ (original_title) æ˜¯ä¸­æ–‡ã€‚
          3. åª’ä½“å·²åŒ…å«ä¸­æ–‡éŸ³è½¨ã€‚
          4. åª’ä½“å·²åŒ…å«ä¸­æ–‡å­—å¹•ã€‚
        """
        import re
        
        # å‡†å¤‡å…³é”®è¯å’Œè¯­è¨€ä»£ç 
        CHINESE_LANG_CODES = {'chi', 'zho', 'chs', 'cht', 'zh-cn', 'zh-hans', 'zh-sg', 'cmn', 'yue'}
        CHINESE_SPEAKING_REGIONS = {'ä¸­å›½', 'ä¸­å›½å¤§é™†', 'é¦™æ¸¯', 'ä¸­å›½é¦™æ¸¯', 'å°æ¹¾', 'ä¸­å›½å°æ¹¾', 'æ–°åŠ å¡'}

        # ä¼˜å…ˆçº§ 1: æ£€æŸ¥åˆ¶ç‰‡å›½å®¶/åœ°åŒº (ä¾ç„¶æ˜¯æœ€å¯é çš„ä¾æ®ä¹‹ä¸€)
        if media_metadata and media_metadata.get('countries_json'):
            if not set(media_metadata['countries_json']).isdisjoint(CHINESE_SPEAKING_REGIONS):
                return True

        # â˜…â˜…â˜… ä¼˜å…ˆçº§ 2: æ£€æŸ¥ TMDB çš„åŸå§‹æ ‡é¢˜ (æ ¸å¿ƒä¿®æ”¹) â˜…â˜…â˜…
        if media_metadata and (original_title := media_metadata.get('original_title')):
            # åŒ¹é…ä¸­æ–‡å­—ç¬¦çš„ Unicode èŒƒå›´
            chinese_chars = re.findall(r'[\u4e00-\u9fff]', original_title)
            # å¦‚æœåŸå§‹æ ‡é¢˜ä¸­åŒ…å«2ä¸ªæˆ–ä»¥ä¸Šçš„ä¸­æ–‡å­—ç¬¦ï¼Œå°±è®¤å®šä¸ºåè¯­å†…å®¹
            if len(chinese_chars) >= 2:
                return True

        # ä¼˜å…ˆçº§ 3: æ£€æŸ¥ç°æœ‰éŸ³è½¨
        detected_audio_langs = _get_detected_languages_from_streams(media_streams, 'Audio', AUDIO_SUBTITLE_KEYWORD_MAP)
        if 'chi' in detected_audio_langs or 'yue' in detected_audio_langs:
            return True
            
        # ä¼˜å…ˆçº§ 4: æ£€æŸ¥ç°æœ‰å­—å¹•
        detected_subtitle_langs = _get_detected_languages_from_streams(media_streams, 'Subtitle', AUDIO_SUBTITLE_KEYWORD_MAP)
        if 'chi' in detected_subtitle_langs or 'yue' in detected_subtitle_langs:
            return True

        # æ³¨æ„ï¼šæˆ‘ä»¬å·²ç»å½»åº•ç§»é™¤äº†å¯¹æœ¬åœ°æ˜¾ç¤ºåç§° (item_details['Name']) çš„æ£€æŸ¥ï¼Œå› ä¸ºå®ƒä¼šé€ æˆè¯¯åˆ¤
        return False

    is_exempted = _is_exempted_from_chinese_check(item_details)
    
    try:
        if config.get("resubscribe_audio_enabled") and not is_exempted:
            required_langs = set(config.get("resubscribe_audio_missing_languages", []))
            if 'chi' in required_langs or 'yue' in required_langs:
                # â˜…â˜…â˜… è®©éŸ³è½¨åˆ¤æ–­ä¹Ÿä½¿ç”¨æ™ºèƒ½å‡½æ•° â˜…â˜…â˜…
                detected_audio_langs = _get_detected_languages_from_streams(
                    media_streams, 'Audio', AUDIO_SUBTITLE_KEYWORD_MAP
                )
                if 'chi' not in detected_audio_langs and 'yue' not in detected_audio_langs:
                    reasons.append("ç¼ºä¸­æ–‡éŸ³è½¨")
    except Exception as e:
        logger.warning(f"  âœ [éŸ³è½¨æ£€æŸ¥] å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    try:
        if config.get("resubscribe_subtitle_enabled") and not is_exempted:
            required_langs = set(config.get("resubscribe_subtitle_missing_languages", []))
            if 'chi' in required_langs:
                detected_subtitle_langs = _get_detected_languages_from_streams(
                    media_streams, 'Subtitle', AUDIO_SUBTITLE_KEYWORD_MAP
                )
                
                # â˜…â˜…â˜… æ–°å¢çš„æ ¸å¿ƒé€»è¾‘ï¼šå¤–æŒ‚å­—å¹•è±å…è§„åˆ™ â˜…â˜…â˜…
                # å¦‚æœé€šè¿‡å¸¸è§„æ–¹å¼æ²¡æ‰¾åˆ°ä¸­å­—ï¼Œåˆ™æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¤–æŒ‚å­—å¹•
                if 'chi' not in detected_subtitle_langs and 'yue' not in detected_subtitle_langs:
                    if any(s.get('IsExternal') for s in media_streams if s.get('Type') == 'Subtitle'):
                        # å¦‚æœå­˜åœ¨å¤–æŒ‚å­—å¹•ï¼Œå°±é»˜è®¤å®ƒæ˜¯ä¸­æ–‡ï¼Œå¹¶åŠ å…¥åˆ°æ£€æµ‹ç»“æœä¸­
                        detected_subtitle_langs.add('chi')

                # æœ€ç»ˆæ£€æŸ¥
                if 'chi' not in detected_subtitle_langs and 'yue' not in detected_subtitle_langs:
                    reasons.append("ç¼ºä¸­æ–‡å­—å¹•")
    except Exception as e:
        logger.warning(f"  âœ [å­—å¹•æ£€æŸ¥] å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                 
    if reasons:
        final_reason = "; ".join(sorted(list(set(reasons))))
        logger.info(f"  âœ ã€Š{item_name}ã€‹éœ€è¦æ´—ç‰ˆã€‚åŸå› : {final_reason}")
        return True, final_reason
    else:
        logger.debug(f"  âœ ã€Š{item_name}ã€‹è´¨é‡è¾¾æ ‡ã€‚")
        return False, ""

# â˜…â˜…â˜… ç²¾å‡†æ‰¹é‡è®¢é˜…çš„åå°ä»»åŠ¡ â˜…â˜…â˜…
def task_resubscribe_batch(processor, item_ids: List[str]):
    """ã€ç²¾å‡†æ‰¹é‡ç‰ˆã€‘åå°ä»»åŠ¡ï¼šåªè®¢é˜…åˆ—è¡¨ä¸­æŒ‡å®šçš„ä¸€æ‰¹åª’ä½“é¡¹ã€‚"""
    task_name = "æ‰¹é‡åª’ä½“æ´—ç‰ˆ"
    logger.info(f"--- å¼€å§‹æ‰§è¡Œ '{task_name}' ä»»åŠ¡ (ç²¾å‡†æ¨¡å¼) ---")
    
    items_to_subscribe = []
    
    try:
        # 1. ä»æ•°æ®åº“ä¸­ç²¾ç¡®è·å–éœ€è¦å¤„ç†çš„é¡¹ç›®
        with connection.get_db_connection() as conn:
            cursor = conn.cursor()
            sql = "SELECT * FROM resubscribe_cache WHERE item_id = ANY(%s)"
            cursor.execute(sql, (item_ids,))
            items_to_subscribe = cursor.fetchall()

        total_to_process = len(items_to_subscribe)
        if total_to_process == 0:
            task_manager.update_status_from_thread(100, "ä»»åŠ¡å®Œæˆï¼šé€‰ä¸­çš„é¡¹ç›®ä¸­æ²¡æœ‰éœ€è¦è®¢é˜…çš„é¡¹ã€‚")
            return

        logger.info(f"  âœ ç²¾å‡†ä»»åŠ¡ï¼šå…±æ‰¾åˆ° {total_to_process} ä¸ªé¡¹ç›®å¾…å¤„ç†ï¼Œå°†å¼€å§‹è®¢é˜…...")
        
        # 2. åç»­çš„è®¢é˜…ã€åˆ é™¤ã€é…é¢æ£€æŸ¥é€»è¾‘å’Œâ€œä¸€é”®æ´—ç‰ˆâ€å®Œå…¨ä¸€è‡´
        all_rules = resubscribe_db.get_all_resubscribe_rules()
        config = processor.config
        delay = float(config.get(constants.CONFIG_OPTION_RESUBSCRIBE_DELAY_SECONDS, 1.5))
        resubscribed_count = 0
        deleted_count = 0

        for i, item in enumerate(items_to_subscribe):
            if processor.is_stop_requested():
                logger.info("  âœ ä»»åŠ¡è¢«ç”¨æˆ·ä¸­æ­¢ã€‚")
                break
            
            current_quota = settings_db.get_subscription_quota()
            if current_quota <= 0:
                logger.warning("  âœ æ¯æ—¥è®¢é˜…é…é¢å·²ç”¨å°½ï¼Œä»»åŠ¡æå‰ç»“æŸã€‚")
                break

            item_id = item.get('item_id')
            item_name = item.get('item_name')
            task_manager.update_status_from_thread(
                int((i / total_to_process) * 100), 
                f"({i+1}/{total_to_process}) [é…é¢:{current_quota}] æ­£åœ¨è®¢é˜…: {item_name}"
            )

            # 1. è·å–å½“å‰é¡¹ç›®åŒ¹é…çš„è§„åˆ™
            matched_rule_id = item.get('matched_rule_id')
            rule = next((r for r in all_rules if r['id'] == matched_rule_id), None) if matched_rule_id else None

            # 2. è®©â€œæ™ºèƒ½è·å®˜â€é…ç‰Œ (item å­—å…¸æœ¬èº«å°±åŒ…å«äº†éœ€è¦çš„ä¿¡æ¯)
            payload = build_resubscribe_payload(item, rule)

            if not payload:
                logger.warning(f"ä¸ºã€Š{item.get('item_name')}ã€‹æ„å»ºè®¢é˜…Payloadå¤±è´¥ï¼Œå·²è·³è¿‡ã€‚")
                continue # è·³è¿‡è¿™ä¸ªé¡¹ç›®ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª

            # 3. å‘é€è®¢é˜…
            success = moviepilot.subscribe_with_custom_payload(payload, config)
            
            if success:
                settings_db.decrement_subscription_quota()
                resubscribed_count += 1
                
                matched_rule_id = item.get('matched_rule_id')
                rule = next((r for r in all_rules if r['id'] == matched_rule_id), None) if matched_rule_id else None

                if rule and rule.get('delete_after_resubscribe'):
                    delete_success = emby.delete_item(
                        item_id=item_id, emby_server_url=processor.emby_url,
                        emby_api_key=processor.emby_api_key, user_id=processor.emby_user_id
                    )
                    if delete_success:
                        resubscribe_db.delete_resubscribe_cache_item(item_id)
                        deleted_count += 1
                    else:
                        resubscribe_db.update_resubscribe_item_status(item_id, 'subscribed')
                else:
                    resubscribe_db.update_resubscribe_item_status(item_id, 'subscribed')
                
                if i < total_to_process - 1: time.sleep(delay)

        final_message = f"æ‰¹é‡ä»»åŠ¡å®Œæˆï¼æˆåŠŸæäº¤ {resubscribed_count} ä¸ªè®¢é˜…ï¼Œåˆ é™¤ {deleted_count} ä¸ªåª’ä½“é¡¹ã€‚"
        task_manager.update_status_from_thread(100, final_message)

    except Exception as e:
        logger.error(f"æ‰§è¡Œ '{task_name}' ä»»åŠ¡æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        task_manager.update_status_from_thread(-1, f"ä»»åŠ¡å¤±è´¥: {e}")

# --- ä¸€é”®æ´—ç‰ˆ ---
def task_resubscribe_library(processor):
    """ åå°ä»»åŠ¡ï¼šè®¢é˜…æˆåŠŸåï¼Œæ ¹æ®è§„åˆ™åˆ é™¤æˆ–æ›´æ–°ç¼“å­˜ã€‚"""
    task_name = "åª’ä½“æ´—ç‰ˆ"
    logger.info(f"--- å¼€å§‹æ‰§è¡Œ '{task_name}' ä»»åŠ¡ ---")
    
    config = processor.config
    
    try:
        all_rules = resubscribe_db.get_all_resubscribe_rules()
        delay = float(config.get(constants.CONFIG_OPTION_RESUBSCRIBE_DELAY_SECONDS, 1.5))

        with connection.get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM resubscribe_cache WHERE status = 'needed'")
            items_to_resubscribe = cursor.fetchall()

        total_needed = len(items_to_resubscribe)
        if total_needed == 0:
            task_manager.update_status_from_thread(100, "ä»»åŠ¡å®Œæˆï¼šæ²¡æœ‰å‘ç°éœ€è¦æ´—ç‰ˆçš„é¡¹ç›®ã€‚")
            return

        logger.info(f"  âœ å…±æ‰¾åˆ° {total_needed} ä¸ªé¡¹ç›®å¾…å¤„ç†ï¼Œå°†å¼€å§‹è®¢é˜…...")
        resubscribed_count = 0
        deleted_count = 0

        for i, item in enumerate(items_to_resubscribe):
            if processor.is_stop_requested(): break
            
            current_quota = settings_db.get_subscription_quota()
            if current_quota <= 0:
                logger.warning("  âœ æ¯æ—¥è®¢é˜…é…é¢å·²ç”¨å°½ï¼Œä»»åŠ¡æå‰ç»“æŸã€‚")
                break

            item_name = item.get('item_name')
            item_id = item.get('item_id')
            task_manager.update_status_from_thread(
                int((i / total_needed) * 100), 
                f"({i+1}/{total_needed}) [é…é¢:{current_quota}] æ­£åœ¨è®¢é˜…: {item_name}"
            )

            # 1. è·å–å½“å‰é¡¹ç›®åŒ¹é…çš„è§„åˆ™
            matched_rule_id = item.get('matched_rule_id')
            rule = next((r for r in all_rules if r['id'] == matched_rule_id), None) if matched_rule_id else None

            # 2. è®©â€œæ™ºèƒ½è·å®˜â€é…ç‰Œ (item å­—å…¸æœ¬èº«å°±åŒ…å«äº†éœ€è¦çš„ä¿¡æ¯)
            payload = build_resubscribe_payload(item, rule)

            if not payload:
                logger.warning(f"ä¸ºã€Š{item.get('item_name')}ã€‹æ„å»ºè®¢é˜…Payloadå¤±è´¥ï¼Œå·²è·³è¿‡ã€‚")
                continue # è·³è¿‡è¿™ä¸ªé¡¹ç›®ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª

            # 3. å‘é€è®¢é˜…
            success = moviepilot.subscribe_with_custom_payload(payload, config)
            
            if success:
                settings_db.decrement_subscription_quota()
                resubscribed_count += 1
                
                matched_rule_id = item.get('matched_rule_id')
                rule = next((r for r in all_rules if r['id'] == matched_rule_id), None) if matched_rule_id else None

                # --- â˜…â˜…â˜… æ ¸å¿ƒé€»è¾‘æ”¹é€ ï¼šæ ¹æ®è§„åˆ™å†³å®šæ˜¯â€œåˆ é™¤â€è¿˜æ˜¯â€œæ›´æ–°â€ â˜…â˜…â˜… ---
                if rule and rule.get('delete_after_resubscribe'):
                    logger.warning(f"  âœ è§„åˆ™ '{rule['name']}' è¦æ±‚åˆ é™¤æºæ–‡ä»¶ï¼Œæ­£åœ¨åˆ é™¤ Emby é¡¹ç›®: {item_name} (ID: {item_id})")
                    
                    id_to_delete = None
                    if item.get('item_type') == 'Season':
                        id_to_delete = item.get('emby_item_id') # å¯¹äºå­£ï¼Œå¿…é¡»ä½¿ç”¨ emby_item_id (å®é™…çš„å­£GUID)
                        if not id_to_delete:
                            logger.error(f"  âœ æ— æ³•åˆ é™¤å­£ '{item_name}' (ç¼“å­˜ID: {item_id})ï¼šemby_item_id (å­£GUID) ä¸ºç©ºã€‚è·³è¿‡åˆ é™¤ã€‚")
                            resubscribe_db.update_resubscribe_item_status(item_id, 'subscribed') # è®¢é˜…æˆåŠŸï¼Œä½†åˆ é™¤å¤±è´¥
                            continue
                    else:
                        id_to_delete = item.get('emby_item_id') or item_id # å¯¹äºç”µå½±æˆ–å‰§é›†ï¼Œä¼˜å…ˆä½¿ç”¨ emby_item_idï¼Œå¦åˆ™å›é€€åˆ° item_id

                    delete_success = emby.delete_item(
                        item_id=id_to_delete, 
                        emby_server_url=processor.emby_url,
                        emby_api_key=processor.emby_api_key, user_id=processor.emby_user_id
                    )
                    if delete_success:
                        # å¦‚æœ Emby é¡¹åˆ é™¤æˆåŠŸï¼Œå°±ä»æˆ‘ä»¬çš„ç¼“å­˜é‡Œä¹Ÿåˆ é™¤
                        resubscribe_db.delete_resubscribe_cache_item(item_id)
                        deleted_count += 1
                    else:
                        # å¦‚æœ Emby é¡¹åˆ é™¤å¤±è´¥ï¼Œé‚£æˆ‘ä»¬åªæ›´æ–°çŠ¶æ€ï¼Œè®©ç”¨æˆ·çŸ¥é“è®¢é˜…æˆåŠŸäº†ä½†åˆ é™¤å¤±è´¥
                        resubscribe_db.update_resubscribe_item_status(item_id, 'subscribed')
                else:
                    # å¦‚æœæ²¡æœ‰åˆ é™¤è§„åˆ™ï¼Œå°±æ­£å¸¸æ›´æ–°çŠ¶æ€
                    resubscribe_db.update_resubscribe_item_status(item_id, 'subscribed')
                
                if i < total_needed - 1: time.sleep(delay)

        final_message = f"ä»»åŠ¡å®Œæˆï¼æˆåŠŸæäº¤ {resubscribed_count} ä¸ªè®¢é˜…ï¼Œå¹¶æ ¹æ®è§„åˆ™åˆ é™¤äº† {deleted_count} ä¸ªåª’ä½“é¡¹ã€‚"
        if not processor.is_stop_requested() and current_quota <= 0:
             final_message = f"é…é¢ç”¨å°½ï¼æˆåŠŸæäº¤ {resubscribed_count} ä¸ªè®¢é˜…ï¼Œåˆ é™¤ {deleted_count} ä¸ªåª’ä½“é¡¹ã€‚"
        task_manager.update_status_from_thread(100, final_message)

    except Exception as e:
        logger.error(f"æ‰§è¡Œ '{task_name}' ä»»åŠ¡æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        task_manager.update_status_from_thread(-1, f"ä»»åŠ¡å¤±è´¥: {e}")

# â˜…â˜…â˜… ç²¾å‡†æ‰¹é‡åˆ é™¤çš„åå°ä»»åŠ¡ â˜…â˜…â˜…
def task_delete_batch(processor, item_ids: List[str]):
    """ã€ç²¾å‡†æ‰¹é‡ç‰ˆã€‘åå°ä»»åŠ¡ï¼šåªåˆ é™¤åˆ—è¡¨ä¸­æŒ‡å®šçš„ä¸€æ‰¹åª’ä½“é¡¹ã€‚"""
    task_name = "æ‰¹é‡åˆ é™¤åª’ä½“"
    logger.info(f"--- å¼€å§‹æ‰§è¡Œ '{task_name}' ä»»åŠ¡ (ç²¾å‡†æ¨¡å¼) ---")
    
    items_to_delete = []
    try:
        with connection.get_db_connection() as conn:
            cursor = conn.cursor()
            sql = "SELECT * FROM resubscribe_cache WHERE item_id = ANY(%s)"
            cursor.execute(sql, (item_ids,))
            items_to_delete = cursor.fetchall()

        total_to_process = len(items_to_delete)
        if total_to_process == 0:
            task_manager.update_status_from_thread(100, "ä»»åŠ¡å®Œæˆï¼šé€‰ä¸­çš„é¡¹ç›®ä¸­æ²¡æœ‰å¯åˆ é™¤çš„é¡¹ã€‚")
            return

        logger.info(f"  âœ ç²¾å‡†åˆ é™¤ï¼šå…±æ‰¾åˆ° {total_to_process} ä¸ªé¡¹ç›®å¾…å¤„ç†...")
        deleted_count = 0

        for i, item in enumerate(items_to_delete):
            if processor.is_stop_requested(): break
            
            item_id = item.get('item_id')
            item_name = item.get('item_name')
            task_manager.update_status_from_thread(
                int((i / total_to_process) * 100), 
                f"({i+1}/{total_to_process}) æ­£åœ¨åˆ é™¤: {item_name}"
            )
            
            id_to_delete = None
            if item.get('item_type') == 'Season':
                id_to_delete = item.get('emby_item_id') # å¯¹äºå­£ï¼Œå¿…é¡»ä½¿ç”¨ emby_item_id (å®é™…çš„å­£GUID)
                if not id_to_delete:
                    logger.error(f"  âœ æ— æ³•åˆ é™¤å­£ '{item_name}' (ç¼“å­˜ID: {item_id})ï¼šemby_item_id (å­£GUID) ä¸ºç©ºã€‚è·³è¿‡åˆ é™¤ã€‚")
                    continue
            else:
                id_to_delete = item.get('emby_item_id') or item_id # å¯¹äºç”µå½±æˆ–å‰§é›†ï¼Œä¼˜å…ˆä½¿ç”¨ emby_item_idï¼Œå¦åˆ™å›é€€åˆ° item_id

            delete_success = emby.delete_item(
                item_id=id_to_delete, 
                emby_server_url=processor.emby_url,
                emby_api_key=processor.emby_api_key, user_id=processor.emby_user_id
            )
            if delete_success:
                resubscribe_db.delete_resubscribe_cache_item(item_id)
                deleted_count += 1
            
            time.sleep(0.5) # é¿å…è¯·æ±‚è¿‡å¿«

        final_message = f"æ‰¹é‡åˆ é™¤ä»»åŠ¡å®Œæˆï¼æˆåŠŸåˆ é™¤äº† {deleted_count} ä¸ªåª’ä½“é¡¹ã€‚"
        task_manager.update_status_from_thread(100, final_message)

    except Exception as e:
        logger.error(f"æ‰§è¡Œ '{task_name}' ä»»åŠ¡æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        task_manager.update_status_from_thread(-1, f"ä»»åŠ¡å¤±è´¥: {e}")

def task_update_resubscribe_cache(processor, force_full_update: bool = False):
    """
    - æ¢å¤äº†ç®€æ´çš„å‡½æ•°ç»“æ„ï¼Œæ‰€æœ‰ä¸šåŠ¡é€»è¾‘éƒ½é€šè¿‡è°ƒç”¨æ­£ç¡®çš„å…¨å±€è¾…åŠ©å‡½æ•°å®Œæˆã€‚
    """
    scan_mode = "æ·±åº¦æ¨¡å¼" if force_full_update else "å¿«é€Ÿæ¨¡å¼"
    task_name = f"åˆ·æ–°æ´—ç‰ˆçŠ¶æ€ ({scan_mode})"
    logger.info(f"--- å¼€å§‹æ‰§è¡Œ '{task_name}' ä»»åŠ¡ ---")
    
    try:
        task_manager.update_status_from_thread(0, "æ­£åœ¨åŠ è½½è§„åˆ™å¹¶ç¡®å®šæ‰«æèŒƒå›´...")
        all_enabled_rules = [rule for rule in resubscribe_db.get_all_resubscribe_rules() if rule.get('enabled')]
        library_ids_to_scan = set()
        for rule in all_enabled_rules:
            target_libs = rule.get('target_library_ids')
            if isinstance(target_libs, list):
                library_ids_to_scan.update(target_libs)
        libs_to_process_ids = list(library_ids_to_scan)

        if not libs_to_process_ids:
            task_manager.update_status_from_thread(100, "ä»»åŠ¡è·³è¿‡ï¼šæ²¡æœ‰è§„åˆ™æŒ‡å®šåª’ä½“åº“")
            return
        
        task_manager.update_status_from_thread(10, f"æ­£åœ¨ä» {len(libs_to_process_ids)} ä¸ªç›®æ ‡åº“ä¸­è·å–é¡¹ç›®...")
        all_items_base_info = emby.get_emby_library_items(
            base_url=processor.emby_url, api_key=processor.emby_api_key, user_id=processor.emby_user_id,
            media_type_filter="Movie,Series", library_ids=libs_to_process_ids,
            fields="ProviderIds,Name,Type,ChildCount,_SourceLibraryId"
        ) or []
        
        items_to_process = []
        
        if force_full_update:
            logger.info(f"  âœ [æ·±åº¦æ¨¡å¼] æ­£åœ¨æ¸…ç©ºæ—§ç¼“å­˜ä»¥è¿›è¡Œå…¨é¢åˆ·æ–°...")
            resubscribe_db.clear_resubscribe_cache_except_ignored()
            
            # â˜…â˜…â˜… å…³é”®ä¿®å¤ï¼šæ¸…ç©ºåï¼Œå°†æ‰€æœ‰éå¿½ç•¥çš„é¡¹ç›®ä½œä¸ºå¤„ç†ç›®æ ‡ â˜…â˜…â˜…
            # é‡æ–°è·å–ä¸€æ¬¡ç¼“å­˜ï¼Œè¿™æ¬¡åªå‰©ä¸‹ ignored çš„é¡¹ç›®äº†
            cached_items_after_clear = resubscribe_db.get_all_resubscribe_cache()
            ignored_ids = {item['item_id'] for item in cached_items_after_clear}
            
            # ä»æ‰€æœ‰ Emby é¡¹ç›®ä¸­ï¼Œæ’é™¤æ‰é‚£äº›è¢«å¿½ç•¥çš„
            items_to_process = [item for item in all_items_base_info if item.get('Id') not in ignored_ids]
            logger.info(f"  âœ [æ·±åº¦æ¨¡å¼] å°†å¯¹ {len(items_to_process)} ä¸ªéå¿½ç•¥é¡¹ç›®è¿›è¡Œå…¨é¢åˆ†æã€‚")

        else:
            # --- å¿«é€Ÿæ¨¡å¼ (é€»è¾‘ä¿æŒä¸å˜) ---
            logger.info("  âœ [å¿«é€Ÿæ¨¡å¼] å·²å¯åŠ¨ï¼Œå°†è¿›è¡Œå¢é‡æ‰«æ...")
            cached_items = resubscribe_db.get_all_resubscribe_cache()
            current_emby_ids = {item.get('Id') for item in all_items_base_info}
            cached_ids = {item['item_id'] for item in cached_items}
            
            deleted_ids = list(cached_ids - current_emby_ids)
            if deleted_ids:
                logger.info(f"  âœ [å¿«é€Ÿæ¨¡å¼] å‘ç° {len(deleted_ids)} ä¸ªé¡¹ç›®å·²ä»åª’ä½“åº“ç§»é™¤ï¼Œå°†æ¸…ç†å…¶ç¼“å­˜ã€‚")
                resubscribe_db.delete_resubscribe_cache_items_batch(deleted_ids)
            
            new_item_ids = current_emby_ids - cached_ids
            if new_item_ids:
                logger.info(f"  âœ [å¿«é€Ÿæ¨¡å¼] å‘ç° {len(new_item_ids)} ä¸ªæ–°é¡¹ç›®ï¼Œå°†å¯¹å®ƒä»¬è¿›è¡Œåˆ†æã€‚")
                items_to_process = [item for item in all_items_base_info if item.get('Id') in new_item_ids]
            else:
                logger.info("  âœ [å¿«é€Ÿæ¨¡å¼] æœªå‘ç°æ–°å¢é¡¹ç›®ï¼Œæ— éœ€åˆ†æã€‚")

        # â˜…â˜…â˜… æ— è®ºå“ªç§æ¨¡å¼ï¼Œéƒ½éœ€è¦åœ¨å¤„ç†å‰è·å–æœ€æ–°çš„ç¼“å­˜çŠ¶æ€ â˜…â˜…â˜…
        # å› ä¸ºæ·±åº¦æ¨¡å¼æ¸…ç©ºäº†ç¼“å­˜ï¼Œæ‰€ä»¥éœ€è¦é‡æ–°è·å–
        final_cached_items = resubscribe_db.get_all_resubscribe_cache()
        current_db_status_map = {item['item_id']: item['status'] for item in final_cached_items}

        total = len(items_to_process)
        if total == 0:
            task_manager.update_status_from_thread(100, f"ä»»åŠ¡å®Œæˆï¼š({scan_mode}) æ— éœ€å¤„ç†ä»»ä½•é¡¹ç›®ã€‚")
            return

        logger.info(f"  âœ å°†ä¸º {total} ä¸ªåª’ä½“é¡¹ç›®è·å–è¯¦æƒ…å¹¶æŒ‰è§„åˆ™æ£€æŸ¥æ´—ç‰ˆçŠ¶æ€...")
        cache_update_batch = []
        processed_count = 0
        library_to_rule_map = {}
        for rule in reversed(all_enabled_rules):
            target_libs = rule.get('target_library_ids')
            if isinstance(target_libs, list):
                for lib_id in target_libs:
                    library_to_rule_map[lib_id] = rule

        def process_item_for_cache(item_base_info):
            item_id = item_base_info.get('Id')
            item_name = item_base_info.get('Name')
            source_lib_id = item_base_info.get('_SourceLibraryId')

            if current_db_status_map.get(item_id) == 'ignored': return None
        
            try:
                applicable_rule = library_to_rule_map.get(source_lib_id)
                if not applicable_rule:
                    return { "item_id": item_id, "status": 'ok', "reason": "æ— åŒ¹é…è§„åˆ™" }
                
                item_details = emby.get_emby_item_details(item_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id)
                if not item_details: return None
                
                tmdb_id = item_details.get("ProviderIds", {}).get("Tmdb")
                media_metadata = collection_db.get_media_metadata_by_tmdb_id(tmdb_id) if tmdb_id else None
                item_type = item_details.get('Type')

                # â˜…â˜…â˜… æ ¸å¿ƒæ”¹é€ ï¼šå¦‚æœæ˜¯å‰§é›†ï¼Œåˆ™æŒ‰å­£å¤„ç† â˜…â˜…â˜…
                if item_type == 'Series':
                    seasons = emby.get_series_seasons(item_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id)
                    if not seasons:
                        return None # å¦‚æœå‰§é›†æ²¡æœ‰å­£ä¿¡æ¯ï¼Œåˆ™è·³è¿‡

                    season_cache_results = []
                    
                    for season in seasons:
                        season_number = season.get('IndexNumber')
                        season_id = season.get('Id')
                        if season_number is None or season_id is None:
                            continue

                        season_item_id = f"{item_id}-S{season_number}"
                        
                        first_episode_details = None
                        first_episode_list = emby.get_season_children(season_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id, fields="Id", limit=1)
                        if first_episode_list and (first_episode_id := first_episode_list[0].get('Id')):
                            first_episode_details = emby.get_emby_item_details(first_episode_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id)

                        if not first_episode_details:
                            needs_resubscribe, reason = False, "å­£å†…å®¹ä¸ºç©º"
                        else:
                            needs_resubscribe, reason = _item_needs_resubscribe(first_episode_details, applicable_rule, media_metadata)

                        old_status = current_db_status_map.get(season_item_id)
                        new_status = 'ok' if not needs_resubscribe else ('subscribed' if old_status == 'subscribed' else 'needed')
                        
                        # --- ä»¥ä¸‹æ‰€æœ‰æ˜¾ç¤ºä¿¡æ¯çš„ç”Ÿæˆé€»è¾‘ï¼Œéƒ½åŸºäº first_episode_details ---
                        media_streams = first_episode_details.get('MediaStreams', []) if first_episode_details else []
                        video_stream = next((s for s in media_streams if s.get('Type') == 'Video'), None)
                        file_name_lower = os.path.basename(first_episode_details.get('Path', '')).lower() if first_episode_details else ""
                        
                        raw_effect_tag = _get_standardized_effect(file_name_lower, video_stream)
                        EFFECT_DISPLAY_MAP = {'dovi_p8': 'DoVi P8', 'dovi_p7': 'DoVi P7', 'dovi_p5': 'DoVi P5', 'dovi_other': 'DoVi (Other)', 'hdr10+': 'HDR10+', 'hdr': 'HDR', 'sdr': 'SDR'}
                        effect_str = EFFECT_DISPLAY_MAP.get(raw_effect_tag, raw_effect_tag.upper())

                        resolution_str = "æœªçŸ¥"
                        if video_stream:
                            width, height = int(video_stream.get('Width') or 0), int(video_stream.get('Height') or 0)
                            _, resolution_str = _get_resolution_tier(width, height)
                        
                        quality_str = _extract_quality_tag_from_filename(file_name_lower, video_stream)
                        
                        detected_audio_langs = _get_detected_languages_from_streams(media_streams, 'Audio', AUDIO_SUBTITLE_KEYWORD_MAP)
                        AUDIO_DISPLAY_MAP = {'chi': 'å›½è¯­', 'yue': 'ç²¤è¯­', 'eng': 'è‹±è¯­', 'jpn': 'æ—¥è¯­'}
                        audio_str = ', '.join(sorted([AUDIO_DISPLAY_MAP.get(lang, lang) for lang in detected_audio_langs])) or 'æ— '
                        
                        detected_sub_langs = _get_detected_languages_from_streams(media_streams, 'Subtitle', AUDIO_SUBTITLE_KEYWORD_MAP)
                        if 'chi' not in detected_sub_langs and 'yue' not in detected_sub_langs and any(s.get('IsExternal') for s in media_streams if s.get('Type') == 'Subtitle'):
                            detected_sub_langs.add('chi')
                        SUB_DISPLAY_MAP = {'chi': 'ä¸­å­—', 'yue': 'ç²¤å­—', 'eng': 'è‹±æ–‡', 'jpn': 'æ—¥æ–‡'}
                        subtitle_str = ', '.join(sorted([SUB_DISPLAY_MAP.get(lang, lang) for lang in detected_sub_langs])) or 'æ— '

                        file_path = first_episode_details.get('Path') if first_episode_details else None
                        filename = os.path.basename(file_path) if file_path else None

                        season_cache_item = {
                            "item_id": season_item_id,
                            "emby_item_id": season_id,
                            "series_id": item_id,
                            "season_number": season_number,
                            "item_name": f"{item_name} - ç¬¬ {season_number} å­£",
                            "tmdb_id": tmdb_id,
                            "item_type": "Season",
                            "status": new_status,
                            "reason": reason,
                            "resolution_display": resolution_str,
                            "quality_display": quality_str,
                            "effect_display": effect_str,
                            "audio_display": audio_str,
                            "subtitle_display": subtitle_str,
                            "audio_languages_raw": list(detected_audio_langs),
                            "subtitle_languages_raw": list(detected_sub_langs),
                            "matched_rule_id": applicable_rule.get('id'),
                            "matched_rule_name": applicable_rule.get('name'),
                            "source_library_id": source_lib_id,
                            "path": file_path,
                            "filename": filename
                        }
                        season_cache_results.append(season_cache_item)
                    
                    return season_cache_results # è¿”å›åŒ…å«æ‰€æœ‰å­£ç»“æœçš„åˆ—è¡¨

                # å¦‚æœä¸æ˜¯å‰§é›†ï¼ˆæ˜¯ç”µå½±ï¼‰ï¼Œåˆ™æ²¿ç”¨æ—§é€»è¾‘
                else:
                    needs_resubscribe, reason = _item_needs_resubscribe(item_details, applicable_rule, media_metadata)
                    old_status = current_db_status_map.get(item_id)
                    new_status = 'ok' if not needs_resubscribe else ('subscribed' if old_status == 'subscribed' else 'needed')
                    
                    media_streams = item_details.get('MediaStreams', [])
                    video_stream = next((s for s in media_streams if s.get('Type') == 'Video'), None)
                    file_name_lower = os.path.basename(item_details.get('Path', '')).lower()
                    
                    raw_effect_tag = _get_standardized_effect(file_name_lower, video_stream)
                    EFFECT_DISPLAY_MAP = {'dovi_p8': 'DoVi P8', 'dovi_p7': 'DoVi P7', 'dovi_p5': 'DoVi P5', 'dovi_other': 'DoVi (Other)', 'hdr10+': 'HDR10+', 'hdr': 'HDR', 'sdr': 'SDR'}
                    effect_str = EFFECT_DISPLAY_MAP.get(raw_effect_tag, raw_effect_tag.upper())

                    resolution_str = "æœªçŸ¥"
                    if video_stream:
                        width, height = int(video_stream.get('Width') or 0), int(video_stream.get('Height') or 0)
                        _, resolution_str = _get_resolution_tier(width, height)
                    
                    quality_str = _extract_quality_tag_from_filename(file_name_lower, video_stream)
                    
                    detected_audio_langs = _get_detected_languages_from_streams(media_streams, 'Audio', AUDIO_SUBTITLE_KEYWORD_MAP)
                    AUDIO_DISPLAY_MAP = {'chi': 'å›½è¯­', 'yue': 'ç²¤è¯­', 'eng': 'è‹±è¯­', 'jpn': 'æ—¥è¯­'}
                    audio_str = ', '.join(sorted([AUDIO_DISPLAY_MAP.get(lang, lang) for lang in detected_audio_langs])) or 'æ— '
                    
                    detected_sub_langs = _get_detected_languages_from_streams(media_streams, 'Subtitle', AUDIO_SUBTITLE_KEYWORD_MAP)
                    if 'chi' not in detected_sub_langs and 'yue' not in detected_sub_langs and any(s.get('IsExternal') for s in media_streams if s.get('Type') == 'Subtitle'):
                        detected_sub_langs.add('chi')
                    SUB_DISPLAY_MAP = {'chi': 'ä¸­å­—', 'yue': 'ç²¤å­—', 'eng': 'è‹±æ–‡', 'jpn': 'æ—¥æ–‡'}
                    subtitle_str = ', '.join(sorted([SUB_DISPLAY_MAP.get(lang, lang) for lang in detected_sub_langs])) or 'æ— '

                    file_path = item_details.get('Path')
                    filename = os.path.basename(file_path) if file_path else None

                    return {
                        "item_id": item_id, "item_name": item_details.get('Name'), "tmdb_id": tmdb_id, "item_type": item_type, "status": new_status, 
                        "reason": reason, "resolution_display": resolution_str, "quality_display": quality_str, "effect_display": effect_str,
                        "audio_display": audio_str, "subtitle_display": subtitle_str,
                        "audio_languages_raw": list(detected_audio_langs), "subtitle_languages_raw": list(detected_sub_langs),
                        "matched_rule_id": applicable_rule.get('id'), "matched_rule_name": applicable_rule.get('name'), "source_library_id": source_lib_id,
                        "path": file_path, 
                        "filename": filename
                    }
            except Exception as e:
                logger.error(f"  âœ å¤„ç†é¡¹ç›® '{item_name}' (ID: {item_id}) æ—¶çº¿ç¨‹å†…å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                return None

        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_item = {executor.submit(process_item_for_cache, item): item for item in items_to_process}
            for future in as_completed(future_to_item):
                if processor.is_stop_requested(): break
                result = future.result()
                if result:
                    # â˜…â˜…â˜… ä¿®æ”¹ç‚¹ï¼šå¦‚æœè¿”å›çš„æ˜¯åˆ—è¡¨ï¼ˆå‰§é›†çš„å¤šå­£ç»“æœï¼‰ï¼Œåˆ™æ‰©å±•åˆ—è¡¨ â˜…â˜…â˜…
                    if isinstance(result, list):
                        cache_update_batch.extend(result)
                    else:
                        cache_update_batch.append(result)
                processed_count += 1
                progress = int(20 + (processed_count / (total or 1)) * 80)
                task_manager.update_status_from_thread(progress, f"({processed_count}/{total}) æ­£åœ¨åˆ†æ: {future_to_item[future].get('Name')}")

        if cache_update_batch:
            logger.info(f"  âœ åˆ†æå®Œæˆï¼Œæ­£åœ¨å°† {len(cache_update_batch)} æ¡è®°å½•å†™å…¥ç¼“å­˜è¡¨...")
            resubscribe_db.upsert_resubscribe_cache_batch(cache_update_batch)
            
            task_manager.update_status_from_thread(99, "ç¼“å­˜å†™å…¥å®Œæˆï¼Œå³å°†åˆ·æ–°...")
            time.sleep(1) # ç»™å‰ç«¯ä¸€ç‚¹ååº”æ—¶é—´ï¼Œç¡®ä¿ä¿¡å·è¢«æ¥æ”¶

        final_message = "åª’ä½“æ´—ç‰ˆçŠ¶æ€åˆ·æ–°å®Œæˆï¼"
        if processor.is_stop_requested(): final_message = "ä»»åŠ¡å·²ä¸­æ­¢ã€‚"
        task_manager.update_status_from_thread(100, final_message)

    except Exception as e:
        logger.error(f"æ‰§è¡Œ '{task_name}' ä»»åŠ¡æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        task_manager.update_status_from_thread(-1, f"ä»»åŠ¡å¤±è´¥: {e}")
