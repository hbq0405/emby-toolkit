# tasks/custom_collections.py
# è‡ªå»ºåˆé›†ä»»åŠ¡æ¨¡å— (V5 - å®æ—¶æ¶æ„é€‚é…ç‰ˆ)

import json
import logging
import pytz
import time
import random
from datetime import datetime
from typing import Dict, Any, List, Set

# å¯¼å…¥éœ€è¦çš„åº•å±‚æ¨¡å—å’Œå…±äº«å®ä¾‹
import handler.emby as emby
import task_manager
import handler.tmdb as tmdb
from database import connection, custom_collection_db, settings_db, media_db, request_db, queries_db
from handler.custom_collection import ListImporter
from services.cover_generator import CoverGeneratorService
from handler.poster_generator import cleanup_placeholder, sync_all_subscription_posters
import constants
import config_manager

logger = logging.getLogger(__name__)

# è¾…åŠ©å‡½æ•°åº”ç”¨ä¿®æ­£
def _apply_id_corrections(tmdb_items: list, definition: dict, collection_name: str) -> tuple[list, dict]:
    """
    åº”ç”¨åˆé›†å®šä¹‰ä¸­çš„ä¿®æ­£è§„åˆ™ (æ”¯æŒ ID ä¿®æ­£å’Œ æ ‡é¢˜ ä¿®æ­£)ã€‚
    """
    corrections = definition.get('corrections', {})
    corrected_id_to_original_id_map = {}
    
    if corrections:
        logger.info(f"  -> æ£€æµ‹åˆ°åˆé›† '{collection_name}' å­˜åœ¨ {len(corrections)} æ¡ä¿®æ­£è§„åˆ™ï¼Œæ­£åœ¨åº”ç”¨...")
        
        for item in tmdb_items:
            original_id_str = str(item.get('id')) if item.get('id') else None
            original_title = item.get('title')
            
            correction_found = None
            
            # 1. ä¼˜å…ˆå°è¯• ID åŒ¹é…
            if original_id_str and original_id_str in corrections:
                correction_found = corrections[original_id_str]
            # 2. å¦‚æœæ²¡æœ‰ ID åŒ¹é…ï¼Œå°è¯• æ ‡é¢˜ åŒ¹é…
            elif original_title:
                title_key = f"title:{original_title}"
                if title_key in corrections:
                    correction_found = corrections[title_key]

            # 3. åº”ç”¨ä¿®æ­£
            if correction_found:
                new_id = None
                new_season = None
                
                if isinstance(correction_found, dict):
                    new_id = correction_found.get('tmdb_id')
                    new_season = correction_found.get('season')
                else:
                    new_id = correction_found
                
                if new_id:
                    item['id'] = new_id
                    if original_id_str:
                        corrected_id_to_original_id_map[str(new_id)] = original_id_str
                
                if new_season is not None:
                    item['season'] = new_season

    return tmdb_items, corrected_id_to_original_id_map

# è¾…åŠ©å‡½æ•°æ¦œå•å¥åº·æ£€æŸ¥
def _perform_list_collection_health_check(
    tmdb_items: list, 
    tmdb_to_emby_item_map: dict, 
    corrected_id_to_original_id_map: dict, 
    collection_db_record: dict, 
    tmdb_api_key: str
) -> dict:
    """
    æ¦œå•å¥åº·æ£€æŸ¥ (ä»…ç”¨äº List ç±»å‹)
    """
    collection_id = collection_db_record.get('id')
    collection_name = collection_db_record.get('name', 'æœªçŸ¥åˆé›†')
    logger.info(f"  âœ æ¦œå•åˆé›† '{collection_name}'ï¼Œå¼€å§‹è¿›è¡Œå¥åº·åº¦åˆ†æ...")

    # è·å–ä¸Šä¸€æ¬¡åŒæ­¥æ—¶ç”Ÿæˆçš„åª’ä½“åˆ—è¡¨ 
    old_media_map = {}
    historical_data = collection_db_record.get('generated_media_info_json')
    
    if historical_data:
        try:
            old_items = []
            if isinstance(historical_data, str):
                old_items = json.loads(historical_data)
            elif isinstance(historical_data, list):
                old_items = historical_data
            
            if old_items:
                old_media_map = {str(item['tmdb_id']): item['media_type'] for item in old_items if item.get('tmdb_id')}
        except Exception as e:
            logger.warning(f"  -> è§£æåˆé›† '{collection_name}' çš„å†å²åª’ä½“åˆ—è¡¨æ—¶å¤±è´¥: {e}")

    # æå‰åŠ è½½æ‰€æœ‰åœ¨åº“çš„â€œå­£â€çš„ä¿¡æ¯
    in_library_seasons_set = set()
    try:
        with connection.get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT parent_series_tmdb_id, season_number FROM media_metadata WHERE item_type = 'Season' AND in_library = TRUE")
            for row in cursor.fetchall():
                in_library_seasons_set.add((row['parent_series_tmdb_id'], row['season_number']))
    except Exception as e_db:
        logger.error(f"  -> è·å–åœ¨åº“å­£åˆ—è¡¨æ—¶å‘ç”Ÿæ•°æ®åº“é”™è¯¯: {e_db}", exc_info=True)

    # è·å–æ‰€æœ‰åœ¨åº“çš„ Key é›†åˆ (æ ¼å¼: id_type)
    in_library_keys = set(tmdb_to_emby_item_map.keys())

    subscribed_or_paused_keys = set()
    try:
        with connection.get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT tmdb_id, item_type FROM media_metadata WHERE subscription_status IN ('SUBSCRIBED', 'PAUSED', 'WANTED', 'IGNORED', 'PENDING_RELEASE')")
            for row in cursor.fetchall():
                subscribed_or_paused_keys.add(f"{row['tmdb_id']}_{row['item_type']}")
    except Exception as e_sub:
        logger.error(f"  -> è·å–è®¢é˜…çŠ¶æ€æ—¶å‘ç”Ÿæ•°æ®åº“é”™è¯¯: {e_sub}", exc_info=True)
    
    missing_released_items = []
    missing_unreleased_items = []
    parent_series_to_ensure_exist = []
    today_str = datetime.now().strftime('%Y-%m-%d')

    for item_def in tmdb_items:
        tmdb_id = str(item_def.get('tmdb_id'))
        media_type = item_def.get('media_type')
        season_num = item_def.get('season')

        is_in_library = False
        
        if item_def.get('emby_id'):
            is_in_library = True
        elif season_num is not None and media_type == 'Series':
            if (tmdb_id, season_num) in in_library_seasons_set:
                is_in_library = True
        else:
            current_key = f"{tmdb_id}_{media_type}"
            if current_key in in_library_keys:
                is_in_library = True
            else:
                original_id = corrected_id_to_original_id_map.get(tmdb_id)
                if original_id:
                    original_key = f"{original_id}_{media_type}"
                    if original_key in in_library_keys:
                        is_in_library = True
        
        if is_in_library:
            continue

        check_sub_key = f"{tmdb_id}_{media_type}"
        if check_sub_key in subscribed_or_paused_keys:
            continue
        
        if not tmdb_id or tmdb_id == 'None':
            continue

        try:
            details = None
            # æ ‡è®°æ˜¯å¦éœ€è¦å°†è¯¥æ¡ç›®æœ¬èº«åŠ å…¥å¾…è®¢é˜…åˆ—è¡¨
            # é»˜è®¤ä¸º Trueï¼Œå¦‚æœæ˜¯æ•´å‰§æ‹†è§£æ¨¡å¼ï¼Œåˆ™è®¾ä¸º False (å› ä¸ºæˆ‘ä»¬ä¼šæ·»åŠ å…·ä½“çš„å­£)
            add_self_to_missing_list = True 

            if season_num is not None and media_type == 'Series':
                # ... (åŸæœ‰å•å­£é€»è¾‘ä¿æŒä¸å˜) ...
                details = tmdb.get_tv_season_details(tmdb_id, season_num, tmdb_api_key)
                if details:
                    item_type_for_db = 'Season'
                    parent_details = tmdb.get_tv_details(tmdb_id, tmdb_api_key)
                    details['parent_series_tmdb_id'] = tmdb_id
                    details['parent_title'] = parent_details.get('name', '')
                    details['parent_poster_path'] = parent_details.get('poster_path')

                    parent_series_to_ensure_exist.append({
                        'tmdb_id': tmdb_id,
                        'item_type': 'Series',
                        'title': parent_details.get('name'),
                        'original_title': parent_details.get('original_name'),
                        'release_date': parent_details.get('first_air_date'),
                        'release_year': parent_details.get('first_air_date', '----').split('-')[0],
                        'poster_path': parent_details.get('poster_path')
                    })
            else:
                # è·å–è¯¦æƒ…
                details = tmdb.get_movie_details(tmdb_id, tmdb_api_key) if media_type == 'Movie' else tmdb.get_tv_details(tmdb_id, tmdb_api_key)
                
                # â˜…â˜…â˜… æ–°å¢é€»è¾‘ï¼šå¦‚æœæ˜¯æ•´å‰§ï¼Œç«‹åˆ»æ‹†è§£ä¸ºå­£ â˜…â˜…â˜…
                if details and media_type == 'Series':
                    # 1. æ—¢ç„¶æˆ‘ä»¬è¦æ·»åŠ å…·ä½“çš„å­£ï¼Œå°±ä¸éœ€è¦è®¢é˜… Series æœ¬ä½“äº†
                    add_self_to_missing_list = False
                    
                    # 2. ç¡®ä¿çˆ¶å‰§é›†å…ƒæ•°æ®å­˜åœ¨ (å ä½)
                    parent_series_to_ensure_exist.append({
                        'tmdb_id': tmdb_id,
                        'item_type': 'Series',
                        'title': details.get('name'),
                        'original_title': details.get('original_name'),
                        'release_date': details.get('first_air_date'),
                        'release_year': details.get('first_air_date', '----').split('-')[0],
                        'poster_path': details.get('poster_path')
                    })

                    # 3. éå†æ‰€æœ‰å­£
                    seasons = details.get('seasons', [])
                    series_name = details.get('name')
                    series_poster = details.get('poster_path')
                    
                    for season in seasons:
                        s_num = season.get('season_number')
                        # è·³è¿‡ç‰¹åˆ«ç¯‡ (Season 0) å’Œ å·²ç»åœ¨åº“çš„å­£
                        if s_num is None or s_num == 0: continue
                        if (tmdb_id, s_num) in in_library_seasons_set: continue
                        
                        # 4. æ„å»ºå­£çš„è®¢é˜…è¯·æ±‚
                        s_air_date = season.get('air_date')
                        s_poster = season.get('poster_path') or series_poster
                        
                        season_item_for_db = {
                            'tmdb_id': str(season.get('id')), # å­£çš„ TMDb ID
                            'item_type': 'Season',
                            'title': season.get('name') or f"ç¬¬ {s_num} å­£",
                            'release_date': s_air_date,
                            'release_year': int(s_air_date.split('-')[0]) if s_air_date else None,
                            'overview': season.get('overview'),
                            'poster_path': s_poster,
                            'parent_series_tmdb_id': tmdb_id,
                            'season_number': s_num,
                            'source': { "type": "collection", "id": collection_db_record.get('id'), "name": collection_name }
                        }
                        
                        # 5. åˆ†æµï¼šå·²ä¸Šæ˜  vs æœªä¸Šæ˜ 
                        if s_air_date and s_air_date > today_str:
                            missing_unreleased_items.append(season_item_for_db)
                        else:
                            missing_released_items.append(season_item_for_db)
                    
                    logger.info(f"  -> [æ™ºèƒ½æ‹†è§£] å·²å°†å‰§é›†ã€Š{series_name}ã€‹æ‹†è§£ä¸ºç¼ºå°‘çš„å­£è¿›è¡Œè®¢é˜…ã€‚")

            if not details: continue
            
            # å¦‚æœ add_self_to_missing_list ä¸º Trueï¼Œè¯´æ˜æ˜¯ç”µå½±æˆ–è€…å•å­£ï¼Œèµ°åŸæœ‰é€»è¾‘
            if add_self_to_missing_list:
                release_date = details.get("air_date") or details.get("release_date") or details.get("first_air_date", '')
                
                release_year = None
                if release_date and '-' in release_date:
                    try:
                        release_year = int(release_date.split('-')[0])
                    except:
                        pass

                item_details_for_db = {
                    'tmdb_id': str(details.get('id')),
                    'item_type': item_type_for_db,
                    'title': details.get('name') or f"ç¬¬ {season_num} å­£" if item_type_for_db == 'Season' else details.get('title') or details.get('name'),
                    'release_date': release_date,
                    'release_year': release_year, 
                    'overview': details.get('overview'),
                    'poster_path': details.get('poster_path') or details.get('parent_poster_path'),
                    'parent_series_tmdb_id': tmdb_id if item_type_for_db == 'Season' else None,
                    'season_number': details.get('season_number'),
                    'source': { "type": "collection", "id": collection_db_record.get('id'), "name": collection_name }
                }

                if release_date and release_date > today_str:
                    missing_unreleased_items.append(item_details_for_db)
                else:
                    missing_released_items.append(item_details_for_db)

        except Exception as e:
            logger.error(f"ä¸ºåˆé›† '{collection_name}' è·å– {tmdb_id} (å­£: {season_num}) è¯¦æƒ…æ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)

    source_for_subscription = {"type": "collection", "id": collection_db_record.get('id'), "name": collection_name}

    if parent_series_to_ensure_exist:
        unique_parents = {p['tmdb_id']: p for p in parent_series_to_ensure_exist}.values()
        logger.info(f"  -> æ£€æµ‹åˆ° {len(unique_parents)} ä¸ªç¼ºå¤±çš„çˆ¶å‰§é›†å…ƒæ•°æ®ï¼Œæ­£åœ¨åˆ›å»ºå ä½è®°å½•...")
        request_db.set_media_status_none(
            tmdb_ids=[p['tmdb_id'] for p in unique_parents],
            item_type='Series',
            media_info_list=list(unique_parents)
        )

    def group_and_update(items_list, status):
        if not items_list: return
        logger.info(f"  -> æ£€æµ‹åˆ° {len(items_list)} ä¸ªç¼ºå¤±åª’ä½“ï¼Œå°†è®¢é˜…çŠ¶æ€è®¾ä¸º '{status}'...")
        
        requests_by_type = {}
        for item in items_list:
            item_type = item['item_type']
            if item_type not in requests_by_type:
                requests_by_type[item_type] = []
            requests_by_type[item_type].append(item)
            
        for item_type, requests in requests_by_type.items():
            if status == 'WANTED':
                request_db.set_media_status_wanted(
                    tmdb_ids=[req['tmdb_id'] for req in requests],
                    item_type=item_type,
                    media_info_list=requests,
                    source=source_for_subscription
                )
            elif status == 'PENDING_RELEASE':
                request_db.set_media_status_pending_release(
                    tmdb_ids=[req['tmdb_id'] for req in requests],
                    item_type=item_type,
                    media_info_list=requests,
                    source=source_for_subscription
                )

    group_and_update(missing_released_items, 'WANTED')
    group_and_update(missing_unreleased_items, 'PENDING_RELEASE')

    if old_media_map:
        new_tmdb_ids = {str(item['tmdb_id']) for item in tmdb_items}
        removed_tmdb_ids = set(old_media_map.keys()) - new_tmdb_ids

        if removed_tmdb_ids:
            logger.warning(f"  -> æ£€æµ‹åˆ° {len(removed_tmdb_ids)} ä¸ªåª’ä½“å·²ä»åˆé›† '{collection_name}' ä¸­ç§»é™¤ï¼Œæ­£åœ¨æ¸…ç†å…¶è®¢é˜…æ¥æº...")
            source_to_remove = {
                "type": "collection", 
                "id": collection_id, 
                "name": collection_name
            }
            for tmdb_id in removed_tmdb_ids:
                item_type = old_media_map.get(tmdb_id)
                if item_type:
                    try:
                        request_db.remove_subscription_source(tmdb_id, item_type, source_to_remove)
                        cleanup_placeholder(tmdb_id)
                    except Exception as e_remove:
                        logger.error(f"  -> æ¸…ç†åª’ä½“ {tmdb_id} ({item_type}) çš„æ¥æºæ—¶å‘ç”Ÿé”™è¯¯: {e_remove}", exc_info=True)
    return 

def _get_cover_badge_text_for_collection(collection_db_info: Dict[str, Any]) -> Any:
    """
    æ ¹æ®è‡ªå®šä¹‰åˆé›†çš„æ•°æ®åº“ä¿¡æ¯ï¼Œæ™ºèƒ½åˆ¤æ–­å¹¶è¿”å›ç”¨äºå°é¢è§’æ ‡çš„å‚æ•°ã€‚
    """
    item_count_to_pass = collection_db_info.get('in_library_count', 0)
    collection_type = collection_db_info.get('type')
    definition = collection_db_info.get('definition_json', {})
    
    if collection_type == 'list':
        raw_url = definition.get('url', '')
        urls = raw_url if isinstance(raw_url, list) else [str(raw_url)]
        types_found = set()
        for u in urls:
            if not isinstance(u, str): continue
            if u.startswith('maoyan://'): types_found.add('çŒ«çœ¼')
            elif 'douban.com/doulist' in u: types_found.add('è±†åˆ—')
            elif 'themoviedb.org/discover/' in u: types_found.add('æ¢ç´¢')
            else: types_found.add('æœªçŸ¥')

        if len(types_found) == 1 and 'æœªçŸ¥' not in types_found:
            return types_found.pop()
        else:
            if types_found == {'æœªçŸ¥'}: return 'æ¦œå•'
            return 'æ··åˆ'    
            
    if collection_type == 'ai_recommendation_global':
        return 'çƒ­æ¦œ'
    if collection_type == 'ai_recommendation':
        return 'æ¨è'
    
    return item_count_to_pass

# â˜…â˜…â˜… ä¸€é”®ç”Ÿæˆæ‰€æœ‰åˆé›†çš„åå°ä»»åŠ¡ (é‡æ„ç‰ˆ) â˜…â˜…â˜…
def task_process_all_custom_collections(processor):
    """
    ä¸€é”®ç”Ÿæˆæ‰€æœ‰åˆé›†çš„åå°ä»»åŠ¡ (è½»é‡åŒ–ç‰ˆ - ä»…åˆ·æ–°å¤–éƒ¨æ•°æ®æº)ã€‚
    - ä»…å¤„ç† List (æ¦œå•) å’Œ AI Recommendation Global (å…¨å±€AI)ã€‚
    - è·³è¿‡ Filter (ç­›é€‰) å’Œ AI Recommendation (ä¸ªäººAI)ï¼Œå› ä¸ºå®ƒä»¬æ˜¯å®æ—¶è®¡ç®—çš„ï¼Œæ— éœ€åå°åˆ·æ–°ã€‚
    """
    task_name = "ç”Ÿæˆæ‰€æœ‰è‡ªå»ºåˆé›†"
    logger.info(f"--- å¼€å§‹æ‰§è¡Œ '{task_name}' ä»»åŠ¡ ---")

    try:
        # 1. è·å–åˆé›†å®šä¹‰
        task_manager.update_status_from_thread(10, "æ­£åœ¨è·å–æ‰€æœ‰å¯ç”¨çš„åˆé›†å®šä¹‰...")
        all_collections = custom_collection_db.get_all_active_custom_collections()
        
        # --- è¿‡æ»¤é€»è¾‘ï¼šåªä¿ç•™éœ€è¦ä»å¤–éƒ¨è·å–æ•°æ®çš„ç±»å‹ ---
        target_types = {'list', 'ai_recommendation_global'}
        active_collections = [c for c in all_collections if c['type'] in target_types]
        
        skipped_count = len(all_collections) - len(active_collections)
        if skipped_count > 0:
            logger.info(f"  -> å·²è·³è¿‡ {skipped_count} ä¸ªæœ¬åœ°ç­›é€‰/ä¸ªäººAIç±»åˆé›† (æ— éœ€å®šæ—¶åˆ·æ–°)ã€‚")

        if not active_collections:
            task_manager.update_status_from_thread(100, "æ²¡æœ‰éœ€è¦åˆ·æ–°çš„æ¦œå•æˆ–å…¨å±€æ¨èåˆé›†ã€‚")
            return

        # 2. åŠ è½½å…¨é‡æ˜ å°„ (ç”¨äºåŒ¹é…æœ¬åœ°åª’ä½“)
        task_manager.update_status_from_thread(12, "æ­£åœ¨ä»æœ¬åœ°æ•°æ®åº“åŠ è½½å…¨é‡åª’ä½“æ˜ å°„...")
        tmdb_to_emby_item_map = media_db.get_tmdb_to_emby_map(library_ids=None)
        
        # 3. è·å–ç°æœ‰åˆé›†åˆ—è¡¨ (ç”¨äº Emby å®ä½“åˆé›†åŒæ­¥)
        task_manager.update_status_from_thread(15, "æ­£åœ¨ä»Embyè·å–ç°æœ‰åˆé›†åˆ—è¡¨...")
        all_emby_collections = emby.get_all_collections_from_emby_generic(base_url=processor.emby_url, api_key=processor.emby_api_key, user_id=processor.emby_user_id) or []
        prefetched_collection_map = {coll.get('Name', '').lower(): coll for coll in all_emby_collections}

        # 4. åˆå§‹åŒ–å°é¢ç”Ÿæˆå™¨
        cover_service = None
        try:
            cover_config = settings_db.get_setting('cover_generator_config') or {}
            if cover_config.get("enabled"):
                cover_service = CoverGeneratorService(config=cover_config)
        except Exception: pass

        total_collections = len(active_collections)

        for i, collection in enumerate(active_collections):
            if processor.is_stop_requested(): break

            collection_id = collection['id']
            collection_name = collection['name']
            collection_type = collection['type']
            definition = collection['definition_json']
            
            progress = 20 + int((i / total_collections) * 75)
            task_manager.update_status_from_thread(progress, f"({i+1}/{total_collections}) æ­£åœ¨å¤„ç†: {collection_name}")

            try:
                global_ordered_emby_ids = [] # ç”¨äºåŒæ­¥ç»™ Emby å®ä½“åˆé›† (å°é¢ç´ æ)
                items_for_db = []            # ç”¨äºå­˜å…¥ generated_media_info_json
                total_count = 0              # ç”¨äºè§’æ ‡

                # æ¦œå•/æ¨èç±» (List/AI Global) - å…¨é‡æ¨¡å¼
                raw_tmdb_items = []
                if collection_type == 'list':
                    importer = ListImporter(processor.tmdb_api_key)
                    raw_tmdb_items, _ = importer.process(definition)
                else:
                    # ai_recommendation_global
                    from handler.custom_collection import RecommendationEngine
                    rec_engine = RecommendationEngine(processor.tmdb_api_key)
                    raw_tmdb_items = rec_engine.generate(definition)

                # åº”ç”¨ä¿®æ­£
                raw_tmdb_items, corrected_id_to_original_id_map = _apply_id_corrections(raw_tmdb_items, definition, collection_name)
                
                # æ˜ å°„ Emby ID
                tmdb_items = []
                for item in raw_tmdb_items:
                    tmdb_id = str(item.get('id')) if item.get('id') else None
                    media_type = item.get('type')
                    emby_id = item.get('emby_id')
                    
                    if not emby_id and tmdb_id:
                        key = f"{tmdb_id}_{media_type}"
                        if key in tmdb_to_emby_item_map:
                            emby_id = tmdb_to_emby_item_map[key]['Id']
                    
                    processed_item = {
                        'tmdb_id': tmdb_id,
                        'media_type': media_type,
                        'emby_id': emby_id,
                        'title': item.get('title'),
                        **({'season': item['season']} if 'season' in item and item.get('season') is not None else {})
                    }
                    tmdb_items.append(processed_item)
                    
                    if emby_id:
                        global_ordered_emby_ids.append(emby_id)

                # æ¦œå•/å…¨å±€AIç±»éœ€è¦å…¨é‡å­˜å‚¨ï¼Œå› ä¸ºåå‘ä»£ç†å±‚æ— æ³•å®æ—¶çˆ¬è™«
                items_for_db = tmdb_items
                total_count = len(global_ordered_emby_ids)

                # æ‰§è¡Œå¥åº·æ£€æŸ¥ (æ¦œå•ç±»å’Œå…¨å±€AIæ¨èéƒ½éœ€è¦)
                # ä½œç”¨ï¼šå¯¹æ¯” TMDB åˆ—è¡¨å’Œæœ¬åœ°åº“ï¼Œè‡ªåŠ¨è®¢é˜…ç¼ºå¤±çš„åª’ä½“
                if collection_type in ['list', 'ai_recommendation_global']:
                    _perform_list_collection_health_check(
                        tmdb_items=tmdb_items, 
                        tmdb_to_emby_item_map=tmdb_to_emby_item_map, 
                        corrected_id_to_original_id_map=corrected_id_to_original_id_map,
                        collection_db_record=collection,
                        tmdb_api_key=processor.tmdb_api_key
                    )

                # åç»­å¤„ç†
                # 1. æ›´æ–° Emby å®ä½“åˆé›† (ç”¨äºå°é¢)
                emby_collection_id = emby.create_or_update_collection_with_emby_ids(
                    collection_name=collection_name, 
                    emby_ids_in_library=global_ordered_emby_ids,
                    base_url=processor.emby_url, 
                    api_key=processor.emby_api_key, 
                    user_id=processor.emby_user_id,
                    prefetched_collection_map=prefetched_collection_map,
                    allow_empty=False 
                )

                # 2. æ›´æ–°æ•°æ®åº“çŠ¶æ€
                update_data = {
                    "emby_collection_id": emby_collection_id,
                    "item_type": json.dumps(definition.get('item_type', ['Movie'])),
                    "last_synced_at": datetime.now(pytz.utc),
                    "in_library_count": total_count, # ä¿å­˜çœŸå®æ€»æ•°
                    "generated_media_info_json": json.dumps(items_for_db, ensure_ascii=False)
                }
                custom_collection_db.update_custom_collection_sync_results(collection_id, update_data)

                # 3. å°é¢ç”Ÿæˆ
                if cover_service and emby_collection_id:
                    try:
                        library_info = emby.get_emby_item_details(emby_collection_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id)
                        if library_info:
                            # é‡æ–°è·å–ä¸€æ¬¡æœ€æ–°çš„ info ä»¥ç¡®ä¿ count å‡†ç¡®
                            latest_collection_info = custom_collection_db.get_custom_collection_by_id(collection_id)
                            item_count_to_pass = _get_cover_badge_text_for_collection(latest_collection_info)
                            cover_service.generate_for_library(
                                emby_server_id='main_emby', library=library_info,
                                item_count=item_count_to_pass, content_types=definition.get('item_type', ['Movie'])
                            )
                    except Exception as e_cover:
                        logger.error(f"ä¸ºåˆé›† '{collection_name}' ç”Ÿæˆå°é¢æ—¶å‡ºé”™: {e_cover}", exc_info=True)

                # é˜²å°æ§ä¼‘çœ  (ä»…é’ˆå¯¹çŒ«çœ¼æ¦œå•)
                is_maoyan = False
                raw_url = definition.get('url', '')
                urls = raw_url if isinstance(raw_url, list) else [str(raw_url)]
                for u in urls:
                    if isinstance(u, str) and u.startswith('maoyan://'):
                        is_maoyan = True
                        break
                if collection_type == 'list' and is_maoyan:
                    time.sleep(10)
                
            except Exception as e_coll:
                logger.error(f"å¤„ç†åˆé›† '{collection_name}' (ID: {collection_id}) æ—¶å‘ç”Ÿé”™è¯¯: {e_coll}", exc_info=True)
                continue
        
        final_message = "æ‰€æœ‰å¤–éƒ¨æºåˆé›†(List/Global AI)å‡å·²å¤„ç†å®Œæ¯•ï¼"
        if processor.is_stop_requested(): final_message = "ä»»åŠ¡å·²ä¸­æ­¢ã€‚"
        
        try:
            if config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_PROXY_SHOW_MISSING_PLACEHOLDERS, False):
                sync_all_subscription_posters()
            else:
                logger.info("  âœ æ£€æµ‹åˆ°å ä½æµ·æŠ¥åŠŸèƒ½å·²å…³é—­ï¼Œè·³è¿‡æµ·æŠ¥åŒæ­¥ã€‚")
        except Exception as e:
            logger.error(f"å…¨é‡åŒæ­¥å ä½æµ·æŠ¥å¤±è´¥: {e}")

        task_manager.update_status_from_thread(100, final_message)
        logger.info(f"--- '{task_name}' ä»»åŠ¡æˆåŠŸå®Œæˆ ---")

    except Exception as e:
        logger.error(f"æ‰§è¡Œ '{task_name}' ä»»åŠ¡æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        task_manager.update_status_from_thread(-1, f"ä»»åŠ¡å¤±è´¥: {e}")

# --- å¤„ç†å•ä¸ªè‡ªå®šä¹‰åˆé›†çš„æ ¸å¿ƒä»»åŠ¡ ---
def process_single_custom_collection(processor, custom_collection_id: int):
    """
    å¤„ç†å•ä¸ªè‡ªå®šä¹‰åˆé›† (é€»è¾‘ä¸æ‰¹é‡ä»»åŠ¡ä¸€è‡´ï¼Œå·²é€‚é…è½»é‡åŒ–æ¶æ„)ã€‚
    """
    task_name = f"ç”Ÿæˆå•ä¸ªè‡ªå»ºåˆé›† (ID: {custom_collection_id})"
    logger.info(f"--- å¼€å§‹æ‰§è¡Œ '{task_name}' ä»»åŠ¡ ---")
    
    try:
        # 1. è¯»å–åˆé›†å®šä¹‰
        task_manager.update_status_from_thread(10, "æ­£åœ¨è¯»å–åˆé›†å®šä¹‰...")
        collection = custom_collection_db.get_custom_collection_by_id(custom_collection_id)
        if not collection: raise ValueError(f"æœªæ‰¾åˆ°IDä¸º {custom_collection_id} çš„è‡ªå®šä¹‰åˆé›†ã€‚")
        
        collection_name = collection['name']
        collection_type = collection['type']
        definition = collection['definition_json']
        
        task_manager.update_status_from_thread(20, f"æ­£åœ¨å¤„ç†ã€Š{collection_name}ã€‹...")

        global_ordered_emby_ids = []
        items_for_db = []
        total_count = 0

        # ==================================================================
        # åˆ†æ”¯ A: ç­›é€‰ç±» (Filter) - æé€Ÿæ¨¡å¼
        # ==================================================================
        if collection_type == 'filter':
            admin_user_id = processor.emby_user_id
            target_library_ids = definition.get('target_library_ids', [])
            sample_items, total_count = queries_db.query_virtual_library_items(
                rules=definition.get('rules', []),
                logic=definition.get('logic', 'AND'),
                user_id=admin_user_id,
                limit=9,
                offset=0,
                item_types=definition.get('item_type', ['Movie']),
                target_library_ids=target_library_ids
            )
            global_ordered_emby_ids = [item['Id'] for item in sample_items]
            items_for_db = [{'emby_id': item['Id']} for item in sample_items]

        # ==================================================================
        # åˆ†æ”¯ B: æ¦œå•/æ¨èç±» (List/AI) - å…¨é‡æ¨¡å¼
        # ==================================================================
        elif collection_type in ['list', 'ai_recommendation_global']:
            raw_tmdb_items = []
            if collection_type == 'list':
                importer = ListImporter(processor.tmdb_api_key)
                raw_tmdb_items, _ = importer.process(definition)
            else:
                from handler.custom_collection import RecommendationEngine
                rec_engine = RecommendationEngine(processor.tmdb_api_key)
                raw_tmdb_items = rec_engine.generate(definition)

            raw_tmdb_items, corrected_id_to_original_id_map = _apply_id_corrections(raw_tmdb_items, definition, collection_name)
            
            # æ˜ å°„ Emby ID (éœ€è¦å…¨é‡æ˜ å°„è¡¨)
            task_manager.update_status_from_thread(15, "æ­£åœ¨åŠ è½½åª’ä½“æ˜ å°„è¡¨...")
            # æ”¾å¼ƒä½¿ç”¨ get_emby_ids_for_itemsï¼Œæ”¹ç”¨æ‰¹é‡ä»»åŠ¡åŒæ¬¾å‡½æ•°
            tmdb_to_emby_item_map = media_db.get_tmdb_to_emby_map()

            tmdb_items = []
            for item in raw_tmdb_items:
                tmdb_id = str(item.get('id'))
                media_type = item.get('type')
                emby_id = None
                
                # ç»Ÿä¸€ä½¿ç”¨ key åŒ¹é…
                key = f"{tmdb_id}_{media_type}"
                if key in tmdb_to_emby_item_map:
                    emby_id = tmdb_to_emby_item_map[key]['Id']
                
                processed_item = {
                    'tmdb_id': tmdb_id,
                    'media_type': media_type,
                    'emby_id': emby_id,
                    'title': item.get('title'),
                    **({'season': item['season']} if 'season' in item and item.get('season') is not None else {})
                }
                tmdb_items.append(processed_item)
                
                if emby_id:
                    global_ordered_emby_ids.append(emby_id)

            items_for_db = tmdb_items
            total_count = len(global_ordered_emby_ids)

            if collection_type == 'list':
                # æ„é€ ä¸€ä¸ªä¸´æ—¶çš„ map ä¼ ç»™å¥åº·æ£€æŸ¥
                tmdb_to_emby_map_full = tmdb_to_emby_item_map # å¤ç”¨
                _perform_list_collection_health_check(
                    tmdb_items=tmdb_items,
                    tmdb_to_emby_item_map=tmdb_to_emby_map_full,
                    corrected_id_to_original_id_map=corrected_id_to_original_id_map,
                    collection_db_record=collection,
                    tmdb_api_key=processor.tmdb_api_key
                )

        # ==================================================================
        # åˆ†æ”¯ C: ä¸ªäººæ¨èç±» (AI) - å°é¢å¿«è½¦é“ (éµå®ˆå‰ç«¯å®šä¹‰çš„åº“å’Œç±»å‹)
        # ==================================================================
        elif collection_type == 'ai_recommendation':
            # ğŸ’¡ æ ¸å¿ƒæ€è·¯ï¼šåå°ä»»åŠ¡ä»…ä¸ºç”Ÿæˆå°é¢ï¼Œä¸è°ƒç”¨ LLM æµªè´¹ Tokensã€‚
            # æˆ‘ä»¬ç›´æ¥æ ¹æ®å‰ç«¯å®šä¹‰çš„ [åª’ä½“åº“] å’Œ [å†…å®¹ç±»å‹] æå–é«˜åˆ†ç‰‡ä½œä¸ºé—¨é¢ã€‚
            
            admin_user_id = processor.emby_user_id
            # 1. æå–å‰ç«¯å®šä¹‰çš„è§„åˆ™
            target_library_ids = definition.get('target_library_ids', [])
            item_types = definition.get('item_type', ['Movie'])
            
            logger.info(f"  âœ æ­£åœ¨ä¸ºã€Š{collection_name}ã€‹ç­›é€‰å°é¢ç´ æ (ç±»å‹: {item_types})...")

            # 2. è°ƒç”¨æŸ¥è¯¢å¼•æ“ï¼šéµå®ˆå‰ç«¯è§„åˆ™ + è¯„åˆ† > 7 (ä¿è¯å°é¢è´¨é‡)
            sample_items, _ = queries_db.query_virtual_library_items(
                rules=[{"field": "rating", "operator": "gte", "value": 7}],
                logic='AND',
                user_id=admin_user_id,
                limit=20, 
                offset=0,
                item_types=item_types,         # ğŸ‘ˆ éµå®ˆå‰ç«¯é€‰çš„å†…å®¹ç±»å‹
                target_library_ids=target_library_ids, # ğŸ‘ˆ éµå®ˆå‰ç«¯é€‰çš„åª’ä½“åº“
                sort_by='random'               # ğŸ‘ˆ éšæœºæ’åºï¼Œè®©å°é¢æ¯æ¬¡æ›´æ–°éƒ½æœ‰æ–°é²œæ„Ÿ
            )
            
            # 3. å…œåº•é€»è¾‘ï¼šå¦‚æœé«˜åˆ†ç‰‡å¤ªå°‘ï¼ˆæ¯”å¦‚æ–°åº“ï¼‰ï¼Œåˆ™æ”¾å®½æ¡ä»¶çº¯éšæœºæŠ“å–
            if len(sample_items) < 9:
                logger.debug(f"  âœ é«˜åˆ†ç´ æä¸è¶³ï¼Œæ”¾å®½æ¡ä»¶æŠ“å–...")
                sample_items, _ = queries_db.query_virtual_library_items(
                    rules=[], 
                    user_id=admin_user_id,
                    limit=20,
                    item_types=item_types,
                    target_library_ids=target_library_ids,
                    sort_by='random'
                )

            # 4. å¡«å……æ•°æ®
            global_ordered_emby_ids = [item['Id'] for item in sample_items]
            # æ•°æ®åº“é‡Œå­˜ä¸ªç®€å•çš„å ä½ï¼Œåä»£å±‚å®æ—¶è®¿é—®æ—¶ä¼šåŠ¨æ€ç”ŸæˆçœŸæ­£çš„ AI åˆ—è¡¨
            items_for_db = [{'emby_id': item['Id']} for item in sample_items]
            total_count = 0 # ä¸ªäººæ¨èç±»åœ¨åå°ä»»åŠ¡ä¸­ä¸è®¡æ€»æ•°

        if not global_ordered_emby_ids and collection_type != 'ai_recommendation':
             # å¦‚æœæ²¡æ‰¾åˆ°ä»»ä½•ä¸œè¥¿ï¼Œä¸”ä¸æ˜¯AIæ¨èï¼ˆAIæ¨èå…è®¸ç©ºï¼‰ï¼Œåˆ™æ¸…ç©º Emby å®ä½“åˆé›†
             # ä½†ä¸ºäº†å°é¢ç”Ÿæˆå™¨ä¸æŠ¥é”™ï¼Œæˆ‘ä»¬è¿˜æ˜¯èµ°æ­£å¸¸æµç¨‹ï¼Œåªæ˜¯åˆ—è¡¨ä¸ºç©º
             pass

        # 5. åœ¨ Emby ä¸­åˆ›å»º/æ›´æ–°åˆé›†
        task_manager.update_status_from_thread(60, "æ­£åœ¨Embyä¸­åˆ›å»º/æ›´æ–°åˆé›†...")
        should_allow_empty = (collection_type == 'ai_recommendation')
        emby_collection_id = emby.create_or_update_collection_with_emby_ids(
            collection_name=collection_name, 
            emby_ids_in_library=global_ordered_emby_ids, 
            base_url=processor.emby_url, 
            api_key=processor.emby_api_key, 
            user_id=processor.emby_user_id,
            allow_empty=should_allow_empty
        )

        # 6. æ›´æ–°æ•°æ®åº“çŠ¶æ€
        update_data = {
            "emby_collection_id": emby_collection_id,
            "item_type": json.dumps(definition.get('item_type', ['Movie'])),
            "last_synced_at": datetime.now(pytz.utc),
            "in_library_count": total_count,
            "generated_media_info_json": json.dumps(items_for_db, ensure_ascii=False)
        }
        custom_collection_db.update_custom_collection_sync_results(custom_collection_id, update_data)

        # 7. å°é¢ç”Ÿæˆ
        try:
            cover_config = settings_db.get_setting('cover_generator_config') or {}
            if cover_config.get("enabled") and emby_collection_id:
                cover_service = CoverGeneratorService(config=cover_config)
                library_info = emby.get_emby_item_details(emby_collection_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id)
                if library_info:
                    latest_collection_info = custom_collection_db.get_custom_collection_by_id(custom_collection_id)
                    item_count_to_pass = _get_cover_badge_text_for_collection(latest_collection_info)
                    cover_service.generate_for_library(
                        emby_server_id='main_emby', library=library_info,
                        item_count=item_count_to_pass, content_types=definition.get('item_type', ['Movie'])
                    )
        except Exception as e_cover:
            logger.error(f"ä¸ºåˆé›† '{collection_name}' ç”Ÿæˆå°é¢æ—¶å‘ç”Ÿé”™è¯¯: {e_cover}", exc_info=True)
        
        try:
            if config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_PROXY_SHOW_MISSING_PLACEHOLDERS, False):
                sync_all_subscription_posters()
            else:
                logger.info("  âœ æ£€æµ‹åˆ°å ä½æµ·æŠ¥åŠŸèƒ½å·²å…³é—­ï¼Œè·³è¿‡æµ·æŠ¥åŒæ­¥ã€‚")
        except Exception as e:
            logger.error(f"å…¨é‡åŒæ­¥å ä½æµ·æŠ¥å¤±è´¥: {e}")

        task_manager.update_status_from_thread(100, "è‡ªå»ºåˆé›†åŠæµ·æŠ¥åŒæ­¥å®Œæ¯•ï¼")
        logger.info(f"--- '{task_name}' ä»»åŠ¡æˆåŠŸå®Œæˆ ---")

    except Exception as e:
        logger.error(f"æ‰§è¡Œ '{task_name}' ä»»åŠ¡æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        task_manager.update_status_from_thread(-1, f"ä»»åŠ¡å¤±è´¥: {e}")