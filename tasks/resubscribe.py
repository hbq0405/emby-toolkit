# tasks/resubscribe.py
# åª’ä½“æ´—ç‰ˆä¸“å±ä»»åŠ¡æ¨¡å—

import os
import re 
import time
import logging
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed 
from collections import defaultdict

# å¯¼å…¥éœ€è¦çš„åº•å±‚æ¨¡å—
import task_manager
import handler.emby as emby
import handler.moviepilot as moviepilot
import config_manager 
import constants  
from database import resubscribe_db, settings_db, media_db

# ä» helpers å¯¼å…¥çš„è¾…åŠ©å‡½æ•°å’Œå¸¸é‡
from .helpers import (
    analyze_media_asset, 
    _get_resolution_tier, 
    _get_detected_languages_from_streams, 
    _get_standardized_effect, 
    _extract_quality_tag_from_filename,
    AUDIO_SUBTITLE_KEYWORD_MAP
)

logger = logging.getLogger(__name__)

# ======================================================================
# æ ¸å¿ƒä»»åŠ¡ï¼šåˆ·æ–°æ´—ç‰ˆçŠ¶æ€
# ======================================================================

def task_update_resubscribe_cache(processor, force_full_update: bool = False):
    """
    ã€V4 - æ•°æ®åº“ä¸­å¿ƒåŒ–é‡æ„ç‰ˆã€‘
    æ‰«ææŒ‡å®šçš„åª’ä½“åº“ï¼Œå®Œå…¨ä¾èµ–æœ¬åœ° media_metadata ç¼“å­˜è¿›è¡Œåˆ†æï¼Œå®ç°æé€Ÿæ‰«æã€‚
    """
    scan_mode = "æ·±åº¦æ¨¡å¼" if force_full_update else "å¿«é€Ÿæ¨¡å¼"
    task_name = f"åˆ·æ–°æ´—ç‰ˆçŠ¶æ€ ({scan_mode})"
    logger.info(f"--- å¼€å§‹æ‰§è¡Œ '{task_name}' ä»»åŠ¡ ---")
    
    try:
        task_manager.update_status_from_thread(0, "æ­£åœ¨åŠ è½½è§„åˆ™å¹¶ç¡®å®šæ‰«æèŒƒå›´...")
        all_enabled_rules = [rule for rule in resubscribe_db.get_all_resubscribe_rules() if rule.get('enabled')]
        
        # 1. å»ºç«‹åª’ä½“åº“åˆ°è§„åˆ™çš„æ˜ å°„ï¼Œç”¨äºåç»­åˆ†é…
        library_to_rule_map = {}
        all_target_lib_ids = set()
        for rule in reversed(all_enabled_rules): # ä¼˜å…ˆçº§é«˜çš„è§„åˆ™ä¼šè¦†ç›–ä½çš„
            if target_libs := rule.get('target_library_ids'):
                all_target_lib_ids.update(target_libs)
                for lib_id in target_libs:
                    library_to_rule_map[lib_id] = rule
        
        if not all_target_lib_ids:
            task_manager.update_status_from_thread(100, "ä»»åŠ¡è·³è¿‡ï¼šæ²¡æœ‰è§„åˆ™æŒ‡å®šä»»ä½•åª’ä½“åº“")
            return

        # 2. â˜…â˜…â˜… æ ¸å¿ƒå˜æ›´ï¼šä¸å†è·å–Embyè¯¦æƒ…ï¼Œè€Œæ˜¯è¿›è¡Œè½»é‡çº§ç´¢å¼• â˜…â˜…â˜…
        task_manager.update_status_from_thread(10, f"æ­£åœ¨ä» {len(all_target_lib_ids)} ä¸ªç›®æ ‡åº“ä¸­å»ºç«‹åª’ä½“ç´¢å¼•...")
        
        # è¿™ä¸ªAPIè°ƒç”¨æ˜¯å¿…è¦çš„ï¼Œå› ä¸ºå®ƒèƒ½å‘Šè¯‰æˆ‘ä»¬å“ªäº›åª’ä½“é¡¹ï¼ˆä»¥åŠå®ƒä»¬çš„emby_item_idï¼‰ç¡®å®å­˜åœ¨äºç›®æ ‡åº“ä¸­
        emby_index = emby.get_all_library_versions(
            base_url=processor.emby_url, api_key=processor.emby_api_key, user_id=processor.emby_user_id,
            media_type_filter="Movie,Series,Episode", library_ids=list(all_target_lib_ids),
            fields="Id,Type,ProviderIds,SeriesId,ParentIndexNumber,IndexNumber,_SourceLibraryId,Name"
        ) or []

        # 3. â˜…â˜…â˜… æ ¸å¿ƒå˜æ›´ï¼šä»æœ¬åœ°æ•°æ®åº“æ‰¹é‡è·å–æ‰€æœ‰éœ€è¦çš„å…ƒæ•°æ® â˜…â˜…â˜…
        tmdb_ids_in_scope = {item['ProviderIds'].get('Tmdb') for item in emby_index if item.get('ProviderIds', {}).get('Tmdb')}
        
        if not tmdb_ids_in_scope:
            task_manager.update_status_from_thread(100, "ä»»åŠ¡å®Œæˆï¼šç›®æ ‡åª’ä½“åº“ä¸ºç©ºã€‚")
            return

        logger.info(f"  âœ æ­£åœ¨ä»æœ¬åœ°æ•°æ®åº“æ‰¹é‡è·å– {len(tmdb_ids_in_scope)} ä¸ªåª’ä½“é¡¹çš„è¯¦ç»†å…ƒæ•°æ®...")
        metadata_map = media_db.get_media_details_by_tmdb_ids(list(tmdb_ids_in_scope))
        
        series_tmdb_ids = {
            meta['tmdb_id'] for meta in metadata_map.values() if meta.get('item_type') == 'Series'
        }
        all_episodes_from_db = media_db.get_episodes_for_series(list(series_tmdb_ids))
        episodes_map = defaultdict(list)
        for ep in all_episodes_from_db:
            episodes_map[ep['parent_series_tmdb_id']].append(ep)

        # 4. å¢é‡/å…¨é‡åˆ¤æ–­
        items_to_process_index = []
        if force_full_update:
            logger.info("  âœ [æ·±åº¦æ¨¡å¼] å°†å¯¹æ‰€æœ‰é¡¹ç›®è¿›è¡Œå…¨é¢åˆ†æã€‚")
            resubscribe_db.clear_resubscribe_cache_except_ignored()
            items_to_process_index = emby_index
        else:
            logger.info("  âœ [å¿«é€Ÿæ¨¡å¼] å°†è¿›è¡Œå¢é‡æ‰«æ...")
            cached_items = resubscribe_db.get_all_resubscribe_cache()
            
            # item_id åœ¨ç¼“å­˜ä¸­æ˜¯ emby_item_id (ç”µå½±) æˆ– series_id-S# (å­£)
            # æˆ‘ä»¬éœ€è¦æ„å»ºå½“å‰ Emby ä¸­æ‰€æœ‰æœ‰æ•ˆé¡¹çš„ ID é›†åˆ
            current_emby_item_ids = set()
            for item in emby_index:
                if item.get('Type') == 'Movie':
                    current_emby_item_ids.add(item.get('Id'))
                elif item.get('Type') == 'Episode' and item.get('SeriesId') and item.get('ParentIndexNumber') is not None:
                    season_item_id = f"{item['SeriesId']}-S{item['ParentIndexNumber']}"
                    current_emby_item_ids.add(season_item_id)

            cached_ids = {item['item_id'] for item in cached_items}
            deleted_ids = list(cached_ids - current_emby_item_ids)
            if deleted_ids:
                resubscribe_db.delete_resubscribe_cache_items_batch(deleted_ids)
            
            # æ‰¾å‡ºéœ€è¦å¤„ç†çš„æ–°é¡¹ç›®
            new_item_ids = set()
            for item in emby_index:
                item_id = item.get('Id')
                if item.get('Type') == 'Movie':
                    if item_id not in cached_ids:
                        new_item_ids.add(item_id)
                elif item.get('Type') == 'Episode' and item.get('SeriesId') and item.get('ParentIndexNumber') is not None:
                    season_item_id = f"{item['SeriesId']}-S{item['ParentIndexNumber']}"
                    if season_item_id not in cached_ids:
                        new_item_ids.add(item.get('SeriesId')) # å¦‚æœä¸€å­£æ˜¯æ–°çš„ï¼Œæˆ‘ä»¬éœ€è¦å¤„ç†æ•´ä¸ªå‰§é›†
            
            if new_item_ids:
                items_to_process_index = [item for item in emby_index if item.get('Id') in new_item_ids or item.get('SeriesId') in new_item_ids]

        # 5. â˜…â˜…â˜… æ ¸å¿ƒå˜æ›´ï¼šåœ¨å†…å­˜ä¸­è¿›è¡Œæé€Ÿå¤„ç† â˜…â˜…â˜…
        total = len(items_to_process_index)
        if total == 0:
            task_manager.update_status_from_thread(100, f"ä»»åŠ¡å®Œæˆï¼š({scan_mode}) æ— éœ€å¤„ç†ä»»ä½•æ–°é¡¹ç›®ã€‚")
            return

        logger.info(f"  âœ å°†å¯¹ {total} ä¸ªåª’ä½“ç´¢å¼•é¡¹æŒ‰è§„åˆ™æ£€æŸ¥æ´—ç‰ˆçŠ¶æ€...")
        cache_update_batch = []
        processed_count = 0
        
        # å°†ç´¢å¼•é¡¹æŒ‰ç”µå½±å’Œå‰§é›†åˆ†ç»„
        movies_to_process = [item for item in items_to_process_index if item.get('Type') == 'Movie']
        series_episodes_map = defaultdict(list)
        series_metadata_map = {} # ç”¨äºå­˜å‚¨å‰§é›†æœ¬èº«çš„å…ƒæ•°æ®ï¼Œé¿å…é‡å¤æŸ¥æ‰¾

        for item in items_to_process_index:
            # æˆ‘ä»¬åªå…³å¿ƒåˆ†é›†ï¼Œå› ä¸ºå®ƒä»¬ä»£è¡¨äº†å®é™…çš„æ–‡ä»¶
            if item.get('Type') == 'Episode' and item.get('SeriesId'):
                series_id = item.get('SeriesId')
                series_episodes_map[series_id].append(item)
                
                # é¡ºä¾¿å­˜å‚¨å‰§é›†æœ¬èº«çš„ç´¢å¼•ä¿¡æ¯ï¼ˆåªéœ€è¦ä¸€æ¬¡ï¼‰
                if series_id not in series_metadata_map:
                    # ä»åŸå§‹ç´¢å¼•ä¸­æ‰¾åˆ°è¿™ä¸ªå‰§é›†çš„é¡¶å±‚ä¿¡æ¯
                    series_index_item = next((s for s in emby_index if s.get('Id') == series_id and s.get('Type') == 'Series'), None)
                    if series_index_item:
                        series_metadata_map[series_id] = series_index_item

        # --- å¤„ç†ç”µå½± ---
        for movie_index in movies_to_process:
            if processor.is_stop_requested(): break
            processed_count += 1
            progress = int(20 + (processed_count / total) * 80)
            task_manager.update_status_from_thread(progress, f"({processed_count}/{total}) æ­£åœ¨åˆ†æ: {movie_index.get('Name')}")

            tmdb_id = movie_index.get('ProviderIds', {}).get('Tmdb')
            metadata = metadata_map.get(tmdb_id)
            if not metadata or not metadata.get('asset_details_json'): continue
            
            # å‡è®¾æˆ‘ä»¬åªåˆ†æç¬¬ä¸€ä¸ªç‰ˆæœ¬
            asset = metadata['asset_details_json'][0]
            rule = library_to_rule_map.get(movie_index.get('_SourceLibraryId'))
            if not rule: continue

            needs, reason = _item_needs_resubscribe(asset, rule, metadata)
            status = 'needed' if needs else 'ok'
            
            cache_update_batch.append({
                "item_id": movie_index.get('Id'), "emby_item_id": movie_index.get('Id'),
                "item_name": movie_index.get('Name'), "tmdb_id": tmdb_id, "item_type": "Movie",
                "status": status, "reason": reason, **analyze_media_asset(asset),
                "matched_rule_id": rule.get('id'), "matched_rule_name": rule.get('name'),
                "source_library_id": movie_index.get('_SourceLibraryId'),
                "path": asset.get('path'), "filename": os.path.basename(asset.get('path', ''))
            })

        # --- å¤„ç†å‰§é›† ---
        for series_id, series_index in series_metadata_map.items():
            if processor.is_stop_requested(): break
            processed_count += 1
            progress = int(20 + (processed_count / total) * 80)
            task_manager.update_status_from_thread(progress, f"({processed_count}/{total}) æ­£åœ¨åˆ†æ: {series_index.get('Name')}")

            tmdb_id = series_index.get('ProviderIds', {}).get('Tmdb')
            series_metadata = metadata_map.get(tmdb_id)
            episodes_for_series = episodes_map.get(tmdb_id)
            if not series_metadata or not episodes_for_series: continue

            rule = library_to_rule_map.get(series_index.get('_SourceLibraryId'))
            if not rule: continue

            episodes_by_season = defaultdict(list)
            for ep in episodes_for_series:
                episodes_by_season[ep.get('season_number')].append(ep)

            for season_num, episodes_in_season in episodes_by_season.items():
                if season_num is None or not episodes_in_season: continue
                
                # é€‰å–ç¬¬ä¸€é›†ä½œä¸ºä»£è¡¨
                representative_episode = episodes_in_season[0]
                if not representative_episode.get('asset_details_json'): continue
                
                asset = representative_episode['asset_details_json'][0]
                needs, reason = _item_needs_resubscribe(asset, rule, series_metadata)
                status = 'needed' if needs else 'ok'

                season_item_id = f"{series_id}-S{season_num}"
                season_emby_id = next((item.get('Id') for item in emby_index if item.get('Type') == 'Season' and item.get('ParentId') == series_id and item.get('IndexNumber') == season_num), None)

                cache_update_batch.append({
                    "item_id": season_item_id, "emby_item_id": season_emby_id, "series_id": series_id,
                    "season_number": season_num, "item_name": f"{series_index.get('Name')} - ç¬¬ {season_num} å­£",
                    "tmdb_id": tmdb_id, "item_type": "Season", "status": status, "reason": reason,
                    **analyze_media_asset(asset),
                    "matched_rule_id": rule.get('id'), "matched_rule_name": rule.get('name'),
                    "source_library_id": series_index.get('_SourceLibraryId'),
                    "path": asset.get('path'), "filename": os.path.basename(asset.get('path', ''))
                })

        if cache_update_batch:
            resubscribe_db.upsert_resubscribe_cache_batch(cache_update_batch)
            
        final_message = "åª’ä½“æ´—ç‰ˆçŠ¶æ€åˆ·æ–°å®Œæˆï¼"
        if processor.is_stop_requested(): final_message = "ä»»åŠ¡å·²ä¸­æ­¢ã€‚"
        task_manager.update_status_from_thread(100, final_message)

    except Exception as e:
        logger.error(f"æ‰§è¡Œ '{task_name}' ä»»åŠ¡æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        task_manager.update_status_from_thread(-1, f"ä»»åŠ¡å¤±è´¥: {e}")

# ======================================================================
# æ ¸å¿ƒä»»åŠ¡ï¼šæ‰§è¡Œæ´—ç‰ˆè®¢é˜…
# ======================================================================

def task_resubscribe_library(processor):
    """ã€V2 - ç‹¬ç«‹é‡æ„ç‰ˆã€‘ä¸€é”®æ´—ç‰ˆæ‰€æœ‰çŠ¶æ€ä¸º 'needed' çš„é¡¹ç›®ã€‚"""
    _execute_resubscribe(processor, "ä¸€é”®åª’ä½“æ´—ç‰ˆ", "needed")

def task_resubscribe_batch(processor, item_ids: List[str]):
    """ã€V2 - ç‹¬ç«‹é‡æ„ç‰ˆã€‘ç²¾å‡†æ´—ç‰ˆæŒ‡å®šçš„é¡¹ç›®ã€‚"""
    _execute_resubscribe(processor, "æ‰¹é‡åª’ä½“æ´—ç‰ˆ", item_ids)

# ======================================================================
# æ ¸å¿ƒä»»åŠ¡ï¼šæ‰¹é‡åˆ é™¤
# ======================================================================

def task_delete_batch(processor, item_ids: List[str]):
    """ã€V2 - ç‹¬ç«‹é‡æ„ç‰ˆã€‘ç²¾å‡†åˆ é™¤æŒ‡å®šçš„é¡¹ç›®ã€‚"""
    task_name = "æ‰¹é‡åˆ é™¤åª’ä½“"
    logger.info(f"--- å¼€å§‹æ‰§è¡Œ '{task_name}' ä»»åŠ¡ (ç²¾å‡†æ¨¡å¼) ---")
    
    items_to_delete = resubscribe_db.get_resubscribe_cache_by_ids(item_ids)
    total = len(items_to_delete)
    if total == 0:
        task_manager.update_status_from_thread(100, "ä»»åŠ¡å®Œæˆï¼šé€‰ä¸­çš„é¡¹ç›®ä¸­æ²¡æœ‰å¯åˆ é™¤çš„é¡¹ã€‚")
        return

    deleted_count = 0
    for i, item in enumerate(items_to_delete):
        if processor.is_stop_requested(): break
        
        item_id = item.get('item_id')
        item_name = item.get('item_name')
        task_manager.update_status_from_thread(int((i / total) * 100), f"({i+1}/{total}) æ­£åœ¨åˆ é™¤: {item_name}")
        
        id_to_delete = item.get('emby_item_id') or item_id
        
        if emby.delete_item(id_to_delete, processor.emby_url, processor.emby_api_key, processor.emby_user_id):
            resubscribe_db.delete_resubscribe_cache_item(item_id)
            deleted_count += 1
        
        time.sleep(0.5)

    final_message = f"æ‰¹é‡åˆ é™¤ä»»åŠ¡å®Œæˆï¼æˆåŠŸåˆ é™¤äº† {deleted_count} ä¸ªåª’ä½“é¡¹ã€‚"
    task_manager.update_status_from_thread(100, final_message)

# ======================================================================
# å†…éƒ¨è¾…åŠ©å‡½æ•°
# ======================================================================

def _process_single_item_for_cache(processor, item_base_info: dict, library_to_rule_map: dict) -> Optional[List[dict]]:
    """åœ¨çº¿ç¨‹ä¸­å¤„ç†å•ä¸ªåª’ä½“é¡¹ï¼ˆç”µå½±æˆ–å‰§é›†ï¼‰çš„åˆ†æé€»è¾‘ã€‚"""
    item_id = item_base_info.get('Id')
    item_name = item_base_info.get('Name')
    source_lib_id = item_base_info.get('_SourceLibraryId')

    try:
        applicable_rule = library_to_rule_map.get(source_lib_id)
        if not applicable_rule:
            return [{"item_id": item_id, "status": 'ok', "reason": "æ— åŒ¹é…è§„åˆ™"}]
        
        item_details = emby.get_emby_item_details(item_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id)
        if not item_details: return None
        
        tmdb_id = item_details.get("ProviderIds", {}).get("Tmdb")
        media_metadata = media_db.get_media_details_by_tmdb_ids([tmdb_id]) if tmdb_id else None
        item_type = item_details.get('Type')

        if item_type == 'Series':
            seasons = emby.get_series_seasons(item_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id)
            if not seasons: return None

            season_cache_results = []
            for season in seasons:
                season_number = season.get('IndexNumber')
                season_id = season.get('Id')
                if season_number is None or season_id is None: continue

                season_item_id = f"{item_id}-S{season_number}"
                
                first_episode_details = None
                first_episode_list = emby.get_season_children(season_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id, fields="Id", limit=1)
                if first_episode_list and (first_episode_id := first_episode_list[0].get('Id')):
                    first_episode_details = emby.get_emby_item_details(first_episode_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id)

                if not first_episode_details:
                    needs_resubscribe, reason, analysis_data = False, "å­£å†…å®¹ä¸ºç©º", {}
                else:
                    needs_resubscribe, reason = _item_needs_resubscribe(first_episode_details, applicable_rule, media_metadata)
                    analysis_data = analyze_media_asset(first_episode_details)

                new_status = 'needed' if needs_resubscribe else 'ok'
                
                season_cache_item = {
                    "item_id": season_item_id, "emby_item_id": season_id, "series_id": item_id,
                    "season_number": season_number, "item_name": f"{item_name} - ç¬¬ {season_number} å­£",
                    "tmdb_id": tmdb_id, "item_type": "Season", "status": new_status, "reason": reason,
                    **analysis_data,
                    "matched_rule_id": applicable_rule.get('id'), "matched_rule_name": applicable_rule.get('name'),
                    "source_library_id": source_lib_id,
                    "path": first_episode_details.get('Path') if first_episode_details else None,
                    "filename": os.path.basename(first_episode_details.get('Path', '')) if first_episode_details else None
                }
                season_cache_results.append(season_cache_item)
            return season_cache_results
        else: # Movie
            needs_resubscribe, reason = _item_needs_resubscribe(item_details, applicable_rule, media_metadata)
            new_status = 'needed' if needs_resubscribe else 'ok'
            analysis_data = analyze_media_asset(item_details)
            
            return [{
                "item_id": item_id, "emby_item_id": item_id, "item_name": item_name, "tmdb_id": tmdb_id,
                "item_type": item_type, "status": new_status, "reason": reason,
                **analysis_data,
                "matched_rule_id": applicable_rule.get('id'), "matched_rule_name": applicable_rule.get('name'),
                "source_library_id": source_lib_id,
                "path": item_details.get('Path'), "filename": os.path.basename(item_details.get('Path', ''))
            }]
    except Exception as e:
        logger.error(f"  âœ å¤„ç†é¡¹ç›® '{item_name}' (ID: {item_id}) æ—¶çº¿ç¨‹å†…å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        return None

def _item_needs_resubscribe(asset_details: dict, rule: dict, media_metadata: Optional[dict]) -> tuple[bool, str]:
    """
    ã€V4 - æ•°æ®åº“ä¸­å¿ƒåŒ–é‡æ„ç‰ˆã€‘
    åˆ¤æ–­å•ä¸ªåª’ä½“èµ„äº§æ˜¯å¦éœ€è¦æ´—ç‰ˆçš„æ ¸å¿ƒé€»è¾‘ï¼Œæ•°æ®æºä¸ºæ•°æ®åº“ç¼“å­˜ã€‚
    """
    item_name = media_metadata.get('title', 'æœªçŸ¥é¡¹ç›®')
    logger.trace(f"  âœ [æ´—ç‰ˆæ£€æŸ¥] å¼€å§‹ä¸ºã€Š{item_name}ã€‹æ£€æŸ¥æ´—ç‰ˆéœ€æ±‚...")
    
    # â˜…â˜…â˜… æ ¸å¿ƒå˜æ›´ï¼šä» asset_details è·å–ä¿¡æ¯ â˜…â˜…â˜…
    media_streams = asset_details.get('media_streams', [])
    file_path = asset_details.get('path', '')
    file_name_lower = os.path.basename(file_path).lower() if file_path else ""
    video_stream = next((s for s in media_streams if s.get('Type') == 'Video'), None)

    reasons = []

    # 1. åˆ†è¾¨ç‡æ£€æŸ¥
    try:
        if rule.get("resubscribe_resolution_enabled"):
            if not video_stream:
                reasons.append("æ— è§†é¢‘æµä¿¡æ¯")
            else:
                threshold_width = int(rule.get("resubscribe_resolution_threshold") or 1920)
                required_tier, required_tier_name = _get_resolution_tier(threshold_width, 0)
                current_width = int(video_stream.get('width') or 0)
                current_height = int(video_stream.get('height') or 0)
                current_tier, _ = _get_resolution_tier(current_width, current_height)
                if current_tier < required_tier:
                    reasons.append(f"åˆ†è¾¨ç‡ < {required_tier_name}")
    except (ValueError, TypeError) as e:
        logger.warning(f"  âœ [åˆ†è¾¨ç‡æ£€æŸ¥] å¤„ç†æ—¶å‘ç”Ÿç±»å‹é”™è¯¯: {e}")

    # 2. è´¨é‡æ£€æŸ¥
    try:
        if rule.get("resubscribe_quality_enabled"):
            required_list = rule.get("resubscribe_quality_include", [])
            if isinstance(required_list, list) and required_list:
                required_list_lower = [str(q).lower() for q in required_list]
                # â˜…â˜…â˜… æ ¸å¿ƒå˜æ›´ï¼šä» asset_details è·å–ä¿¡æ¯ â˜…â˜…â˜…
                current_quality = asset_details.get('quality_display', '').lower()
                if not any(term in current_quality for term in required_list_lower):
                    reasons.append("è´¨é‡ä¸ç¬¦")
    except Exception as e:
        logger.warning(f"  âœ [è´¨é‡æ£€æŸ¥] å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    # 3. ç‰¹æ•ˆæ£€æŸ¥
    try:
        if rule.get("resubscribe_effect_enabled"):
            user_choices = rule.get("resubscribe_effect_include", [])
            if isinstance(user_choices, list) and user_choices:
                EFFECT_HIERARCHY = ["dovi_p8", "dovi_p7", "dovi_p5", "dovi_other", "hdr10+", "hdr", "sdr"]
                OLD_EFFECT_MAP = {"æœæ¯”è§†ç•Œ": "dovi_other", "HDR": "hdr"}
                highest_req_priority = 999
                for choice in user_choices:
                    normalized_choice = OLD_EFFECT_MAP.get(choice, choice)
                    try:
                        priority = EFFECT_HIERARCHY.index(normalized_choice)
                        if priority < highest_req_priority:
                            highest_req_priority = priority
                    except ValueError: continue
                
                if highest_req_priority < 999:
                    # â˜…â˜…â˜… æ ¸å¿ƒå˜æ›´ï¼šä» asset_details è·å–ä¿¡æ¯ â˜…â˜…â˜…
                    current_effect = asset_details.get('effect_display', [])
                    current_best_effect = min(current_effect, key=lambda e: EFFECT_HIERARCHY.index(e) if e in EFFECT_HIERARCHY else 999) if current_effect else 'sdr'
                    current_priority = EFFECT_HIERARCHY.index(current_best_effect)
                    if current_priority > highest_req_priority:
                        reasons.append("ç‰¹æ•ˆä¸ç¬¦")
    except Exception as e:
        logger.warning(f"  âœ [ç‰¹æ•ˆæ£€æŸ¥] å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    # 4. æ–‡ä»¶å¤§å°æ£€æŸ¥
    try:
        if rule.get("resubscribe_filesize_enabled"):
            # â˜…â˜…â˜… æ ¸å¿ƒå˜æ›´ï¼šä» asset_details è·å–ä¿¡æ¯ â˜…â˜…â˜…
            file_size_bytes = asset_details.get('size_bytes')
            if file_size_bytes:
                operator = rule.get("resubscribe_filesize_operator", 'lt')
                threshold_gb = float(rule.get("resubscribe_filesize_threshold_gb", 10.0))
                file_size_gb = file_size_bytes / (1024**3)
                needs_resubscribe = False
                reason_text = ""
                if operator == 'lt' and file_size_gb < threshold_gb:
                    needs_resubscribe = True
                    reason_text = f"æ–‡ä»¶ < {threshold_gb} GB"
                elif operator == 'gt' and file_size_gb > threshold_gb:
                    needs_resubscribe = True
                    reason_text = f"æ–‡ä»¶ > {threshold_gb} GB"
                if needs_resubscribe:
                    reasons.append(reason_text)
    except (ValueError, TypeError, IndexError) as e:
        logger.warning(f"  âœ [æ–‡ä»¶å¤§å°æ£€æŸ¥] å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    # 5. éŸ³è½¨å’Œå­—å¹•æ£€æŸ¥
    def _is_exempted_from_chinese_check(media_streams: list, media_metadata: Optional[dict]) -> bool:
        import re
        CHINESE_SPEAKING_REGIONS = {'ä¸­å›½', 'ä¸­å›½å¤§é™†', 'é¦™æ¸¯', 'ä¸­å›½é¦™æ¸¯', 'å°æ¹¾', 'ä¸­å›½å°æ¹¾', 'æ–°åŠ å¡'}
        if media_metadata and media_metadata.get('countries_json'):
            if not set(media_metadata['countries_json']).isdisjoint(CHINESE_SPEAKING_REGIONS): return True
        if media_metadata and (original_title := media_metadata.get('original_title')):
            if len(re.findall(r'[\u4e00-\u9fff]', original_title)) >= 2: return True
        detected_audio_langs = _get_detected_languages_from_streams(media_streams, 'Audio')
        if 'chi' in detected_audio_langs or 'yue' in detected_audio_langs: return True
        detected_subtitle_langs = _get_detected_languages_from_streams(media_streams, 'Subtitle')
        if 'chi' in detected_subtitle_langs or 'yue' in detected_subtitle_langs: return True
        return False

    is_exempted = _is_exempted_from_chinese_check(media_streams, media_metadata)
    
    try:
        if rule.get("resubscribe_audio_enabled") and not is_exempted:
            required_langs = set(rule.get("resubscribe_audio_missing_languages", []))
            if 'chi' in required_langs or 'yue' in required_langs:
                detected_audio_langs = _get_detected_languages_from_streams(media_streams, 'Audio')
                if 'chi' not in detected_audio_langs and 'yue' not in detected_audio_langs:
                    reasons.append("ç¼ºä¸­æ–‡éŸ³è½¨")
    except Exception as e:
        logger.warning(f"  âœ [éŸ³è½¨æ£€æŸ¥] å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    try:
        if rule.get("resubscribe_subtitle_enabled") and not is_exempted:
            required_langs = set(rule.get("resubscribe_subtitle_missing_languages", []))
            if 'chi' in required_langs:
                detected_subtitle_langs = _get_detected_languages_from_streams(media_streams, 'Subtitle')
                if 'chi' not in detected_subtitle_langs and 'yue' not in detected_subtitle_langs:
                    if any(s.get('IsExternal') for s in media_streams if s.get('Type') == 'Subtitle'):
                        detected_subtitle_langs.add('chi')
                if 'chi' not in detected_subtitle_langs and 'yue' not in detected_subtitle_langs:
                    reasons.append("ç¼ºä¸­æ–‡å­—å¹•")
    except Exception as e:
        logger.warning(f"  âœ [å­—å¹•æ£€æŸ¥] å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                 
    if reasons:
        final_reason = "; ".join(sorted(list(set(reasons))))
        logger.info(f"  âœ ã€Š{item_name}ã€‹éœ€è¦æ´—ç‰ˆã€‚åŸå› : {final_reason}")
        return True, final_reason
    else:
        logger.debug(f"  âœ ã€Š{item_name}ã€‹è´¨é‡è¾¾æ ‡ã€‚")
        return False, ""

def _build_resubscribe_payload(item_details: dict, rule: Optional[dict]) -> Optional[dict]:
    """æ„å»ºå‘é€ç»™ MoviePilot çš„è®¢é˜… payloadã€‚"""
    from .subscriptions import _extract_exclusion_keywords_from_filename, AUDIO_SUBTITLE_KEYWORD_MAP
    # â˜…â˜…â˜… å…³é”®è°ƒè¯•æ­¥éª¤ 1: æ‰“å°ä¼ å…¥çš„å®Œæ•´åŸå§‹æ•°æ® â˜…â˜…â˜…
    from datetime import date, datetime # ç¡®ä¿å¯¼å…¥
    details_for_log = item_details.copy()
    for key, value in details_for_log.items():
        # å°† datetime å’Œ date å¯¹è±¡éƒ½è½¬æ¢ä¸º ISO æ ¼å¼çš„å­—ç¬¦ä¸²
        if isinstance(value, (datetime, date)):
            details_for_log[key] = value.isoformat()

    # --- 1. æ›´ç¨³å¥åœ°æå–æ ¸å¿ƒID ---
    item_name = item_details.get('item_name') # ç›´æ¥ä½¿ç”¨ item_nameï¼Œå®ƒæ›´å¯é 
    tmdb_id_str = str(item_details.get('tmdb_id', '')).strip()
    item_type = item_details.get('item_type') # 'Movie' or 'Season'

    if not all([item_name, tmdb_id_str, item_type]):
        logger.error(f"æ„å»ºPayloadå¤±è´¥ï¼šç¼ºå°‘æ ¸å¿ƒåª’ä½“ä¿¡æ¯ (name, tmdb_id, type)ã€‚æ¥æº: {item_details}")
        return None
    
    try:
        tmdb_id = int(tmdb_id_str)
    except (ValueError, TypeError):
        logger.error(f"æ„å»ºPayloadå¤±è´¥ï¼šTMDB ID '{tmdb_id_str}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ã€‚")
        return None

    # --- 2. åˆå§‹åŒ–Payloadï¼Œå¹¶æ ¹æ®ç±»å‹å†³å®šåŸºç¡€è®¢é˜…å ---
    # é»˜è®¤ä½¿ç”¨åŸå§‹å‰§é›†åï¼Œé¿å…åç§°ä¸­åŒ…å« â€œ- ç¬¬ X å­£â€
    base_series_name = item_name.split(' - ç¬¬')[0]
    media_type_for_payload = "ç”µè§†å‰§" if item_type in ["Series", "Season"] else "ç”µå½±"

    payload = {
        "name": base_series_name,
        "tmdbid": tmdb_id,
        "type": media_type_for_payload,
        "best_version": 1
    }

    # --- 3. â˜…â˜…â˜… æ ¸å¿ƒé€»è¾‘ï¼šå¦‚æœæ˜¯å­£ï¼Œåˆ™å¿…é¡»æ·»åŠ  season å­—æ®µ â˜…â˜…â˜…
    if item_type == "Season":
        season_num = item_details.get('season_number')
        if season_num is not None:
            payload['season'] = int(season_num)
            logger.info(f"  âœ å·²ä¸ºã€Š{base_series_name}ã€‹ç²¾å‡†æŒ‡å®šè®¢é˜…å­£: {payload['season']}")
        else:
            # è¿™æ˜¯ä¸€ä¸ªä¿æŠ¤æ€§åˆ†æ”¯ï¼Œæ­£å¸¸æƒ…å†µä¸‹ä¸åº”è¯¥è¿›å…¥
            logger.error(f"  âœ ä¸¥é‡é”™è¯¯ï¼šé¡¹ç›®ç±»å‹ä¸º 'Season'ï¼Œä½†åœ¨æ•°æ®åº“è®°å½•ä¸­æœªæ‰¾åˆ° 'season_number'ï¼å°†æŒ‰æ•´å­£è®¢é˜…ï¼Œå¯èƒ½å¯¼è‡´é—®é¢˜ï¼")

    # --- 4. å¤„ç†æ–‡ä»¶åæ’é™¤é€»è¾‘ ---
    original_filename = item_details.get('filename')
    if original_filename:
        exclusion_keywords_list = _extract_exclusion_keywords_from_filename(original_filename)
        
        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜… æ ¸å¿ƒé€»è¾‘é‡æ„ â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
        # åªæœ‰åœ¨æå–åˆ°æœ‰æ•ˆå…³é”®å­—æ—¶ï¼Œæ‰æ„å»ºå¹¶åº”ç”¨â€œä¸”(AND)â€é€»è¾‘çš„æ­£åˆ™è¡¨è¾¾å¼
        if exclusion_keywords_list:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼çš„æ­£å‘å…ˆè¡Œæ–­è¨€ (positive lookahead) æ¥å®ç° AND é€»è¾‘
            # ä¾‹å¦‚: (?=.*1080p)(?=.*x265)(?=.*GROUP)
            # è¿™æ„å‘³ç€æ ‡é¢˜ä¸­å¿…é¡»åŒæ—¶åŒ…å« "1080p", "x265", å’Œ "GROUP"
            and_regex_parts = [f"(?=.*{re.escape(k)})" for k in exclusion_keywords_list]
            payload['exclude'] = "".join(and_regex_parts)
            logger.info(f"  âœ ç²¾å‡†æ’é™¤æ¨¡å¼ï¼šå·²ä¸ºã€Š{item_name}ã€‹ç”Ÿæˆ AND é€»è¾‘æ­£åˆ™: {payload['exclude']}")
        else:
            # å¦‚æœåˆ—è¡¨ä¸ºç©ºï¼Œè¯´æ˜æ–‡ä»¶åå¾ˆå¹²å‡€ï¼Œæ²¡æœ‰ä»»ä½•å¯ä¾›æ’é™¤çš„ç‰¹å¾
            # æ­¤æ—¶æˆ‘ä»¬ä¸æ·»åŠ ä»»ä½• exclude å‚æ•°ï¼Œè¿™æ˜¯æœ€å®‰å…¨çš„åšæ³•
            logger.info(f"  âœ… æ–‡ä»¶ååˆ†æå®Œæˆï¼Œæœªæå–åˆ°æœ‰æ•ˆæŠ€æœ¯æˆ–å‘å¸ƒç»„å…³é”®å­—ï¼Œä¸æ·»åŠ æ’é™¤è§„åˆ™ã€‚")
        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

    else:
        logger.info("  ğŸ¤· æ–‡ä»¶åä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œæ— æ³•æå–å…³é”®å­—ã€‚")

    use_custom_subscribe = config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_USE_CUSTOM_RESUBSCRIBE, False)
    if not use_custom_subscribe or not rule:
        log_reason = "è‡ªå®šä¹‰æ´—ç‰ˆæœªå¼€å¯" if not use_custom_subscribe else "æœªåŒ¹é…åˆ°è§„åˆ™"
        logger.info(f"  âœ ã€Š{item_name}ã€‹å°†ä½¿ç”¨å…¨å±€æ´—ç‰ˆ ({log_reason})ã€‚")
        
        return payload

    rule_name = rule.get('name', 'æœªçŸ¥è§„åˆ™')
    final_include_lookaheads = []

    # --- åˆ†è¾¨ç‡ã€è´¨é‡ (é€»è¾‘ä¸å˜) ---
    if rule.get("resubscribe_resolution_enabled"):
        threshold = rule.get("resubscribe_resolution_threshold")
        target_resolution = None
        if threshold == 3840: target_resolution = "4k"
        elif threshold == 1920: target_resolution = "1080p"
        if target_resolution:
            payload['resolution'] = target_resolution
            logger.info(f"  âœ ã€Š{item_name}ã€‹æŒ‰è§„åˆ™ '{rule_name}' è¿½åŠ è¿‡æ»¤å™¨ - åˆ†è¾¨ç‡: {target_resolution}")
    if rule.get("resubscribe_quality_enabled"):
        quality_list = rule.get("resubscribe_quality_include")
        if isinstance(quality_list, list) and quality_list:
            payload['quality'] = ",".join(quality_list)
            logger.info(f"  âœ ã€Š{item_name}ã€‹æŒ‰è§„åˆ™ '{rule_name}' è¿½åŠ è¿‡æ»¤å™¨ - è´¨é‡: {payload['quality']}")
    
    # --- ç‰¹æ•ˆè®¢é˜…é€»è¾‘ (å®æˆ˜ä¼˜åŒ–) ---
    if rule.get("resubscribe_effect_enabled"):
        effect_list = rule.get("resubscribe_effect_include", [])
        if isinstance(effect_list, list) and effect_list:
            simple_effects_for_payload = set()
            
            EFFECT_HIERARCHY = ["dovi_p8", "dovi_p7", "dovi_p5", "dovi_other", "hdr10+", "hdr", "sdr"]
            # â˜…â˜…â˜… æ ¸å¿ƒä¿®æ”¹ï¼šå°† "dv" åŠ å…¥æ­£åˆ™ â˜…â˜…â˜…
            EFFECT_PARAM_MAP = {
                "dovi_p8": ("(?=.*(dovi|dolby|dv))(?=.*hdr)", "dovi"),
                "dovi_p7": ("(?=.*(dovi|dolby|dv))(?=.*(p7|profile.?7))", "dovi"),
                "dovi_p5": ("(?=.*(dovi|dolby|dv))", "dovi"),
                "dovi_other": ("(?=.*(dovi|dolby|dv))", "dovi"),
                "hdr10+": ("(?=.*(hdr10\+|hdr10plus))", "hdr10+"),
                "hdr": ("(?=.*hdr)", "hdr")
            }
            OLD_EFFECT_MAP = {"æœæ¯”è§†ç•Œ": "dovi_other", "HDR": "hdr"}

            highest_req_priority = 999
            best_effect_choice = None
            for choice in effect_list:
                normalized_choice = OLD_EFFECT_MAP.get(choice, choice)
                try:
                    priority = EFFECT_HIERARCHY.index(normalized_choice)
                    if priority < highest_req_priority:
                        highest_req_priority = priority
                        best_effect_choice = normalized_choice
                except ValueError: continue
            
            if best_effect_choice:
                regex_pattern, simple_effect = EFFECT_PARAM_MAP.get(best_effect_choice, (None, None))
                if regex_pattern:
                    final_include_lookaheads.append(regex_pattern)
                if simple_effect:
                    simple_effects_for_payload.add(simple_effect)

            if simple_effects_for_payload:
                 payload['effect'] = ",".join(simple_effects_for_payload)

    # --- éŸ³è½¨ã€å­—å¹•å¤„ç† (é€»è¾‘ä¸å˜) ---
    if rule.get("resubscribe_audio_enabled"):
        audio_langs = rule.get("resubscribe_audio_missing_languages", [])
        if isinstance(audio_langs, list) and audio_langs:
            audio_keywords = [k for lang in audio_langs for k in AUDIO_SUBTITLE_KEYWORD_MAP.get(lang, [])]
            if audio_keywords:
                final_include_lookaheads.append(f"(?=.*({'|'.join(sorted(list(set(audio_keywords)), key=len, reverse=True))}))")

    if rule.get("resubscribe_subtitle_effect_only"):
        final_include_lookaheads.append("(?=.*ç‰¹æ•ˆ)")
    elif rule.get("resubscribe_subtitle_enabled"):
        subtitle_langs = rule.get("resubscribe_subtitle_missing_languages", [])
        if isinstance(subtitle_langs, list) and subtitle_langs:
            subtitle_keywords = [k for lang in subtitle_langs for k in AUDIO_SUBTITLE_KEYWORD_MAP.get(f"sub_{lang}", [])]
            if subtitle_keywords:
                final_include_lookaheads.append(f"(?=.*({'|'.join(sorted(list(set(subtitle_keywords)), key=len, reverse=True))}))")

    if final_include_lookaheads:
        payload['include'] = "".join(final_include_lookaheads)
        logger.info(f"  âœ ã€Š{item_name}ã€‹æŒ‰è§„åˆ™ '{rule_name}' ç”Ÿæˆçš„ AND æ­£åˆ™è¿‡æ»¤å™¨(ç²¾ç­›): {payload['include']}")

    return payload

def _execute_resubscribe(processor, task_name: str, target):
    """æ‰§è¡Œæ´—ç‰ˆè®¢é˜…çš„é€šç”¨å‡½æ•°ã€‚"""
    logger.info(f"--- å¼€å§‹æ‰§è¡Œ '{task_name}' ä»»åŠ¡ ---")
    
    if isinstance(target, str) and target == "needed":
        items_to_subscribe = resubscribe_db.get_all_needed_resubscribe_items()
    elif isinstance(target, list):
        items_to_subscribe = resubscribe_db.get_resubscribe_cache_by_ids(target)
    else:
        task_manager.update_status_from_thread(-1, "ä»»åŠ¡å¤±è´¥ï¼šæ— æ•ˆçš„ç›®æ ‡å‚æ•°")
        return

    total = len(items_to_subscribe)
    if total == 0:
        task_manager.update_status_from_thread(100, "ä»»åŠ¡å®Œæˆï¼šæ²¡æœ‰éœ€è¦æ´—ç‰ˆçš„é¡¹ç›®ã€‚")
        return

    all_rules = resubscribe_db.get_all_resubscribe_rules()
    config = processor.config
    delay = float(config.get(constants.CONFIG_OPTION_RESUBSCRIBE_DELAY_SECONDS, 1.5))
    resubscribed_count, deleted_count = 0, 0

    for i, item in enumerate(items_to_subscribe):
        if processor.is_stop_requested(): break
        
        current_quota = settings_db.get_subscription_quota()
        if current_quota <= 0:
            logger.warning("  âœ æ¯æ—¥è®¢é˜…é…é¢å·²ç”¨å°½ï¼Œä»»åŠ¡æå‰ç»“æŸã€‚")
            break

        item_id = item.get('item_id')
        item_name = item.get('item_name')
        task_manager.update_status_from_thread(int((i / total) * 100), f"({i+1}/{total}) [é…é¢:{current_quota}] æ­£åœ¨è®¢é˜…: {item_name}")

        rule = next((r for r in all_rules if r['id'] == item.get('matched_rule_id')), None)
        payload = _build_resubscribe_payload(item, rule)
        if not payload: continue

        if moviepilot.subscribe_with_custom_payload(payload, config):
            settings_db.decrement_subscription_quota()
            resubscribed_count += 1
            
            if rule and rule.get('delete_after_resubscribe'):
                id_to_delete = item.get('emby_item_id') or item_id
                if emby.delete_item(id_to_delete, processor.emby_url, processor.emby_api_key, processor.emby_user_id):
                    resubscribe_db.delete_resubscribe_cache_item(item_id)
                    deleted_count += 1
                else:
                    resubscribe_db.update_resubscribe_item_status(item_id, 'subscribed')
            else:
                resubscribe_db.update_resubscribe_item_status(item_id, 'subscribed')
            
            if i < total - 1: time.sleep(delay)

    final_message = f"ä»»åŠ¡å®Œæˆï¼æˆåŠŸæäº¤ {resubscribed_count} ä¸ªè®¢é˜…ï¼Œåˆ é™¤ {deleted_count} ä¸ªåª’ä½“é¡¹ã€‚"
    task_manager.update_status_from_thread(100, final_message)