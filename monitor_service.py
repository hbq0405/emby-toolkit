# monitor_service.py

import os
import re
import time
import logging
import threading
from typing import List, Optional, Any, Set
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from gevent import spawn_later

import constants
import config_manager
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from core_processor import MediaProcessor

logger = logging.getLogger(__name__)

# --- å…¨å±€é˜Ÿåˆ—å’Œé” ---
FILE_EVENT_QUEUE = set() 
QUEUE_LOCK = threading.Lock()
DEBOUNCE_TIMER = None
DELETE_EVENT_QUEUE = set()
DELETE_QUEUE_LOCK = threading.Lock()
DELETE_DEBOUNCE_TIMER = None

DEBOUNCE_DELAY = 5 # é˜²æŠ–å»¶è¿Ÿç§’æ•°

class MediaFileHandler(FileSystemEventHandler):
    """
    æ–‡ä»¶ç³»ç»Ÿäº‹ä»¶å¤„ç†å™¨
    """
    def __init__(self, extensions: List[str]):
        self.extensions = [ext.lower() for ext in extensions]

    def _is_valid_media_file(self, file_path: str) -> bool:
        if os.path.exists(file_path) and os.path.isdir(file_path): return False
        _, ext = os.path.splitext(file_path)
        if ext.lower() not in self.extensions: return False
        filename = os.path.basename(file_path)
        if filename.startswith('.'): return False
        if filename.endswith(('.part', '.crdownload', '.tmp', '.aria2')): return False
        return True

    def on_created(self, event):
        if not event.is_directory and self._is_valid_media_file(event.src_path):
            self._enqueue_file(event.src_path)

    def on_moved(self, event):
        if not event.is_directory and self._is_valid_media_file(event.dest_path):
            self._enqueue_file(event.dest_path)

    def on_deleted(self, event):
        if event.is_directory:
            return
        
        _, ext = os.path.splitext(event.src_path)
        if ext.lower() not in self.extensions:
            return

        self._enqueue_delete(event.src_path)

    def _enqueue_file(self, file_path: str):
        """æ–°å¢/ç§»åŠ¨æ–‡ä»¶å…¥é˜Ÿ"""
        global DEBOUNCE_TIMER
        with QUEUE_LOCK:
            if file_path not in FILE_EVENT_QUEUE:
                logger.info(f"  ğŸ” [å®æ—¶ç›‘æ§] æ–‡ä»¶åŠ å…¥é˜Ÿåˆ—: {os.path.basename(file_path)}")
            
            FILE_EVENT_QUEUE.add(file_path)
            
            if DEBOUNCE_TIMER: DEBOUNCE_TIMER.kill()
            DEBOUNCE_TIMER = spawn_later(DEBOUNCE_DELAY, process_batch_queue)

    def _enqueue_delete(self, file_path: str):
        """åˆ é™¤æ–‡ä»¶å…¥é˜Ÿ"""
        global DELETE_DEBOUNCE_TIMER
        with DELETE_QUEUE_LOCK:
            if file_path not in DELETE_EVENT_QUEUE:
                logger.info(f"  ğŸ—‘ï¸ [å®æ—¶ç›‘æ§] åˆ é™¤äº‹ä»¶å…¥é˜Ÿ: {os.path.basename(file_path)}")
            
            DELETE_EVENT_QUEUE.add(file_path)
            
            if DELETE_DEBOUNCE_TIMER: DELETE_DEBOUNCE_TIMER.kill()
            DELETE_DEBOUNCE_TIMER = spawn_later(DEBOUNCE_DELAY, process_delete_batch_queue)

def process_batch_queue():
    """
    å¤„ç†æ–°å¢/ä¿®æ”¹é˜Ÿåˆ— (åˆ†ç»„ä¼˜åŒ–ç‰ˆ)
    """
    global DEBOUNCE_TIMER
    with QUEUE_LOCK:
        files_to_process = list(FILE_EVENT_QUEUE)
        FILE_EVENT_QUEUE.clear()
        DEBOUNCE_TIMER = None
    
    if not files_to_process: return
    
    processor = MonitorService.processor_instance
    if not processor: return

    # 1. æŒ‰çˆ¶ç›®å½•åˆ†ç»„
    grouped_files = {}
    for file_path in files_to_process:
        parent_dir = os.path.dirname(file_path)
        if parent_dir not in grouped_files: 
            grouped_files[parent_dir] = []
        grouped_files[parent_dir].append(file_path)

    # 2. æå–ä»£è¡¨æ–‡ä»¶ (æ¯ä¸ªç›®å½•åªå–ä¸€ä¸ª)
    representative_files = []
    
    logger.info(f"  ğŸš€ [å®æ—¶ç›‘æ§] é˜²æŠ–ç»“æŸï¼Œå…±æ£€æµ‹åˆ° {len(files_to_process)} ä¸ªæ–‡ä»¶ï¼Œèšåˆä¸º {len(grouped_files)} ä¸ªä»»åŠ¡ç»„ã€‚")

    for parent_dir, files in grouped_files.items():
        # å–ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºä»£è¡¨
        rep_file = files[0]
        representative_files.append(rep_file)
        
        # æ‰“å°æ—¥å¿—æ–¹ä¾¿è°ƒè¯•
        folder_name = os.path.basename(parent_dir)
        if len(files) > 1:
            logger.info(f"    â”œâ”€ ç›®å½• '{folder_name}' å« {len(files)} ä¸ªæ–‡ä»¶ï¼Œé€‰å– '{os.path.basename(rep_file)}' ä¸ºä»£è¡¨ã€‚")
        else:
            logger.info(f"    â”œâ”€ ç›®å½• '{folder_name}' å•æ–‡ä»¶: '{os.path.basename(rep_file)}'")

    # 3. å°†ä»£è¡¨æ–‡ä»¶åˆ—è¡¨ä¼ ç»™æ‰¹é‡å¤„ç†çº¿ç¨‹
    threading.Thread(target=_handle_batch_file_task, args=(processor, representative_files)).start()

def process_delete_batch_queue():
    """
    å¤„ç†åˆ é™¤é˜Ÿåˆ— (æ‰¹é‡ç‰ˆ)
    """
    global DELETE_DEBOUNCE_TIMER
    with DELETE_QUEUE_LOCK:
        files = list(DELETE_EVENT_QUEUE)
        DELETE_EVENT_QUEUE.clear()
        DELETE_DEBOUNCE_TIMER = None
    
    if not files: return
    
    processor = MonitorService.processor_instance
    if not processor: return

    logger.info(f"  ğŸ—‘ï¸ [å®æ—¶ç›‘æ§] é˜²æŠ–ç»“æŸï¼Œèšåˆå¤„ç†åˆ é™¤äº‹ä»¶: å…± {len(files)} ä¸ªæ–‡ä»¶")

    # è°ƒç”¨å¤„ç†å™¨çš„æ‰¹é‡åˆ é™¤æ¥å£
    threading.Thread(target=processor.process_file_deletion_batch, args=(files,)).start()

def _handle_batch_file_task(processor, file_paths: List[str]):
    """
    æ‰¹é‡å¤„ç†æ–°å¢æ–‡ä»¶ä»»åŠ¡ï¼š
    1. é€ä¸ªæ£€æŸ¥ä»£è¡¨æ–‡ä»¶çš„ç¨³å®šæ€§ï¼ˆç­‰å¾…æ‹·è´å®Œæˆï¼‰ã€‚
    2. å°†æ‰€æœ‰æœ‰æ•ˆçš„ä»£è¡¨æ–‡ä»¶ä¼ ç»™æ ¸å¿ƒå¤„ç†å™¨çš„æ‰¹é‡å…¥å£ã€‚
    """
    valid_files = []
    
    # 1. æ£€æŸ¥æ–‡ä»¶ç¨³å®šæ€§ (Wait for copy to finish)
    for file_path in file_paths:
        if not os.path.exists(file_path):
            continue
            
        stable_count = 0
        last_size = -1
        is_stable = False
        
        # æœ€å¤šç­‰å¾… 60ç§’
        for _ in range(60): 
            try:
                if not os.path.exists(file_path): 
                    break # æ–‡ä»¶ä¸­é€”æ¶ˆå¤±
                
                size = os.path.getsize(file_path)
                if size > 0 and size == last_size:
                    stable_count += 1
                else:
                    stable_count = 0
                
                last_size = size
                
                # è¿ç»­ 3ç§’ å¤§å°ä¸å˜ï¼Œè®¤ä¸ºæ‹·è´å®Œæˆ
                if stable_count >= 3: 
                    is_stable = True
                    break
                
                time.sleep(1)
            except: 
                pass
        
        if is_stable:
            valid_files.append(file_path)
        else:
            logger.warning(f"  âš ï¸ [å®æ—¶ç›‘æ§] æ–‡ä»¶ä¸ç¨³å®šæˆ–è¶…æ—¶ï¼Œè·³è¿‡å¤„ç†: {os.path.basename(file_path)}")

    if not valid_files:
        return

    # 2. â˜…â˜…â˜… è°ƒç”¨æ ¸å¿ƒå¤„ç†å™¨çš„æ‰¹é‡å…¥å£ â˜…â˜…â˜…
    # è¿™ä¸ªæ–¹æ³•ä¼šï¼š
    # A. éå† valid_files (ä»£è¡¨æ–‡ä»¶)ï¼Œé€ä¸ªç”Ÿæˆè¦†ç›–ç¼“å­˜ (ä¸åˆ·æ–° Emby)ã€‚
    # B. æ”¶é›†æ‰€æœ‰æ¶‰åŠçš„çˆ¶ç›®å½•ã€‚
    # C. ç»Ÿä¸€åˆ·æ–°è¿™äº›çˆ¶ç›®å½•ã€‚
    # è¿™æ ·æ—¢ä¿è¯äº†æ•ˆç‡ï¼ˆä¸é‡å¤åˆ®å‰ŠåŒç›®å½•æ–‡ä»¶ï¼‰ï¼Œåˆä¿è¯äº†å®‰å…¨ï¼ˆç¼“å­˜å°±ç»ªåå†åˆ·æ–°ï¼‰ã€‚
    processor.process_file_actively_batch(valid_files)

class MonitorService:
    # ... (ä¿æŒä¸å˜) ...
    processor_instance = None

    def __init__(self, config: dict, processor: 'MediaProcessor'):
        self.config = config
        self.processor = processor
        MonitorService.processor_instance = processor 
        
        self.observer: Optional[Any] = None
        self.enabled = self.config.get(constants.CONFIG_OPTION_MONITOR_ENABLED, False)
        self.paths = self.config.get(constants.CONFIG_OPTION_MONITOR_PATHS, [])
        self.extensions = self.config.get(constants.CONFIG_OPTION_MONITOR_EXTENSIONS, constants.DEFAULT_MONITOR_EXTENSIONS)

    def start(self):
        if not self.enabled:
            logger.info("  âœ å®æ—¶ç›‘æ§åŠŸèƒ½æœªå¯ç”¨ã€‚")
            return

        if not self.paths:
            logger.warning("  âœ å®æ—¶ç›‘æ§å·²å¯ç”¨ï¼Œä½†æœªé…ç½®ç›‘æ§ç›®å½•åˆ—è¡¨ã€‚")
            return

        self.observer = Observer()
        event_handler = MediaFileHandler(self.extensions)

        started_paths = []
        for path in self.paths:
            if os.path.exists(path) and os.path.isdir(path):
                try:
                    self.observer.schedule(event_handler, path, recursive=True)
                    started_paths.append(path)
                except Exception as e:
                    logger.error(f"  âœ æ— æ³•ç›‘æ§ç›®å½• '{path}': {e}")
            else:
                logger.warning(f"  âœ ç›‘æ§ç›®å½•ä¸å­˜åœ¨æˆ–æ— æ•ˆï¼Œå·²è·³è¿‡: {path}")

        if started_paths:
            self.observer.start()
            logger.info(f"  ğŸ‘€ å®æ—¶ç›‘æ§æœåŠ¡å·²å¯åŠ¨ï¼Œæ­£åœ¨ç›‘å¬ {len(started_paths)} ä¸ªç›®å½•: {started_paths}")
        else:
            logger.warning("  âœ æ²¡æœ‰æœ‰æ•ˆçš„ç›‘æ§ç›®å½•ï¼Œå®æ—¶ç›‘æ§æœåŠ¡æœªå¯åŠ¨ã€‚")

    def stop(self):
        if self.observer:
            logger.info("  âœ æ­£åœ¨åœæ­¢å®æ—¶ç›‘æ§æœåŠ¡...")
            self.observer.stop()
            self.observer.join()
            logger.info("  âœ å®æ—¶ç›‘æ§æœåŠ¡å·²åœæ­¢ã€‚")