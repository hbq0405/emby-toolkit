# monitor_service.py

import os
import re
import time
import logging
import threading
from typing import List, Optional, Any, Set
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from gevent import spawn_later

import constants
import config_manager
import handler.emby as emby
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from core_processor import MediaProcessor

logger = logging.getLogger(__name__)

# --- å…¨å±€é˜Ÿåˆ—å’Œé” ---
FILE_EVENT_QUEUE = set() 
QUEUE_LOCK = threading.Lock()
DEBOUNCE_TIMER = None
DELETE_EVENT_QUEUE = set()
DELETE_QUEUE_LOCK = threading.Lock()
DELETE_DEBOUNCE_TIMER = None

DEBOUNCE_DELAY = 3 # é˜²æŠ–å»¶è¿Ÿç§’æ•°

class EmbyRefreshManager:
    """
    å…¨å±€åˆ·æ–°è“„æ°´æ± ï¼š
    é©»ç•™åœ¨ MonitorService ä¸­ï¼Œè´Ÿè´£æ¥æ”¶ CoreProcessor å¤„ç†å®Œçš„è·¯å¾„ï¼Œ
    è¿›è¡ŒäºŒæ¬¡é˜²æŠ–ï¼Œç›´åˆ°é™é»˜æœŸç»“æŸæ‰é€šçŸ¥ Emby åˆ·æ–°ã€‚
    """
    def __init__(self, processor, cooldown=5.0):
        self.processor = processor # éœ€è¦ç”¨åˆ° processor é‡Œçš„ emby_url ç­‰é…ç½®
        self.cooldown = cooldown
        self.pending_paths = set()
        self.timer = None
        self.lock = threading.Lock()

    def add_paths(self, paths: Set[str]):
        """æ¥æ”¶ä¸€æ‰¹å¾…åˆ·æ–°è·¯å¾„"""
        if not paths: return
        
        with self.lock:
            count_before = len(self.pending_paths)
            self.pending_paths.update(paths)
            count_after = len(self.pending_paths)
            
            if count_after > count_before:
                logger.info(f"  ğŸŒŠ [åˆ·æ–°è“„æ°´æ± ] æ–°å¢ {count_after - count_before} ä¸ªè·¯å¾„ï¼Œå½“å‰ç§¯å‹: {count_after}ã€‚å€’è®¡æ—¶é‡ç½®ä¸º {self.cooldown}s...")
            else:
                # è·¯å¾„å·²å­˜åœ¨ï¼Œä½†ä¹Ÿé‡ç½®å€’è®¡æ—¶ï¼Œå› ä¸ºè¯´æ˜è¿˜åœ¨å†™å…¥
                logger.debug(f"  ğŸŒŠ [åˆ·æ–°è“„æ°´æ± ] è·¯å¾„å·²åœ¨é˜Ÿåˆ—ä¸­ï¼Œé‡ç½®å€’è®¡æ—¶...")

            if self.timer:
                self.timer.cancel()
            self.timer = threading.Timer(self.cooldown, self._flush_and_execute)
            self.timer.start()

    def _flush_and_execute(self):
        """æ‰§è¡Œåˆ·æ–°"""
        paths_to_process = []
        with self.lock:
            paths_to_process = list(self.pending_paths)
            self.pending_paths.clear()
            self.timer = None
        
        if not paths_to_process: return

        logger.info(f"  ğŸš€ [å…¨å±€åˆ·æ–°] é™é»˜æœŸç»“æŸï¼Œå¼€å§‹ç»Ÿä¸€åˆ·æ–° {len(paths_to_process)} ä¸ªç´¯ç§¯è·¯å¾„...")
        
        # ä½¿ç”¨ processor ä¸­çš„é…ç½®
        url = self.processor.emby_url
        key = self.processor.emby_api_key

        unique_anchor_map = {}
        fallback_paths = []

        # è§£æ ID (åˆ©ç”¨ processor ä¸­å¼•ç”¨çš„ emby æ¨¡å—)
        for folder_path in paths_to_process:
            anchor_id, anchor_name = emby.find_nearest_library_anchor(folder_path, url, key)
            if anchor_id:
                unique_anchor_map[anchor_id] = anchor_name
            else:
                fallback_paths.append(folder_path)

        # åˆ·æ–° ID
        if unique_anchor_map:
            logger.info(f"    âœ èšåˆä¸º {len(unique_anchor_map)} ä¸ª Emby é”šç‚¹è¿›è¡Œåˆ·æ–°: {list(unique_anchor_map.values())}")
            for anchor_id, anchor_name in unique_anchor_map.items():
                try:
                    emby.refresh_item_by_id(anchor_id, url, key)
                    time.sleep(0.2)
                except Exception as e:
                    logger.error(f"åˆ·æ–° Emby ID {anchor_id} å¤±è´¥: {e}")

        # åˆ·æ–° è·¯å¾„
        if fallback_paths:
            logger.info(f"    âœ å¯¹ {len(fallback_paths)} ä¸ªæ— æ³•è§£æIDçš„è·¯å¾„æ‰§è¡Œæ™®é€šåˆ·æ–°...")
            for path in fallback_paths:
                try:
                    emby.refresh_library_by_path(path, url, key)
                except Exception as e:
                    logger.error(f"åˆ·æ–°è·¯å¾„ {path} å¤±è´¥: {e}")
        
        logger.info(f"  âœ… [å…¨å±€åˆ·æ–°] å®Œæˆã€‚")

class MediaFileHandler(FileSystemEventHandler):
    """
    æ–‡ä»¶ç³»ç»Ÿäº‹ä»¶å¤„ç†å™¨
    """
    def __init__(self, extensions: List[str]):
        self.extensions = [ext.lower() for ext in extensions]

    def _is_valid_media_file(self, file_path: str) -> bool:
        if os.path.exists(file_path) and os.path.isdir(file_path): return False
        _, ext = os.path.splitext(file_path)
        if ext.lower() not in self.extensions: return False
        filename = os.path.basename(file_path)
        if filename.startswith('.'): return False
        if filename.endswith(('.part', '.crdownload', '.tmp', '.aria2')): return False
        return True

    def on_created(self, event):
        if not event.is_directory and self._is_valid_media_file(event.src_path):
            self._enqueue_file(event.src_path)

    def on_moved(self, event):
        if not event.is_directory and self._is_valid_media_file(event.dest_path):
            self._enqueue_file(event.dest_path)

    def on_deleted(self, event):
        if event.is_directory:
            return
        
        _, ext = os.path.splitext(event.src_path)
        if ext.lower() not in self.extensions:
            return

        self._enqueue_delete(event.src_path)

    def _enqueue_file(self, file_path: str):
        """æ–°å¢/ç§»åŠ¨æ–‡ä»¶å…¥é˜Ÿ"""
        global DEBOUNCE_TIMER
        with QUEUE_LOCK:
            if file_path not in FILE_EVENT_QUEUE:
                logger.info(f"  ğŸ” [å®æ—¶ç›‘æ§] æ–‡ä»¶åŠ å…¥é˜Ÿåˆ—: {os.path.basename(file_path)}")
            
            FILE_EVENT_QUEUE.add(file_path)
            
            if DEBOUNCE_TIMER: DEBOUNCE_TIMER.kill()
            DEBOUNCE_TIMER = spawn_later(DEBOUNCE_DELAY, process_batch_queue)

    def _enqueue_delete(self, file_path: str):
        """åˆ é™¤æ–‡ä»¶å…¥é˜Ÿ"""
        global DELETE_DEBOUNCE_TIMER
        with DELETE_QUEUE_LOCK:
            if file_path not in DELETE_EVENT_QUEUE:
                logger.info(f"  ğŸ—‘ï¸ [å®æ—¶ç›‘æ§] åˆ é™¤äº‹ä»¶å…¥é˜Ÿ: {os.path.basename(file_path)}")
            
            DELETE_EVENT_QUEUE.add(file_path)
            
            if DELETE_DEBOUNCE_TIMER: DELETE_DEBOUNCE_TIMER.kill()
            DELETE_DEBOUNCE_TIMER = spawn_later(DEBOUNCE_DELAY, process_delete_batch_queue)

def process_batch_queue():
    """
    å¤„ç†æ–°å¢/ä¿®æ”¹é˜Ÿåˆ— (åˆ†ç»„ä¼˜åŒ–ç‰ˆ)
    """
    global DEBOUNCE_TIMER
    with QUEUE_LOCK:
        files_to_process = list(FILE_EVENT_QUEUE)
        FILE_EVENT_QUEUE.clear()
        DEBOUNCE_TIMER = None
    
    if not files_to_process: return
    
    processor = MonitorService.processor_instance
    if not processor: return

    # 1. æŒ‰çˆ¶ç›®å½•åˆ†ç»„
    grouped_files = {}
    for file_path in files_to_process:
        parent_dir = os.path.dirname(file_path)
        if parent_dir not in grouped_files: 
            grouped_files[parent_dir] = []
        grouped_files[parent_dir].append(file_path)

    # 2. æå–ä»£è¡¨æ–‡ä»¶ (æ¯ä¸ªç›®å½•åªå–ä¸€ä¸ª)
    representative_files = []
    
    logger.info(f"  ğŸš€ [å®æ—¶ç›‘æ§] é˜²æŠ–ç»“æŸï¼Œå…±æ£€æµ‹åˆ° {len(files_to_process)} ä¸ªæ–‡ä»¶ï¼Œèšåˆä¸º {len(grouped_files)} ä¸ªä»»åŠ¡ç»„ã€‚")

    for parent_dir, files in grouped_files.items():
        # å–ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºä»£è¡¨
        rep_file = files[0]
        representative_files.append(rep_file)
        
        # æ‰“å°æ—¥å¿—æ–¹ä¾¿è°ƒè¯•
        folder_name = os.path.basename(parent_dir)
        if len(files) > 1:
            logger.info(f"    â”œâ”€ ç›®å½• '{folder_name}' å« {len(files)} ä¸ªæ–‡ä»¶ï¼Œé€‰å– '{os.path.basename(rep_file)}' ä¸ºä»£è¡¨ã€‚")
        else:
            logger.info(f"    â”œâ”€ ç›®å½• '{folder_name}' å•æ–‡ä»¶: '{os.path.basename(rep_file)}'")

    # 3. å°†ä»£è¡¨æ–‡ä»¶åˆ—è¡¨ä¼ ç»™æ‰¹é‡å¤„ç†çº¿ç¨‹
    threading.Thread(target=_handle_batch_file_task, args=(processor, representative_files)).start()

def process_delete_batch_queue():
    """
    å¤„ç†åˆ é™¤é˜Ÿåˆ— (æ‰¹é‡ç‰ˆ)
    """
    global DELETE_DEBOUNCE_TIMER
    with DELETE_QUEUE_LOCK:
        files = list(DELETE_EVENT_QUEUE)
        DELETE_EVENT_QUEUE.clear()
        DELETE_DEBOUNCE_TIMER = None
    
    if not files: return
    
    processor = MonitorService.processor_instance
    if not processor: return

    logger.info(f"  ğŸ—‘ï¸ [å®æ—¶ç›‘æ§] é˜²æŠ–ç»“æŸï¼Œèšåˆå¤„ç†åˆ é™¤äº‹ä»¶: å…± {len(files)} ä¸ªæ–‡ä»¶")

    # è°ƒç”¨å¤„ç†å™¨çš„æ‰¹é‡åˆ é™¤æ¥å£
    threading.Thread(target=processor.process_file_deletion_batch, args=(files,)).start()

def _handle_batch_file_task(processor, file_paths: List[str]):
    """
    æ‰¹é‡å¤„ç†æ–°å¢æ–‡ä»¶ä»»åŠ¡ï¼š
    1. é€ä¸ªæ£€æŸ¥ä»£è¡¨æ–‡ä»¶çš„ç¨³å®šæ€§ï¼ˆç­‰å¾…æ‹·è´å®Œæˆï¼‰ã€‚
    2. å°†æ‰€æœ‰æœ‰æ•ˆçš„ä»£è¡¨æ–‡ä»¶ä¼ ç»™æ ¸å¿ƒå¤„ç†å™¨çš„æ‰¹é‡å…¥å£ã€‚
    """
    valid_files = []
    
    # 1. æ£€æŸ¥æ–‡ä»¶ç¨³å®šæ€§ (Wait for copy to finish)
    for file_path in file_paths:
        if not os.path.exists(file_path):
            continue
            
        stable_count = 0
        last_size = -1
        is_stable = False
        
        # æœ€å¤šç­‰å¾… 60ç§’
        for _ in range(60): 
            try:
                if not os.path.exists(file_path): 
                    break # æ–‡ä»¶ä¸­é€”æ¶ˆå¤±
                
                size = os.path.getsize(file_path)
                if size > 0 and size == last_size:
                    stable_count += 1
                else:
                    stable_count = 0
                
                last_size = size
                
                # è¿ç»­ 3ç§’ å¤§å°ä¸å˜ï¼Œè®¤ä¸ºæ‹·è´å®Œæˆ
                if stable_count >= 3: 
                    is_stable = True
                    break
                
                time.sleep(1)
            except: 
                pass
        
        if is_stable:
            valid_files.append(file_path)
        else:
            logger.warning(f"  âš ï¸ [å®æ—¶ç›‘æ§] æ–‡ä»¶ä¸ç¨³å®šæˆ–è¶…æ—¶ï¼Œè·³è¿‡å¤„ç†: {os.path.basename(file_path)}")

    if not valid_files:
        return

    # 1. è°ƒç”¨ Processor å¤„ç†å…ƒæ•°æ®ï¼Œå¹¶è·å–è¿”å›å€¼
    refresh_paths = processor.process_file_actively_batch(valid_files)

    if refresh_paths and hasattr(processor, 'refresh_manager_ref'):
         processor.refresh_manager_ref.add_paths(refresh_paths)

class MonitorService:
    processor_instance = None

    def __init__(self, config: dict, processor: 'MediaProcessor'):
        self.config = config
        self.processor = processor
        MonitorService.processor_instance = processor 
        self.refresh_manager = EmbyRefreshManager(processor, cooldown=5.0)
        self.processor.refresh_manager_ref = self.refresh_manager
        self.observer: Optional[Any] = None
        self.enabled = self.config.get(constants.CONFIG_OPTION_MONITOR_ENABLED, False)
        self.paths = self.config.get(constants.CONFIG_OPTION_MONITOR_PATHS, [])
        self.extensions = self.config.get(constants.CONFIG_OPTION_MONITOR_EXTENSIONS, constants.DEFAULT_MONITOR_EXTENSIONS)

    def start(self):
        if not self.enabled:
            logger.info("  âœ å®æ—¶ç›‘æ§åŠŸèƒ½æœªå¯ç”¨ã€‚")
            return

        if not self.paths:
            logger.warning("  âœ å®æ—¶ç›‘æ§å·²å¯ç”¨ï¼Œä½†æœªé…ç½®ç›‘æ§ç›®å½•åˆ—è¡¨ã€‚")
            return

        self.observer = Observer()
        event_handler = MediaFileHandler(self.extensions)

        started_paths = []
        for path in self.paths:
            if os.path.exists(path) and os.path.isdir(path):
                try:
                    self.observer.schedule(event_handler, path, recursive=True)
                    started_paths.append(path)
                except Exception as e:
                    logger.error(f"  âœ æ— æ³•ç›‘æ§ç›®å½• '{path}': {e}")
            else:
                logger.warning(f"  âœ ç›‘æ§ç›®å½•ä¸å­˜åœ¨æˆ–æ— æ•ˆï¼Œå·²è·³è¿‡: {path}")

        if started_paths:
            self.observer.start()
            logger.info(f"  ğŸ‘€ å®æ—¶ç›‘æ§æœåŠ¡å·²å¯åŠ¨ï¼Œæ­£åœ¨ç›‘å¬ {len(started_paths)} ä¸ªç›®å½•: {started_paths}")
        else:
            logger.warning("  âœ æ²¡æœ‰æœ‰æ•ˆçš„ç›‘æ§ç›®å½•ï¼Œå®æ—¶ç›‘æ§æœåŠ¡æœªå¯åŠ¨ã€‚")

    def stop(self):
        if self.observer:
            logger.info("  âœ æ­£åœ¨åœæ­¢å®æ—¶ç›‘æ§æœåŠ¡...")
            self.observer.stop()
            self.observer.join()
            logger.info("  âœ å®æ—¶ç›‘æ§æœåŠ¡å·²åœæ­¢ã€‚")