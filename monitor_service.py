# monitor_service.py

import os
import re
import time
import logging
import threading
from typing import List, Optional, Any, Set
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from gevent import spawn_later

import constants
import config_manager
import handler.emby as emby
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from core_processor import MediaProcessor

logger = logging.getLogger(__name__)

# --- å…¨å±€é˜Ÿåˆ—å’Œé” ---
FILE_EVENT_QUEUE = set() 
QUEUE_LOCK = threading.Lock()
DEBOUNCE_TIMER = None
DELETE_EVENT_QUEUE = set()
DELETE_QUEUE_LOCK = threading.Lock()
DELETE_DEBOUNCE_TIMER = None

DEBOUNCE_DELAY = 3 # é˜²æŠ–å»¶è¿Ÿç§’æ•°

class MediaFileHandler(FileSystemEventHandler):
    """
    æ–‡ä»¶ç³»ç»Ÿäº‹ä»¶å¤„ç†å™¨
    """
    def __init__(self, extensions: List[str], exclude_dirs: List[str] = None):
        self.extensions = [ext.lower() for ext in extensions]
        # â˜…â˜…â˜… è¿™é‡Œçš„ exclude_dirs ç°åœ¨ä»£è¡¨ exclude_pathsï¼Œä½†åœ¨ Handler å±‚æˆ‘ä»¬ä¸å†ç›´æ¥è¿‡æ»¤ â˜…â˜…â˜…
        # æˆ‘ä»¬è®©æ‰€æœ‰ç¬¦åˆæ‰©å±•åçš„æ–‡ä»¶éƒ½å…¥é˜Ÿï¼Œåœ¨å¤„ç†é˜Ÿåˆ—æ—¶å†å†³å®šæ˜¯â€œåˆ®å‰Šâ€è¿˜æ˜¯â€œä»…åˆ·æ–°â€
        self.exclude_paths = [os.path.normpath(d).lower() for d in (exclude_dirs or [])]

    def _is_valid_media_file(self, file_path: str) -> bool:
        if os.path.exists(file_path) and os.path.isdir(file_path): return False
        
        # 1. æ£€æŸ¥æ‰©å±•å
        _, ext = os.path.splitext(file_path)
        if ext.lower() not in self.extensions: return False
        
        filename = os.path.basename(file_path)
        if filename.startswith('.'): return False
        if filename.endswith(('.part', '.crdownload', '.tmp', '.aria2')): return False

        # â˜…â˜…â˜… ä¿®æ”¹ï¼šç§»é™¤æ­¤å¤„çš„æ’é™¤é€»è¾‘ â˜…â˜…â˜…
        # åªè¦æ˜¯åª’ä½“æ–‡ä»¶ï¼Œæˆ‘ä»¬éƒ½æ¥æ”¶ã€‚åç»­é€»è¾‘å†³å®šæ€ä¹ˆå¤„ç†ã€‚
        return True

    def on_created(self, event):
        if not event.is_directory and self._is_valid_media_file(event.src_path):
            self._enqueue_file(event.src_path)

    def on_moved(self, event):
        if not event.is_directory and self._is_valid_media_file(event.dest_path):
            self._enqueue_file(event.dest_path)

    def on_deleted(self, event):
        if event.is_directory:
            return
        
        _, ext = os.path.splitext(event.src_path)
        if ext.lower() not in self.extensions:
            return

        self._enqueue_delete(event.src_path)

    def _enqueue_file(self, file_path: str):
        """æ–°å¢/ç§»åŠ¨æ–‡ä»¶å…¥é˜Ÿ"""
        global DEBOUNCE_TIMER
        with QUEUE_LOCK:
            if file_path not in FILE_EVENT_QUEUE:
                logger.info(f"  ğŸ” [å®æ—¶ç›‘æ§] æ–‡ä»¶åŠ å…¥é˜Ÿåˆ—: {os.path.basename(file_path)}")
            
            FILE_EVENT_QUEUE.add(file_path)
            
            if DEBOUNCE_TIMER: DEBOUNCE_TIMER.kill()
            DEBOUNCE_TIMER = spawn_later(DEBOUNCE_DELAY, process_batch_queue)

    def _enqueue_delete(self, file_path: str):
        """åˆ é™¤æ–‡ä»¶å…¥é˜Ÿ"""
        global DELETE_DEBOUNCE_TIMER
        with DELETE_QUEUE_LOCK:
            if file_path not in DELETE_EVENT_QUEUE:
                logger.info(f"  ğŸ—‘ï¸ [å®æ—¶ç›‘æ§] åˆ é™¤äº‹ä»¶å…¥é˜Ÿ: {os.path.basename(file_path)}")
            
            DELETE_EVENT_QUEUE.add(file_path)
            
            if DELETE_DEBOUNCE_TIMER: DELETE_DEBOUNCE_TIMER.kill()
            DELETE_DEBOUNCE_TIMER = spawn_later(DEBOUNCE_DELAY, process_delete_batch_queue)

def _is_path_excluded(file_path: str, exclude_paths: List[str]) -> bool:
    """
    æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦å‘½ä¸­æ’é™¤è§„åˆ™ï¼ˆå‰ç¼€åŒ¹é…ï¼‰
    """
    if not exclude_paths:
        return False
        
    norm_file_path = os.path.normpath(file_path).lower()
    
    for exclude_path in exclude_paths:
        # ç¡®ä¿æ’é™¤è·¯å¾„ä¹Ÿæ˜¯è§„èŒƒåŒ–çš„
        norm_exclude = os.path.normpath(exclude_path).lower()
        # ä½¿ç”¨ startswith è¿›è¡Œè·¯å¾„å‰ç¼€åŒ¹é…
        if norm_file_path.startswith(norm_exclude):
            return True
            
    return False

def process_batch_queue():
    """
    å¤„ç†æ–°å¢/ä¿®æ”¹é˜Ÿåˆ— (åˆ†ç»„ä¼˜åŒ– + æ’é™¤è·¯å¾„åˆ†æµç‰ˆ)
    """
    global DEBOUNCE_TIMER
    with QUEUE_LOCK:
        files_to_process = list(FILE_EVENT_QUEUE)
        FILE_EVENT_QUEUE.clear()
        DEBOUNCE_TIMER = None
    
    if not files_to_process: return
    
    processor = MonitorService.processor_instance
    if not processor: return

    # è·å–å½“å‰çš„æ’é™¤é…ç½®
    exclude_paths = config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_MONITOR_EXCLUDE_DIRS, [])

    # â˜…â˜…â˜… åˆ†æµé€»è¾‘ï¼šå°†æ–‡ä»¶åˆ†ä¸ºâ€œæ­£å¸¸åˆ®å‰Šâ€å’Œâ€œä»…åˆ·æ–°â€ä¸¤ç±» â˜…â˜…â˜…
    files_to_scrape = []
    files_to_refresh_only = []

    for file_path in files_to_process:
        if _is_path_excluded(file_path, exclude_paths):
            files_to_refresh_only.append(file_path)
        else:
            files_to_scrape.append(file_path)

    # --- åˆ†æ”¯ 1: å¤„ç†éœ€è¦åˆ®å‰Šçš„æ–‡ä»¶ (åŸæœ‰é€»è¾‘) ---
    if files_to_scrape:
        # 1. æŒ‰çˆ¶ç›®å½•åˆ†ç»„
        grouped_files = {}
        for file_path in files_to_scrape:
            parent_dir = os.path.dirname(file_path)
            if parent_dir not in grouped_files: 
                grouped_files[parent_dir] = []
            grouped_files[parent_dir].append(file_path)

        # 2. æå–ä»£è¡¨æ–‡ä»¶
        representative_files = []
        logger.info(f"  ğŸš€ [å®æ—¶ç›‘æ§] å‡†å¤‡åˆ®å‰Š {len(files_to_scrape)} ä¸ªæ–‡ä»¶ï¼Œèšåˆä¸º {len(grouped_files)} ä¸ªä»»åŠ¡ç»„ã€‚")

        for parent_dir, files in grouped_files.items():
            rep_file = files[0]
            representative_files.append(rep_file)
            folder_name = os.path.basename(parent_dir)
            if len(files) > 1:
                logger.info(f"    â”œâ”€ [åˆ®å‰Š] ç›®å½• '{folder_name}' å« {len(files)} ä¸ªæ–‡ä»¶ï¼Œé€‰å–ä»£è¡¨: {os.path.basename(rep_file)}")
            else:
                logger.info(f"    â”œâ”€ [åˆ®å‰Š] ç›®å½• '{folder_name}' å•æ–‡ä»¶: {os.path.basename(rep_file)}")

        # 3. å¯åŠ¨åˆ®å‰Šçº¿ç¨‹
        threading.Thread(target=_handle_batch_file_task, args=(processor, representative_files)).start()

    # --- åˆ†æ”¯ 2: å¤„ç†ä»…åˆ·æ–°çš„æ–‡ä»¶ (æ–°å¢é€»è¾‘) ---
    if files_to_refresh_only:
        logger.info(f"  ğŸš€ [å®æ—¶ç›‘æ§] å‘ç° {len(files_to_refresh_only)} ä¸ªæ–‡ä»¶å‘½ä¸­æ’é™¤è·¯å¾„ï¼Œå°†è·³è¿‡åˆ®å‰Šç›´æ¥åˆ·æ–° Embyã€‚")
        # å¯åŠ¨ä»…åˆ·æ–°çº¿ç¨‹
        threading.Thread(target=_handle_batch_refresh_only_task, args=(files_to_refresh_only,)).start()

def process_delete_batch_queue():
    """
    å¤„ç†åˆ é™¤é˜Ÿåˆ— (æ‰¹é‡ç‰ˆ)
    """
    global DELETE_DEBOUNCE_TIMER
    with DELETE_QUEUE_LOCK:
        files = list(DELETE_EVENT_QUEUE)
        DELETE_EVENT_QUEUE.clear()
        DELETE_DEBOUNCE_TIMER = None
    
    if not files: return
    
    processor = MonitorService.processor_instance
    if not processor: return

    logger.info(f"  ğŸ—‘ï¸ [å®æ—¶ç›‘æ§] é˜²æŠ–ç»“æŸï¼Œèšåˆå¤„ç†åˆ é™¤äº‹ä»¶: å…± {len(files)} ä¸ªæ–‡ä»¶")

    # è°ƒç”¨å¤„ç†å™¨çš„æ‰¹é‡åˆ é™¤æ¥å£
    threading.Thread(target=processor.process_file_deletion_batch, args=(files,)).start()

def _handle_batch_file_task(processor, file_paths: List[str]):
    """
    æ‰¹é‡å¤„ç†æ–°å¢æ–‡ä»¶ä»»åŠ¡ (åˆ®å‰Šæ¨¡å¼)ï¼š
    1. é€ä¸ªæ£€æŸ¥ä»£è¡¨æ–‡ä»¶çš„ç¨³å®šæ€§ï¼ˆç­‰å¾…æ‹·è´å®Œæˆï¼‰ã€‚
    2. å°†æ‰€æœ‰æœ‰æ•ˆçš„ä»£è¡¨æ–‡ä»¶ä¼ ç»™æ ¸å¿ƒå¤„ç†å™¨çš„æ‰¹é‡å…¥å£ã€‚
    """
    valid_files = _wait_for_files_stability(file_paths)

    if not valid_files:
        return

    # è°ƒç”¨æ ¸å¿ƒå¤„ç†å™¨çš„æ‰¹é‡å…¥å£ (åˆ®å‰Š + åˆ·æ–°)
    processor.process_file_actively_batch(valid_files)

def _handle_batch_refresh_only_task(file_paths: List[str]):
    """
    æ‰¹é‡å¤„ç†ä»…åˆ·æ–°ä»»åŠ¡ï¼š
    1. åŒæ ·éœ€è¦æ£€æŸ¥æ–‡ä»¶ç¨³å®šæ€§ï¼ˆé˜²æ­¢æ–‡ä»¶è¿˜æ²¡æ‹·å®Œå°±é€šçŸ¥Embyåˆ·æ–°ï¼Œå¯¼è‡´Embyè¯†åˆ«åˆ°åæ–‡ä»¶ï¼‰ã€‚
    2. ç›´æ¥è°ƒç”¨ Emby åˆ·æ–°æ¥å£ã€‚
    """
    # 1. ç­‰å¾…æ–‡ä»¶æ‹·è´å®Œæˆ
    valid_files = _wait_for_files_stability(file_paths)
    
    if not valid_files:
        return

    # 2. æå–æ‰€æœ‰æ¶‰åŠçš„çˆ¶ç›®å½•ï¼Œå»é‡
    parent_dirs = set()
    for f in valid_files:
        parent_dirs.add(os.path.dirname(f))
    
    # 3. è·å– Emby é…ç½®
    config = config_manager.APP_CONFIG
    base_url = config.get(constants.CONFIG_OPTION_EMBY_SERVER_URL)
    api_key = config.get(constants.CONFIG_OPTION_EMBY_API_KEY)

    if not base_url or not api_key:
        logger.error("  âŒ [å®æ—¶ç›‘æ§] æ— æ³•æ‰§è¡Œåˆ·æ–°ï¼šEmby é…ç½®ç¼ºå¤±ã€‚")
        return

    # 4. é€ä¸ªåˆ·æ–°ç›®å½•
    logger.info(f"  ğŸ”„ [å®æ—¶ç›‘æ§] æ­£åœ¨é€šçŸ¥ Emby åˆ·æ–° {len(parent_dirs)} ä¸ªæ’é™¤ç›®å½•...")
    for folder_path in parent_dirs:
        try:
            # ä½¿ç”¨ emby æ¨¡å—çš„æ™ºèƒ½åˆ·æ–°å‡½æ•°
            emby.refresh_library_by_path(folder_path, base_url, api_key)
            logger.info(f"    â””â”€ å·²é€šçŸ¥åˆ·æ–°: {folder_path}")
        except Exception as e:
            logger.error(f"    âŒ åˆ·æ–°ç›®å½•å¤±è´¥ {folder_path}: {e}")

def _wait_for_files_stability(file_paths: List[str]) -> List[str]:
    """
    è¾…åŠ©å‡½æ•°ï¼šç­‰å¾…æ–‡ä»¶åˆ—è¡¨ä¸­çš„æ–‡ä»¶å¤§å°ä¸å†å˜åŒ–ï¼ˆæ‹·è´å®Œæˆï¼‰
    """
    valid_files = []
    for file_path in file_paths:
        if not os.path.exists(file_path):
            continue
            
        stable_count = 0
        last_size = -1
        is_stable = False
        
        # æœ€å¤šç­‰å¾… 60ç§’
        for _ in range(60): 
            try:
                if not os.path.exists(file_path): 
                    break # æ–‡ä»¶ä¸­é€”æ¶ˆå¤±
                
                size = os.path.getsize(file_path)
                if size > 0 and size == last_size:
                    stable_count += 1
                else:
                    stable_count = 0
                
                last_size = size
                
                # è¿ç»­ 3ç§’ å¤§å°ä¸å˜ï¼Œè®¤ä¸ºæ‹·è´å®Œæˆ
                if stable_count >= 3: 
                    is_stable = True
                    break
                
                time.sleep(1)
            except: 
                pass
        
        if is_stable:
            valid_files.append(file_path)
        else:
            logger.warning(f"  âš ï¸ [å®æ—¶ç›‘æ§] æ–‡ä»¶ä¸ç¨³å®šæˆ–è¶…æ—¶ï¼Œè·³è¿‡å¤„ç†: {os.path.basename(file_path)}")
    
    return valid_files

class MonitorService:
    processor_instance = None

    def __init__(self, config: dict, processor: 'MediaProcessor'):
        self.config = config
        self.processor = processor
        MonitorService.processor_instance = processor 
        
        self.observer: Optional[Any] = None
        self.enabled = self.config.get(constants.CONFIG_OPTION_MONITOR_ENABLED, False)
        self.paths = self.config.get(constants.CONFIG_OPTION_MONITOR_PATHS, [])
        self.extensions = self.config.get(constants.CONFIG_OPTION_MONITOR_EXTENSIONS, constants.DEFAULT_MONITOR_EXTENSIONS)
        self.exclude_dirs = self.config.get(constants.CONFIG_OPTION_MONITOR_EXCLUDE_DIRS, constants.DEFAULT_MONITOR_EXCLUDE_DIRS)

    def start(self):
        if not self.enabled:
            logger.info("  âœ å®æ—¶ç›‘æ§åŠŸèƒ½æœªå¯ç”¨ã€‚")
            return

        if not self.paths:
            logger.warning("  âœ å®æ—¶ç›‘æ§å·²å¯ç”¨ï¼Œä½†æœªé…ç½®ç›‘æ§ç›®å½•åˆ—è¡¨ã€‚")
            return

        self.observer = Observer()
        event_handler = MediaFileHandler(self.extensions, self.exclude_dirs)

        started_paths = []
        for path in self.paths:
            if os.path.exists(path) and os.path.isdir(path):
                try:
                    self.observer.schedule(event_handler, path, recursive=True)
                    started_paths.append(path)
                except Exception as e:
                    logger.error(f"  âœ æ— æ³•ç›‘æ§ç›®å½• '{path}': {e}")
            else:
                logger.warning(f"  âœ ç›‘æ§ç›®å½•ä¸å­˜åœ¨æˆ–æ— æ•ˆï¼Œå·²è·³è¿‡: {path}")

        if started_paths:
            self.observer.start()
            logger.info(f"  ğŸ‘€ å®æ—¶ç›‘æ§æœåŠ¡å·²å¯åŠ¨ï¼Œæ­£åœ¨ç›‘å¬ {len(started_paths)} ä¸ªç›®å½•: {started_paths}")
        else:
            logger.warning("  âœ æ²¡æœ‰æœ‰æ•ˆçš„ç›‘æ§ç›®å½•ï¼Œå®æ—¶ç›‘æ§æœåŠ¡æœªå¯åŠ¨ã€‚")

    def stop(self):
        if self.observer:
            logger.info("  âœ æ­£åœ¨åœæ­¢å®æ—¶ç›‘æ§æœåŠ¡...")
            self.observer.stop()
            self.observer.join()
            logger.info("  âœ å®æ—¶ç›‘æ§æœåŠ¡å·²åœæ­¢ã€‚")